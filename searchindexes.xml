<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Containerd安装</title><url>/blog/posts/docker/containerd%E5%AE%89%E8%A3%85/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[官方下载地址：https://github.com/containerd/containerd/releases
wget https://github.com/containerd/containerd/releases/download/v1.6.8/cri-containerd-cni-1.6.8-linux-amd64.tar.gz mkdir cri-containerd-cni &amp;&amp; tar -zxvf cri-containerd-cni-1.6.8-linux-amd64.tar.gz -C cri-containerd-cni 复制配置文件
cp cri-containerd-cni/etc/crictl.yaml /etc/ cp cri-containerd-cni/etc/systemd/system/containerd.service /etc/systemd/system/ # 复制 containerd 和相关依赖 cp cri-containerd-cni/usr/local/bin/. /usr/local/bin/ -a # 复制runc文件 cp cri-containerd-cni/usr/local/sbin/. /usr/local/sbin/ -a 生成和配置启动文件 # 1. 创建文件夹 mkdir -p /etc/containerd # 2. 生成配置文件 containerd config default &gt; /etc/containerd/config.toml vim /etc/containerd/config.toml disabled_plugins = [] imports = [] oom_score = 0 plugin_dir = &#34;&#34; required_plugins = [] root = &#34;/var/lib/containerd&#34; state = &#34;/run/containerd&#34; version = 2 [cgroup] path = &#34;&#34; [debug] address = &#34;&#34; format = &#34;&#34; gid = 0 level = &#34;&#34; uid = 0 [grpc] address = &#34;/run/containerd/containerd.sock&#34; gid = 0 max_recv_message_size = 16777216 max_send_message_size = 16777216 tcp_address = &#34;&#34; tcp_tls_cert = &#34;&#34; tcp_tls_key = &#34;&#34; uid = 0 [metrics] address = &#34;&#34; grpc_histogram = false [plugins] [plugins.&#34;io.containerd.gc.v1.scheduler&#34;] deletion_threshold = 0 mutation_threshold = 100 pause_threshold = 0.02 schedule_delay = &#34;0s&#34; startup_delay = &#34;100ms&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;] disable_apparmor = false disable_cgroup = false disable_hugetlb_controller = true disable_proc_mount = false disable_tcp_service = true enable_selinux = false enable_tls_streaming = false ignore_image_defined_volumes = false max_concurrent_downloads = 3 max_container_log_line_size = 16384 netns_mounts_under_state_dir = false restrict_oom_score_adj = false # sandbox_image = &#34;k8s.gcr.io/pause:3.5&#34; # 1. 修改基础镜像地址 sandbox_image = &#34;registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5&#34; selinux_category_range = 1024 stats_collect_period = 10 stream_idle_timeout = &#34;4h0m0s&#34; stream_server_address = &#34;127.0.0.1&#34; stream_server_port = &#34;0&#34; systemd_cgroup = false tolerate_missing_hugetlb_controller = true unset_seccomp_profile = &#34;&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.cni] bin_dir = &#34;/opt/cni/bin&#34; conf_dir = &#34;/etc/cni/net.d&#34; conf_template = &#34;&#34; max_conf_num = 1 [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd] default_runtime_name = &#34;runc&#34; disable_snapshot_annotations = true discard_unpacked_layers = false no_pivot = false snapshotter = &#34;overlayfs&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.default_runtime] base_runtime_spec = &#34;&#34; container_annotations = [] pod_annotations = [] privileged_without_host_devices = false runtime_engine = &#34;&#34; runtime_root = &#34;&#34; runtime_type = &#34;&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.default_runtime.options] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc] base_runtime_spec = &#34;&#34; container_annotations = [] pod_annotations = [] privileged_without_host_devices = false runtime_engine = &#34;&#34; runtime_root = &#34;&#34; runtime_type = &#34;io.containerd.runc.v2&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc.options] BinaryName = &#34;&#34; CriuImagePath = &#34;&#34; CriuPath = &#34;&#34; CriuWorkPath = &#34;&#34; IoGid = 0 IoUid = 0 NoNewKeyring = false NoPivotRoot = false Root = &#34;&#34; ShimCgroup = &#34;&#34; SystemdCgroup = false [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.untrusted_workload_runtime] base_runtime_spec = &#34;&#34; container_annotations = [] pod_annotations = [] privileged_without_host_devices = false runtime_engine = &#34;&#34; runtime_root = &#34;&#34; runtime_type = &#34;&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.untrusted_workload_runtime.options] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.image_decryption] key_model = &#34;node&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry] config_path = &#34;&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.auths] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.configs] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.headers] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.mirrors] # 2. 设置仓库地址 [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.mirrors.&#34;docker.io&#34;] endpoint = [&#34;https://usydjf4t.mirror.aliyuncs.com&#34;] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.mirrors.&#34;k8s.gcr.io&#34;] endpoint = [&#34;https://registry.cn-hangzhou.aliyuncs.com/google_containers&#34;] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.x509_key_pair_streaming] tls_cert_file = &#34;&#34; tls_key_file = &#34;&#34; [plugins.&#34;io.containerd.internal.v1.opt&#34;] path = &#34;/opt/containerd&#34; [plugins.&#34;io.containerd.internal.v1.restart&#34;] interval = &#34;10s&#34; [plugins.&#34;io.containerd.metadata.v1.bolt&#34;] content_sharing_policy = &#34;shared&#34; [plugins.&#34;io.containerd.monitor.v1.cgroups&#34;] no_prometheus = false [plugins.&#34;io.containerd.runtime.v1.linux&#34;] no_shim = false runtime = &#34;runc&#34; runtime_root = &#34;&#34; shim = &#34;containerd-shim&#34; shim_debug = false [plugins.&#34;io.containerd.runtime.v2.task&#34;] platforms = [&#34;linux/amd64&#34;] [plugins.&#34;io.containerd.service.v1.diff-service&#34;] default = [&#34;walking&#34;] [plugins.&#34;io.containerd.snapshotter.v1.aufs&#34;] root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.btrfs&#34;] root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.devmapper&#34;] async_remove = false base_image_size = &#34;&#34; pool_name = &#34;&#34; root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.native&#34;] root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.overlayfs&#34;] root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.zfs&#34;] root_path = &#34;&#34; [proxy_plugins] [stream_processors] [stream_processors.&#34;io.containerd.ocicrypt.decoder.v1.tar&#34;] accepts = [&#34;application/vnd.oci.image.layer.v1.tar+encrypted&#34;] args = [&#34;--decryption-keys-path&#34;, &#34;/etc/containerd/ocicrypt/keys&#34;] env = [&#34;OCICRYPT_KEYPROVIDER_CONFIG=/etc/containerd/ocicrypt/ocicrypt_keyprovider.conf&#34;] path = &#34;ctd-decoder&#34; returns = &#34;application/vnd.oci.image.layer.v1.tar&#34; [stream_processors.&#34;io.containerd.ocicrypt.decoder.v1.tar.gzip&#34;] accepts = [&#34;application/vnd.oci.image.layer.v1.tar+gzip+encrypted&#34;] args = [&#34;--decryption-keys-path&#34;, &#34;/etc/containerd/ocicrypt/keys&#34;] env = [&#34;OCICRYPT_KEYPROVIDER_CONFIG=/etc/containerd/ocicrypt/ocicrypt_keyprovider.conf&#34;] path = &#34;ctd-decoder&#34; returns = &#34;application/vnd.oci.image.layer.v1.tar+gzip&#34; [timeouts] &#34;io.containerd.timeout.shim.cleanup&#34; = &#34;5s&#34; &#34;io.containerd.timeout.shim.load&#34; = &#34;5s&#34; &#34;io.containerd.timeout.shim.shutdown&#34; = &#34;3s&#34; &#34;io.containerd.timeout.task.state&#34; = &#34;2s&#34; [ttrpc] address = &#34;&#34; gid = 0 uid = 0 启动 systemctl daemon-reload systemctl enable containerd --now systemctl status containerd ]]></content></entry><entry><title>Docker换源</title><url>/blog/posts/docker/%E6%8D%A2%E6%BA%90/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[Podman换源 网易 hub-mirror.c.163.com USTC docker.mirrors.ustc.edu.cn vim /etc/containers/registries.conf ################################################ unqualified-search-registries = [&#34;docker.io&#34;] [[registry]] prefix = &#34;docker.io&#34; location = &#34;l6p4ic76.mirror.aliyuncs.com&#34; ################################################# Docker换源 vim /etc/docker/daemon.json { &#34;registry-mirrors&#34;: [&#34;https://l6p4ic76.mirror.aliyuncs.com&#34;], &#34;log-driver&#34;:&#34;json-file&#34;, &#34;log-opts&#34;: {&#34;max-size&#34;:&#34;500m&#34;, &#34;max-file&#34;:&#34;3&#34;} } systemctl restart docker &gt; 南京大学 https://docker.nju.edu.cn/ &gt; 网易 http://hub-mirror.c.163.com &gt; 腾讯云 docker hub mirror https://mirror.ccs.tencentyun.com &gt; docker中国 https://registry.docker-cn.com &gt; 我的 daocloud http://f1361db2.m.daocloud.io &gt; 我的华为云 https://326fcbdbb5c7487aa2d8180833e71119.mirror.swr.myhuaweicloud.com ) 我的阿里云 https://l6p4ic76.mirror.aliyuncs.com 查看镜像源 docker info podman info ]]></content></entry><entry><title>K8S集群部署</title><url>/blog/posts/docker/k8s%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[官网地址：https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/
1. 搭建单Master集群 创建一个 Master 节点 kubeadm init 将 Node节点加入到当前集群中 kubeadm join &lt;Master节点的IP和端口&gt; 环境准备 工作节点 主机名 IP地址 系统版本 master k8s-master 192.168.211.201 almalinux8.6 node1 k8s-node1 192.168.211.202 almalinux8.6 node2 k8s-node2 192.168.211.203 almalinux8.6 注意： 从 2 - 5 的内容在在master和node节点主机在都要执行
2. 安装前准备 2.1 修改和添加主机名 # 修改主机名 # 在master节点执行 hostnamectl set-hostname k8s-master # 在node节点执行 hostnamectl set-hostname k8s-node1 hostnamectl set-hostname k8s-node2 # 添加主机名 cat &gt;&gt; /etc/hosts &lt;&lt; EOF 192.168.211.201 k8s-master 192.168.211.202 k8s-node1 192.168.211.203 k8s-node2 EOF 2.2 关闭防火墙 systemctl stop firewalld systemctl disable firewalld 2.3 关闭 selinux sed -i &#39;s/SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux setenforce 0 2.4 关闭swap分区 先临时关闭，再永久关闭，这样就不用重启 # 临时关闭 swapoff -a # 永久关闭 sed -ri &#39;s/.*swap.*/#&amp;/&#39; /etc/fstab # 重启生效 # 查看效果 free -m # 重新启动swap分区 swapon -a 2.5 网桥过滤 cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-arptables = 1 net.ipv4.ip_forward=1 net.ipv4.ip_forward_use_pmtu = 0 EOF # 生效命令 sysctl --system 2.6 时间同步 # 安装软件 yum -y install ntpdate # 向阿里云服务器同步时间 ntpdate time1.aliyun.com # 删除本地时间并设置时区为上海 rm -rf /etc/localtime ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # 查看时间 date -R || date 3. 所有节点安装Docker 1.卸载旧版本 yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-engine 2.安装需要的依赖包	yum install -y yum-utils 3.设置阿里云docker镜像 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo &amp;&amp; yum makecache 4.安装docker yum -y install docker-ce docker-ce-cli containerd.io 5.启动Docker systemctl start docker &amp;&amp; systemctl enable docker &amp;&amp; systemctl status docker 6.查看docker版本信息 docker info 4. 所有节点配置阿里云Docker、kubernetes镜像 1. 配置阿里云docker镜像加速 mkdir -p /etc/docker cat &gt; /etc/docker/daemon.json &lt;&lt; EOF { &#34;registry-mirrors&#34;: [&#34;https://l6p4ic76.mirror.aliyuncs.com&#34;], &#34;log-driver&#34;:&#34;json-file&#34;, &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;], &#34;log-opts&#34;: {&#34;max-size&#34;:&#34;500m&#34;, &#34;max-file&#34;:&#34;3&#34;} } EOF systemctl restart docker 2. 配置阿里云Kubernetes 镜像 cat &gt;&gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 5. 所有节点安装kubelet kubeadm kubectl yum install -y --nogpgcheck kubelet-1.22.15 kubeadm-1.22.15 kubectl-1.22.15 # 指定K8S版本安装，不指定版本默认安装最新版。 # yum install -y --nogpgcheck kubelet kubeadm kubectl systemctl enable kubelet &amp;&amp; systemctl start kubelet 6. 部署Kubernetes Master节点 这里指定阿里云镜像仓库地址，默认的镜像地址无法加载访问。
kubeadm init \ --apiserver-advertise-address=192.168.211.201 \ --image-repository registry.aliyuncs.com/google_containers \ --kubernetes-version v1.22.15 \ --service-cidr=10.96.0.0/12 \ --pod-network-cidr=10.244.0.0/16 若出现错误
[root@almalinux ~]# kubeadm init \ &gt; --apiserver-advertise-address=192.168.211.201 \ &gt; --image-repository registry.aliyuncs.com/google_containers \ &gt; --kubernetes-version v1.25.3 \ &gt; --service-cidr=10.96.0.0/12 \ &gt; --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.25.3 [preflight] Running pre-flight checks [WARNING FileExisting-tc]: tc not found in system path error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR CRI]: container runtime is not running: output: E1029 14:48:00.390255 29768 remote_runtime.go:948] &#34;Status from runtime service failed&#34; err=&#34;rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.RuntimeService&#34; time=&#34;2022-10-29T14:48:00+08:00&#34; level=fatal msg=&#34;getting status of runtime: rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.RuntimeService&#34; , error: exit status 1 [preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...` To see the stack trace of this error execute with --v=5 or higher 解决办法
rm -rf /etc/containerd/config.toml systemctl restart containerd # 最后使用 kubeadm reset 若出现错误
[root@k8s-master ~]# kubeadm init \ &gt; --apiserver-advertise-address=192.168.211.201 \ &gt; --image-repository registry.aliyuncs.com/google_containers \ &gt; --kubernetes-version v1.25.3 \ &gt; --service-cidr=10.96.0.0/12 \ &gt; --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.25.3 [preflight] Running pre-flight checks [WARNING FileExisting-tc]: tc not found in system path [WARNING Hostname]: hostname &#34;k8s-master&#34; could not be reached [WARNING Hostname]: hostname &#34;k8s-master&#34;: lookup k8s-master on 223.5.5.5:53: no such host error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist [preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...` To see the stack trace of this error execute with --v=5 or higher 解决方法
modprobe br_netfilter echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables 注意： 如果要使用 kubectl get nodes 命令需要做以下配置
- master节点，root用户，执行以下命令 echo &#34;export KUBECONFIG=/etc/kubernetes/admin.conf&#34; &gt;&gt; ~/.bash_profile source ~/.bash_profile - master节点，非root用户，执行以下命令 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config - node节点需要从 master 节点拷贝 admin.con 文件到 node 节点上 scp root@master:/etc/kubernetes/admin.conf /etc/kubernetes/ - root 和 非root 用户的命令同master 7. 部署网络插件 # 以下网络插件任选一个 # CNI网络插件 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml # Flannel网络插件 kubectl apply -f https://kuboard.cn/install-script/flannel/flannel-v0.14.0.yaml # 查看 kubectl get pods -n kube-system 若发现有Pending的删除即可，会自动重新部署
[root@k8s-master ~]# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-7f6cbbb7b8-6gxf6 0/1 Pending 0 23m coredns-7f6cbbb7b8-nnjsk 0/1 Pending 0 23m etcd-k8s-master 1/1 Running 1 23m kube-apiserver-k8s-master 1/1 Running 1 23m kube-controller-manager-k8s-master 1/1 Running 1 23m kube-proxy-6d4d6 1/1 Running 0 18m kube-proxy-m4vx9 1/1 Running 0 23m kube-scheduler-k8s-master 1/1 Running 1 23m [root@k8s-master ~]# kubectl delete pods coredns-7f6cbbb7b8-6gxf6 coredns-7f6cbbb7b8-nnjsk -n kube-system pod &#34;coredns-7f6cbbb7b8-6gxf6&#34; deleted pod &#34;coredns-7f6cbbb7b8-nnjsk&#34; deleted [root@k8s-master ~]# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-7f6cbbb7b8-4df47 1/1 Running 0 11s coredns-7f6cbbb7b8-wxzcl 1/1 Running 0 11s etcd-k8s-master 1/1 Running 1 24m kube-apiserver-k8s-master 1/1 Running 1 24m kube-controller-manager-k8s-master 1/1 Running 1 24m kube-proxy-6d4d6 1/1 Running 0 19m kube-proxy-m4vx9 1/1 Running 0 24m kube-scheduler-k8s-master 8. 部署node节点 # 只在 master 节点执行 kubeadm token create --print-join-command # 在node节点中执行打印出的结果 kubeadm join 192.168.211.201:6443 --token hfyeoe.ie453hoen4eku70w --discovery-token-ca-cert-hash sha256:3716cd7f3c8a52b78b1ab495e7fbd3c6f7dabd899a0237c203c05bce11ac9be6 # 在 master 节点中查看 [root@k8s-master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master Ready control-plane,master 59m v1.22.3 k8s-node1 Ready &lt;none&gt; 54m v1.22.3 k8s-node2 Ready &lt;none&gt; 3m53s v1.22.3 注意： 若新加入的node节点出现NotReady等待一会即可
9. 添加图形化管理（选做） # 在 master 节点执行 kubectl apply -f https://addons.kuboard.cn/kuboard/kuboard-v3-swr.yaml 执行指令 watch kubectl get pods -n kuboard，等待 kuboard 名称空间中所有的 Pod 就绪
root@k8s-master ~]# kubectl get pods -n kuboard NAME READY STATUS RESTARTS AGE kuboard-agent-2-85d76b44dd-jvpm2 1/1 Running 0 9s kuboard-agent-67864c5f66-4w9z2 1/1 Running 0 9s kuboard-etcd-htppb 1/1 Running 0 36s kuboard-v3-765f7bcbfd-lpwct 0/1 Running 0 36s 访问 Kuboard 在浏览器中打开链接 http://your-node-ip-address:30080
输入初始用户名和密码，并登录
用户名： admin 密码： Kuboard123 卸载 kubectl delete -f https://addons.kuboard.cn/kuboard/kuboard-v3-swr.yaml rm -rf /usr/share/kuboard ]]></content></entry><entry><title>安装Docker</title><url>/blog/posts/docker/%E5%AE%89%E8%A3%85docker/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html">1. 命令行安装 1.1 卸载旧版本 yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine 1.2 安装 执行以下命令安装依赖包：
yum install -y yum-utils 鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。 执行下面的命令添加 yum 软件源：
yum-config-manager \ --add-repo \ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 官方源 # yum-config-manager \ # --add-repo \ # https://download.docker.com/linux/centos/docker-ce.repo 更新 yum 软件源缓存，并安装 docker-ce
yum makecache yum install docker-ce docker-ce-cli containerd.io docker-scan-plugin docker-compose-plugin docker-ce-rootless-extras 1.3 防火墙额外设置 由于 CentOS8 防火墙使用了 nftables，但 Docker 尚未支持 nftables， 我们可以使用如下设置使用 iptables：
更改 vim /etc/firewalld/firewalld.conf
# FirewallBackend=nftables FirewallBackend=iptables 或者执行如下命令：
firewall-cmd --permanent --zone=trusted --add-interface=docker0 firewall-cmd --reload 2. 使用脚本自动安装 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 3. 启动Docker systemctl enable docker systemctl start docker</content></entry><entry><title>使用Docker安装常用环境</title><url>/blog/posts/docker/%E4%BD%BF%E7%94%A8docker%E5%AE%89%E8%A3%85%E5%B8%B8%E7%94%A8%E7%8E%AF%E5%A2%83/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[安装Docker $ curl -fsSL get.docker.com -o get-docker.sh $ sudo sh get-docker.sh --mirror Aliyun 卸载
dnf remove -y -q docker-ce docker-ce-cli containerd.io docker-scan-plugin docker-compose-plugin docker-ce-rootless-extras rm -rf 启动 Docker $ sudo systemctl enable docker $ sudo systemctl start docker 建立 docker 用户组 默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。
建立 docker 组：
$ sudo groupadd docker 将当前用户加入 docker 组：
$ sudo usermod -aG docker $USER 注销用户或者重启系统 更换镜像源 vim /etc/docker/daemon.json {&#34;registry-mirrors&#34;: [&#34;http://hub-mirror.c.163.com&#34;]} systemctl restart docker 2) 腾讯云 docker hub mirror https://mirror.ccs.tencentyun.com 3) 华为云 https://05f073ad3c0010ea0f4bc00b7105ec20.mirror.swr.myhuaweicloud.com 4) docker中国 https://registry.docker-cn.com 5) 网易 http://hub-mirror.c.163.com 6) daocloud http://f1361db2.m.daocloud.io 安装Docker图形化界面 #下载 Docker 图形化界面 portainer sudo docker pull portainer/portainer #创建 portainer 容器 sudo docker volume create portainer_data #运行 portainer sudo docker run -d \ -p 9000:9000 \ --name portainer \ --restart always \ -v /var/run/docker.sock:/var/run/docker.sock \ -v portainer_data:/data \ portainer/portainer 安装MySql //拉取MySQL镜像 docker pull mysql //启动MySQL，注意更改密码，用户名为root，密码czyadmin docker run -d \ --name mysql \ --restart=always \ -p 3306:3306 \ -e MYSQL_ROOT_PASSWORD=czyadmin \ mysql 安装Redis //拉取Redis镜像 docker pull redis //启动Redis，注意更改密码，用户名为root，密码czyadmin docker run -d \ --name redis \ --restart=always \ -p 6379:6379 \ redis \ --requirepass &#34;czyadmin&#34; 安装Nginx 拉取镜像
docker pull nginx 创建本地配置文件
mkdir -p /etc/nginx/conf.d &amp;&amp; vim /etc/nginx/nginx.conf user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#39;$remote_addr - $remote_user [$time_local] &#34;$request&#34; &#39; &#39;$status $body_bytes_sent &#34;$http_referer&#34; &#39; &#39;&#34;$http_user_agent&#34; &#34;$http_x_forwarded_for&#34;&#39;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 启动服务
//启动nginx，映射本地配置文件 docker run -d \ --name nginx \ --restart=always \ -p 80:80 \ -v /etc/nginx/nginx.conf:/etc/nginx/nginx.conf \ -v /etc/nginx/conf.d:/etc/nginx/conf.d \ nginx vim /etc/nginx/conf.d/demo.conf server { listen 80; listen [::]:80; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; } } docker exec nginx bash -c &#39;nginx -s reload&#39; 安装RabbitMQ docker pull rabbitmq:management 默认用户名和密码：guest/guest
docker run -dit \ --name rabbitmq \ --restart=always \ -p 5672:5672 \ -p 15672:15672 \ rabbitmq:management 端口 作用 15672 管理界面UI的使用端口 15671 管理监听端口 5672,5671 AMQP 0-9-1 without and with TLSclient端通信口 4369 (epmd)epmd代表Erlang端口映射守护进程，erlang发现口 25672 ( Erlang distribution) server间内部通信口 安装Postgresql docker pull postgres docker run -d \ --name postgres \ --restart=always \ -p 5432:5432 \ -e POSTGRES_PASSWORD=czyadmin \ postgres 用户名：postgres	密码：czyadmin
]]></content></entry><entry><title>树莓派使用Docker安装openwrt作为旁路由(网关服务器)</title><url>/blog/posts/docker/%E6%A0%91%E8%8E%93%E6%B4%BE%E4%BD%BF%E7%94%A8docker%E5%AE%89%E8%A3%85openwrt%E4%BD%9C%E4%B8%BA%E6%97%81%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3%E6%9C%8D%E5%8A%A1%E5%99%A8/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag><tag>树莓派</tag></tags><content type="html"><![CDATA[
推荐使用 树莓派爱好基地的arm64无桌面增强版镜像
仓库地址： https://github.com/openfans-community-offical/Debian-Pi-Aarch64/blob/master/README_zh.md 仓库中有详细的说明文档和下载地址
开始安装openwrt容器 树莓派爱好基地的arm64无桌面增强版自带docker，可以直接使用
1. 打开网卡混杂模式 sudo ip link set eth0 promisc on 2. 创建macvlan虚拟网络，同一网段下的主机才能访问容器 下面的网段(subnet)和网关(gateway)选项请结合实际自行更改
docker network create -d macvlan --subnet=192.168.0.0/24 --gateway=192.168.0.1 -o parent=eth0 macnet 此时，我们使用 docker network ls命令可以看到网络macnet已建立成功：
pi@raspbian:~$ docker network ls NETWORK ID NAME DRIVER SCOPE 7b8e38d3dd3c bridge bridge local f96e6360c248 host host local 7c7a5a51b268 macnet macvlan local c8c6782b8e1e none null local 3. 拉取openwrt镜像 docker pull registry.cn-shanghai.aliyuncs.com/suling/openwrt:rpi4 镜像拉取完成后，我们可以执行docker images命令查看现存镜像：
docker images REPOSITORY TAG IMAGE ID CREATED SIZE registry.cn-shanghai.aliyuncs.com/suling/openwrt rpi4 c3ba4d17a20e 32 hours ago 455MB 4. 创建并启动容器 docker run --restart always --name openwrt -d --network macnet --privileged --ip 192.168.0.200 registry.cn-shanghai.aliyuncs.com/suling/openwrt:rpi4 /sbin/init 其中：
--restart always参数表示容器退出时始终重启，使服务尽量保持始终可用；
--name openwrt参数定义了容器的名称；
-d参数定义使容器运行在 Daemon 模式(后台运行)；
--network macnet参数定义将容器加入 maxnet网络；
--privileged参数定义容器运行在特权模式下；
--ip 192.168.0.200指定容器的ip
registry.cn-shanghai.aliyuncs.com/suling/openwrt:latest为 Docker 镜像名，因容器托管在阿里云 Docker 镜像仓库内，所以在镜像名中含有阿里云仓库信息；
/sbin/init定义容器启动后执行的命令。
启动容器后，我们可以使用 docker ps -a命令查看当前运行的容器：
docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 5cd19f4cd735 registry.cn-shanghai.aliyuncs.com/suling/openwrt:rpi4 &#34;/sbin/init&#34; 20 hours ago Up 7 hours openwrt 5. 进入容器修改ip,网关和dns docker exec -it openwrt ash 执行此命令后我们便进入 OpenWrt 的命令行界面，首先，我们需要编辑 OpenWrt 的网络配置文件：
vim /etc/config/network 我们需要更改 Lan 口设置：
config interface &#39;lan&#39; option ifname &#39;eth0&#39; option proto &#39;static&#39; option netmask &#39;255.255.255.0&#39; option ip6assign &#39;60&#39; option ipaddr &#39;192.168.0.200&#39; option gateway &#39;192.168.0.1&#39; option dns &#39;192.168.0.1&#39; 6. 保存后重启网络 /etc/init.d/network restart 按下Ctrl + D可以退出openwrt的终端
7. 进入luci 控制面板 在浏览器中输入第 5 步option ipaddr项目中的 IP 进入 Luci 控制面板，若option ipaddr的参数为 192.168.0.200，则可以在浏览器输入 http://192.168.0.200进入控制面板。
用户名：root
密码：password
8. 配置防火墙 在网络-防火墙-自定义规则添加以下命令后重启防火墙
iptables -t nat -I POSTROUTING -o eth0 -j MASQUERADE 9. 关闭dhcp服务 在网络-接口处删除多于的网络，只保留LAN口，点击LAN口的修改
来到最下面的基本设置，勾上忽略此接口，然后保存应用即可
10. 将网关指向openwrt 来到路由器的后台管理，将路由器的网关指向openwrt的ip地址即可
参考： https://mlapp.cn/376.html ]]></content></entry></search>