<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Anaconda的安装和入门</title><url>/posts/python/anaconda%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E5%85%A5%E9%97%A8/</url><categories><category>Python</category></categories><tags><tag>Python</tag><tag>Anaconda</tag></tags><content type="html"><![CDATA[1.0安装 1.1下载 Anaconda 下载地址：
https://www.anaconda.com/products/individual#download-section 安装方法：无脑下一步就行(**注意：**若想更改安装目录可自行设置)
1.2配置环境变量 1.2.1 将Anaconda 的安装目录和安装目录下的Scripts目录这两个地址添加到 Path 中即可
1.2.2 检查是否配置成功
conda -V 2.0换源 2.1打开终端依次输入下面的内容 conda config --add channels http://mirrors.ustc.edu.cn/anaconda/pkgs/free/ conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes 2.2删除默认源 在用户根目录（C:\Users\用户名）下找到.condarc文件，打开并并编辑，删除其中的default配置行
2.3 初始化powershell 如不初始化powershell，则在powershell中无法激活conda环境 以管理员的方式进入powershell，输入下面的内容
conda init powershell 3.0 基本使用 3.1 更新conda版本 conda update conda 3.2 查看conda帮助信息 conda -h / conda --help 3.3 创建新环境 默认情况下，新创建的环境将会被保存在anconda安装目录下的envs中
conda create --name &lt;env_name&gt; &lt;package_names&gt; &lt;env_name&gt;：新建环境名
&lt;package_names&gt;：新创建的环境中创建的包，多个包使用空格分隔
3.4 列出已有的环境 conda info --env / conda env list 3.5 切换(激活)/取消(不激活)环境 3.5.1 切换环境
conda activate &lt;env_name&gt; 3.5.2 取消环境
conda deactivate &lt;env_name&gt; 3.6 删除环境 conda remove --name &lt;env_name&gt; --all 3.7 复制环境 conda create --name &lt;new_env_name&gt; --clone &lt;copy_env_name&gt; 3.8 导入和导出环境 3.8.1 导出当前环境的包信息，将包信息存入yaml文件中
导出的文件在当前命令执行的所在目录
conda env export &gt; env.yaml 3.8.2 导入yaml文件的环境信息
conda env create -f env.yaml 3.9 包的管理 3.9.1 列出当前环境的包
conda list 3.9.2 查找可安装的包
conda search &lt;package_name&gt; 3.9.3 安装包
当前环境安装
conda install &lt;package_names&gt; 指定环境安装
conda install --name &lt;env_name&gt; &lt;package_names&gt; pip安装（只能在当前环境安装）
pip install &lt;package_names&gt; 3.9.4 卸载包
卸载当前环境的包
conda remove &lt;package_names&gt; 卸载指定环境的包
conda remove --name &lt;env_name&gt; &lt;packages_names&gt; 3.9.5 更新包
更新指定包
conda update &lt;package_name&gt; 更新所有包
conda update --all ]]></content></entry><entry><title>BT下载服务搭建</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/bt%E4%B8%8B%E8%BD%BD%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag></tags><content type="html"><![CDATA[github项目地址： https://github.com/P3TERX/aria2.sh 0. 新加入Docker安装 文档地址： https://p3terx.com/archives/docker-aria2-pro.html 0.1 安装aria2 自行替换RPC_SECRET后启动
docker run -d \ --name aria2-pro \ --restart always \ --log-opt max-size=1m \ --network host \ -e PUID=$UID \ -e PGID=$GID \ -e RPC_SECRET=czyadmin \ -e RPC_PORT=6800 \ -e LISTEN_PORT=6888 \ -v $PWD/aria2-config:/config \ -v $PWD/aria2-downloads:/downloads \ p3terx/aria2-pro 0.2 安装WEBUI docker run -d \ --name ariang \ --restart always \ --log-opt max-size=1m \ -p 6880:6880 \ p3terx/ariang 0.3 安装filebrowser 默认用户名和密码：admin
docker run -d \ --name filebrowser \ --restart always \ -v $PWD/aria2-downloads:/srv \ -v $PWD/filebrowser/filebrowser.db:/database/filebrowser.db \ -v $PWD/filebrowser/settings.json:/config/settings.json \ -e PUID=$(id -u) \ -e PGID=$(id -g) \ -p 8080:80 \ filebrowser/filebrowser 普通安装 1.0 安装并配置aria2 wget https://picture-czy.oss-cn-beijing.aliyuncs.com/shareFile/aria2.sh -O /root/aria2.sh &amp;&amp; bash /root/aria2.sh 2.0 设置tracker自动更新 wget https://picture-czy.oss-cn-beijing.aliyuncs.com/shareFile/tracker.sh -O /root/tracker.sh &amp;&amp; bash /root/tracker.sh crontab -e # 每周日凌晨5点 0 5 * * 0 /bin/bash /root/tracker.sh 2&gt;&amp;1 3.0 安装AriaNg wget https://picture-czy.oss-cn-beijing.aliyuncs.com/shareFile/AriaNg-1.2.3-AllInOne.zip -O /root/AriaNg.zip apt install nginx -y unzip /root/AriaNg.zip -d /var/www/AriaNg vim /etc/nginx/sites-enabled/AriaNg server { listen 80; #监听端口 server_name 127.0.0.1; #主机ip index index.html index.htm; location / { root /var/www/AriaNg; #站点目录 } } # 检查语法错误 nginx -t # 重启服务 systemctl restart nginx.service 填入RPC密钥 4.0 安装filebrowser wget https://picture-czy.oss-cn-beijing.aliyuncs.com/shareFile/linux-amd64-filebrowser.tar.gz tar -zxvf linux-amd64-filebrowser.tar.gz -C /usr/local/bin/ #先创建一个目录用来存放数据库和配置文件 mkdir /etc/filebrowser/ source ~/.bashrc ############# 国外新方法 ################## curl -fsSL https://raw.githubusercontent.com/filebrowser/get/master/get.sh | bash #创建配置数据库 filebrowser -d /etc/filebrowser/filebrowser.db config init #设置监听地址 filebrowser -d /etc/filebrowser/filebrowser.db config set --address 0.0.0.0 #设置监听端口 filebrowser -d /etc/filebrowser/filebrowser.db config set --port 8080 #设置语言环境 filebrowser -d /etc/filebrowser/filebrowser.db config set --locale zh-cn #设置日志位置 filebrowser -d /etc/filebrowser/filebrowser.db config set --log /var/log/filebrowser.log #添加一个用户 filebrowser -d /etc/filebrowser/filebrowser.db users add admin password --perm.admin #设置网盘根目录 filebrowser -d /etc/filebrowser/filebrowser.db config set --root /mnt/hhd01/aria2 # 启动 filebrowser -d /etc/filebrowser/filebrowser.db Username: admin Password: password 后台挂起 nohup filebrowser -d /etc/filebrowser/filebrowser.db &amp; 或者设置守护进程
vim /lib/systemd/system/filebrowser.service [Unit] Description=File Browser After=network.target [Service] Type=simple ExecStart=/usr/local/bin/filebrowser -d /etc/filebrowser/filebrowser.db Restart=on-abnormal RestartSec=5s KillMode=mixed [Install] WantedBy=multi-user.target systemctl daemon-reload systemctl start filebrowser.service systemctl status filebrowser.service systemctl enable filebrowser.service ]]></content></entry><entry><title>byobu的使用</title><url>/posts/linux%E6%93%8D%E4%BD%9C/byobu%E7%9A%84%E4%BD%BF%E7%94%A8/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html">1.1 安装 sudo apt-get install byobu 命令安装byobu
1.2 登录启动 byobu-enable 表示Byobu窗口管理器将在每次文本登录时自动启动
byobu-disable 表示Byobu窗口管理器将不再在登录时自动启动
1.3 色彩提示 byobu-enable-prompt 启动Byobu的彩色提示
byobu-disable-prompt 禁用Byobu的彩色提示
2.Byobu 使用 更多相关操作可以按 F9 选项查看帮助指南 2.1 使用会话 一个会话仅仅是byobu的运行实例。会话由一组窗口组成，这些窗口基本上是shell会话，默认开启byobu只开0这一个窗口
(1) 创建窗口 F2 创建新的窗口
(2) 切换窗口 F3 回到先前窗口
F4 跳到下一个窗口
(3) 重命名窗口 F8 重新命名一个窗口
(4) 窗口操作 F5 重新加载文件
F6 释放该次对话
F7 进入 复制/回滚模式
F9 配置菜单
Ctrl + D关闭当前窗口
2.2 使用窗格 Byobu提供了将窗口分成多个窗格的功能，包括水平和垂直分割。这些允许您在同一窗口中进行多任务，而不是跨多个窗口。
(1) 创建窗格 SHIFT + F2 创建一个水平窗格
CTRL + F2 创造一个垂直窗格
(2) 切换窗格 以下三个快捷键都可以让窗格切换:
SHIFT + LEFT/RIGHT/UP/DOWN
SHIFT + F3/F4
CTRL + F3/F4
(3) 设置窗格 SHIFT + ALT + LEFT/RIGHT/UP/DOWN 调整当前窗格的大小
SHIFT + F11 切换窗格以暂时填充整个窗口
ALT + F11 永久地将窗格拆分为自己的新窗口
2.3 配置通知栏 ①.按F9进入Byobu配置菜单。
②.导航到 切换状态通知选项，然后按 ENTER
③.选择要启用或禁用的状态通知。(启用状态通知后，它们将显示在底部状态栏中，与窗口指示器一起显示。)
④.选择要启用的状态通知后，选择 应用，按 F5 才能刷新状态栏
有很多不同的通知可供选择，一些常用的通知是：
date 显示当前系统日期。
disk 显示当前磁盘空间使用情况。
hostname 显示当前系统主机名。
ip_address 显示当前系统的IP地址。
load_average 显示当前系统负载平均值。
memory 显示当前的内存使用情况。
network 显示当前的网络使用情况，发送和接收。
reboot_required 显示需要重新启动系统时的指示灯。
release 显示当前的分发版本（例如14.04）。
time 显示当前系统时间。
updates_available 在有可用更新时显示指示符。
uptime 显示当前系统正常运行时间。
whoami 显示当前登录的用户。</content></entry><entry><title>Centos8 KVM 虚拟化</title><url>/posts/kvm%E8%99%9A%E6%8B%9F%E5%8C%96/centos8-kvm-%E8%99%9A%E6%8B%9F%E5%8C%96/</url><categories><category>KVM</category></categories><tags><tag>KVM</tag><tag>Linux</tag></tags><content type="html"><![CDATA[1. 安装Centos8 1.1 下载 Centos8 镜像 下载地址： http://isoredirect.centos.org/centos/8/isos/x86_64/ 1.2 安装Centos8 1.2.1 回车
1.2.2 选择中文
1.2.3 从右到左依次点击配置，先选择安装目的地
1.2.4 配置网络
这时要等待镜像源的选择，不要认为卡了
1.2.5 来到软件选择，选择安装虚拟化主机
1.2.6 设置root密码
1.2.7 点击开始安装，并等待15分钟左右
2. 在 Centos8 上安装KVM 2.1 先检查硬件是否支持虚拟化 grep -e &#39;vmx&#39; /proc/cpuinfo #Intel CPU grep -e &#39;svm&#39; /proc/cpuinfo #AMD CPU 出现标有红色字样的字，则代表支持
2.2 确认KVM模块是否已加载到内核中 lsmod | grep kvm 2.3 安装cockpit Web控制台 cockpit是预先安装的，并在新安装的CentOS 8和RHEL 8系统上启用。 如果您没有安装它，使用下面的dnf命令进行安装。其中cockpit-machines扩展是用来管理基于Libvirt的虚拟机的
使用阿里云镜像，速度更快
$ mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup $ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo $ yum makecache $ dnf install cockpit cockpit-machines 启动cockpit socket服务
$ systemctl start cockpit.socket $ systemctl enable cockpit.socket $ systemctl status cockpit.socket 配置防火墙
$ firewall-cmd --add-service=cockpit --permanent $ firewall-cmd --reload 2.4 打开控制台 使用浏览器打开 https://服务器IP:9090/
用户名和密码和系统的一样
2.5 添加网桥 2.5.1 点击左侧控制面板中 -网络-
2.5.2 点击 -添加网桥- 选择第一个网卡后点击应用
2.6 添加虚拟机 2.6.1 点击左侧控制面板中的 -虚拟机-
2.6.2 点击 -创建虚拟机-
win7镜像我已经上传到/opt/目录下，也可以选择下载一个OS，但需要时间等待
2.6.3 点击创建好的虚拟机，编辑详细信息
这里我编辑了CPU的数量，自行发挥，之后点击安装
2.7 开启win7远程桌面 点击选择用户可以查看和添加远程连接的用户
]]></content></entry><entry><title>Cloudflare WARP解锁NetFlix</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/cloudflare-warp%E8%A7%A3%E9%94%81netflix/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag></tags><content type="html"><![CDATA[1. 检测是否解锁 #项目地址：https://github.com/sjlleo/netflix-verify #下载检测解锁程序 wget -O nf https://github.com/sjlleo/netflix-verify/releases/download/v3.1.0/nf_linux_amd64 &amp;&amp; chmod +x nf #执行 ./nf #通过代理执行 ./nf -proxy socks5://127.0.0.1:40000 2. WARP安装 github地址： https://github.com/P3TERX/warp.sh 使用文档地址： https://p3terx.com/archives/cloudflare-warp-configuration-script.html 使用以下命令一把梭后将自动安装 WARP 官方客户端并开启 SOCKS5 代理端口 (127.0.0.1:40000)：
# 自动配置 WARP 官方客户端 SOCKS5 代理 bash &lt;(curl -fsSL git.io/warp.sh) s5 执行以下命令显示功能菜单和贴心的状态显示：
# Cloudflare WARP 一键配置脚本 功能菜单 bash &lt;(curl -fsSL git.io/warp.sh) menu 3. 通过WARP代理再次检测是否解锁 ./nf -proxy socks5://127.0.0.1:40000 #查询代理后的IP地址： curl ifconfig.me --proxy socks5://127.0.0.1:40000 4. 配置Xray分流 替换掉文本域中的内容后，重启面板 { &#34;api&#34;: { &#34;services&#34;: [ &#34;HandlerService&#34;, &#34;LoggerService&#34;, &#34;StatsService&#34; ], &#34;tag&#34;: &#34;api&#34; }, &#34;inbounds&#34;: [ { &#34;listen&#34;: &#34;127.0.0.1&#34;, &#34;port&#34;: 62789, &#34;protocol&#34;: &#34;dokodemo-door&#34;, &#34;settings&#34;: { &#34;address&#34;: &#34;127.0.0.1&#34; }, &#34;tag&#34;: &#34;api&#34; } ], &#34;outbounds&#34;: [ { &#34;protocol&#34;: &#34;freedom&#34;, &#34;settings&#34;: {} }, { &#34;tag&#34;: &#34;netflix_proxy&#34;, &#34;protocol&#34;: &#34;socks&#34;, &#34;settings&#34;: { &#34;servers&#34;: [ { &#34;address&#34;: &#34;127.0.0.1&#34;, &#34;port&#34;: 40000 } ] } }, { &#34;protocol&#34;: &#34;blackhole&#34;, &#34;settings&#34;: {}, &#34;tag&#34;: &#34;blocked&#34; } ], &#34;policy&#34;: { &#34;system&#34;: { &#34;statsInboundDownlink&#34;: true, &#34;statsInboundUplink&#34;: true } }, &#34;routing&#34;: { &#34;rules&#34;: [ { &#34;type&#34;: &#34;field&#34;, &#34;outboundTag&#34;: &#34;netflix_proxy&#34;, &#34;domain&#34;: [ &#34;geosite:netflix&#34;, &#34;geosite:disney&#34;, &#34;geosite:category-porn&#34; ] }, { &#34;inboundTag&#34;: [ &#34;api&#34; ], &#34;outboundTag&#34;: &#34;api&#34;, &#34;type&#34;: &#34;field&#34; }, { &#34;ip&#34;: [ &#34;geoip:private&#34; ], &#34;outboundTag&#34;: &#34;blocked&#34;, &#34;type&#34;: &#34;field&#34; }, { &#34;outboundTag&#34;: &#34;blocked&#34;, &#34;protocol&#34;: [ &#34;bittorrent&#34; ], &#34;type&#34;: &#34;field&#34; } ] }, &#34;stats&#34;: {} } 重启面板后不通过代理再次检测
./nf 原来的xray配置
{ &#34;api&#34;: { &#34;services&#34;: [ &#34;HandlerService&#34;, &#34;LoggerService&#34;, &#34;StatsService&#34; ], &#34;tag&#34;: &#34;api&#34; }, &#34;inbounds&#34;: [ { &#34;listen&#34;: &#34;127.0.0.1&#34;, &#34;port&#34;: 62789, &#34;protocol&#34;: &#34;dokodemo-door&#34;, &#34;settings&#34;: { &#34;address&#34;: &#34;127.0.0.1&#34; }, &#34;tag&#34;: &#34;api&#34; } ], &#34;outbounds&#34;: [ { &#34;protocol&#34;: &#34;freedom&#34;, &#34;settings&#34;: {} }, { &#34;protocol&#34;: &#34;blackhole&#34;, &#34;settings&#34;: {}, &#34;tag&#34;: &#34;blocked&#34; } ], &#34;policy&#34;: { &#34;system&#34;: { &#34;statsInboundDownlink&#34;: true, &#34;statsInboundUplink&#34;: true } }, &#34;routing&#34;: { &#34;rules&#34;: [ { &#34;inboundTag&#34;: [ &#34;api&#34; ], &#34;outboundTag&#34;: &#34;api&#34;, &#34;type&#34;: &#34;field&#34; }, { &#34;ip&#34;: [ &#34;geoip:private&#34; ], &#34;outboundTag&#34;: &#34;blocked&#34;, &#34;type&#34;: &#34;field&#34; }, { &#34;outboundTag&#34;: &#34;blocked&#34;, &#34;protocol&#34;: [ &#34;bittorrent&#34; ], &#34;type&#34;: &#34;field&#34; } ] }, &#34;stats&#34;: {} } ]]></content></entry><entry><title>Debian Locale问题</title><url>/posts/linux%E6%93%8D%E4%BD%9C/debian-locale%E9%97%AE%E9%A2%98/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>疑难杂症</tag></tags><content type="html">Debian locale问题 问题 root@debian:~# locale -a locale: Cannot set LC_CTYPE to default locale: No such file or directory locale: Cannot set LC_MESSAGES to default locale: No such file or directory locale: Cannot set LC_COLLATE to default locale: No such file or directory C C.UTF-8 POSIX zh_CN.utf8 -bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8) 解决办法 sudo localedef -i en_US -f UTF-8 en_US.UTF-8</content></entry><entry><title>Debian安装MySQL</title><url>/posts/mysql/debian-%E5%AE%89%E8%A3%85-mysql/</url><categories><category>MySQL</category></categories><tags><tag>MySQL</tag></tags><content type="html"><![CDATA[1. 将 MySQL APT 存储库添加到系统 wget http://repo.mysql.com/mysql-apt-config_0.8.13-1_all.deb sudo dpkg -i mysql-apt-config_0.8.13-1_all.deb # 或者 apt-get install ./mysql-apt-config_0.8.13-1_all.deb 选择第一个，按 Tabel 键到确定进行版本的选择，这里选择了5.7，之后来到OK选择，按Table键确定后退出
2. 更新软件包，并安装MySql sudo apt-get update sudo apt install mysql-server 3. 安装过程中会要求输入root密码 4. 创建用户并授权 use mysql create user &#39;colzry&#39;@&#39;%&#39; identified by &#39;colzry_admin&#39;; grant all on *.* to &#39;colzry&#39;@&#39;%&#39;; flush privileges; 5. 将本地登录改为可远程登录 use mysql; // 其中user_name为要更改的用户名 update user set host=&#39;%&#39; where user = &#39;user_name&#39;; // 刷新权限 flush privileges; 5.1还需修改配置文件
vim /etc/mysql/mysql.conf.d/mysqld.cnf 6. 更改密码 // 法一 // user_name为要更改的用户名 new_passwd为要更改的密码 set password for user_name@localhost = password(&#39;new_passwd&#39;); // 法二 // name为要更改的用户名 new_passwd为要更改的密码 set password=password(&#39;new_passwd&#39;); grant all on *.* to &#39;user_name&#39;@&#39;%&#39; identified by &#39;new_passwd&#39;; flush privileges; 7. 卸载 apt-get remove --purge &#39;mysql-.*&#39; apt-get remove --purge &#39;mysql-server.*&#39; ]]></content></entry><entry><title>Debian编译网卡驱动(I219-V)</title><url>/posts/linux%E6%93%8D%E4%BD%9C/debian%E7%BC%96%E8%AF%91%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8i219-v/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>疑难杂症</tag></tags><content type="html">换源 bash &amp;lt;(curl -sSL https://gitee.com/SuperManito/LinuxMirrors/raw/main/ChangeMirrors.sh) 1. 下载网卡驱动 下载e1000e网卡驱动，下载地址 https://downloadcenter.intel.com/zh-cn/download/15817?_ga=1.159975677.114505945.1484457019 2. 配置编译环境 # 查看内核版本 uname -r # 去华农镜像下载对应的linux-headers curl -O https://mirrors.scau.edu.cn/proxmox/debian/dists/bullseye/pve-no-subscription/binary-amd64/pve-headers-5.15.30-2-pve_5.15.30-3_amd64.deb # 安装linux-headers dpkg -i pve-headers-5.15.30-2-pve_5.15.30-3_amd64.deb # 安装编译工具链 sudo apt install build-essential build-essential 包含了以下编译环境
$ apt-cache depends build-essential build-essential |Depends: libc6-dev Depends: &amp;lt;libc-dev&amp;gt; libc6-dev Depends: gcc Depends: g++ Depends: make make-guile Depends: dpkg-de RedHat 安装 yum install make automake gcc gcc-c++ kernel-devel 3. 开始编译 cd e1000e-3.8.5/src make install 若编译报错
common.mk:82: *** Kernel header files not in any of the expected locations. common.mk:83: *** Install the appropriate kernel development package, e.g. common.mk:84: *** kernel-devel, for building kernel modules and try again. Stop. 安装内核源码
sudo apt-get install linux-headers-$(uname -r) 若上面的安装失败，安装通用内核替代
sudo apt-get install linux-headers-generic 创建软连接
ln -s /usr/src/linux-headers-5.4.0-65-generic /usr/src/linux</content></entry><entry><title>entity、bo、vo、po、dto、pojo如何理解和区分</title><url>/posts/java/entitybovopodtopojo%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%92%8C%E5%8C%BA%E5%88%86/</url><categories><category>Java</category></categories><tags><tag>Java</tag></tags><content type="html">Entity 最常用实体类，基本和数据表一一对应，一个实体一张表。
Bo(business object) 代表业务对象的意思，Bo就是把业务逻辑封装为一个对象（注意是逻辑，业务逻辑），这个对象可以包括一个或多个其它的对象。通过调用Dao方法，结合Po或Vo进行业务操作。
形象描述为一个对象的形为和动作，当然也有涉及到基它对象的一些形为和动作。比如处理一个人的业务逻辑，该人会睡觉，吃饭，工作，上班等等行为，还有可能和别人发关系的行为，处理这样的业务逻辑时，我们就可以针对BO去处理。
再比如投保人是一个Po，被保险人是一个Po，险种信息也是一个Po等等，他们组合起来就是一张保单的Bo。
Vo(value object) 代表值对象的意思，通常用于业务层之间的数据传递，由new创建，由GC回收。
主要体现在视图的对象，对于一个WEB页面将整个页面的属性封装成一个对象，然后用一个VO对象在控制层与视图层进行传输交换。
Po(persistant object) 代表持久层对象的意思，对应数据库中表的字段，数据库表中的记录在java对象中的显示状态，最形象的理解就是一个PO就是数据库中的一条记录。
好处是可以把一条记录作为一个对象处理，可以方便的转为其它对象。Vo和Po，都是属性加上属性的get和set方法；表面看没什么不同，但代表的含义是完全不同的。
Dto(data transfer object) 代表数据传输对象的意思
是一种设计模式之间传输数据的软件应用系统，数据传输目标往往是数据访问对象从数据库中检索数据
数据传输对象与数据交互对象或数据访问对象之间的差异是一个以不具任何行为除了存储和检索的数据（访问和存取器）
简而言之，就是接口之间传递的数据封装
表里面有十几个字段：id，name，gender（M/F)，age……
页面需要展示三个字段：name，gender(男/女)，age
DTO由此产生，一是能提高数据传输的速度(减少了传输字段)，二能隐藏后端表结构
Pojo(plian ordinary java object) 代表简单无规则java对象
纯的传统意义的java对象，最基本的Java Bean只有属性加上属性的get和set方法
可以额转化为PO、DTO、VO；比如POJO在传输过程中就是DTO
Dao(data access object) 代表数据访问对象的意思，是sun的一个标准j2ee设计模式的接口之一，负责持久层的操作 。这个基本都了解，Dao和上面几个O区别最大，基本没有互相转化的可能性和必要，主要用来封装对数据的访问，注意，是对数据的访问，不是对数据库的访问。
Controller 代表控制层，主要是Action/Servlet等构成（Spring MVC则是通过@Controller标签使用）此层业务层与视图层打交道的中间层，负责传输VO对象和调用BO层的业务方法，负责视图层请求的数据处理后响应给视图层。
View 代表视图层的意思，主要是指由JSP、HTML等文件形成的显示层。
所以实际项目中，一般都是这样应用的：
控制层(controller-action)，业务层/服务层( bo-manager-service)，实体层(po-entity)，dao(dao)，视图对象(Vo-)，视图层(view-jsp/html)</content></entry><entry><title>FRP内网穿透</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/frpc%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>FRP</tag></tags><content type="html">1. 下载Frp wget https://gitpy.colzry.tk/github.com/fatedier/frp/releases/download/v0.48.0/frp_0.48.0_linux_amd64.tar.gz wget https://github.com/fatedier/frp/releases/download/v0.48.0/frp_0.48.0_linux_amd64.tar.gz 2. 服务端安装 2.1 解压文件 tar -zxvf frp_0.48.0_linux_amd64.tar.gz cd frp_0.48.0_linux_amd64/ cp frps /usr/local/bin/ 2.2 编写配置文件 mkdir /etc/frps vim /etc/frps/frps.ini [common] bind_port = 7000 token = czyadmin 2.3 启动 sudo vim /lib/systemd/system/frps.service [Unit] Description=Frp Server Service After=network.target [Service] Type=simple User=nobody Restart=on-failure RestartSec=5s ExecStart=/usr/local/bin/frps -c /etc/frps/frps.ini ExecReload=/usr/local/bin/frps reload -c /etc/frps/frps.ini LimitNOFILE=1048576 [Install] WantedBy=multi-user.target sudo systemctl daemon-reload sudo systemctl start frps.service sudo systemctl enable --now frps.service 3. 客户端安装 3.1 解压文件 tar -zxvf frp_0.44.0_linux_amd64.tar.gz cd frp_0.44.0_linux_amd64/ cp frpc /usr/local/bin/ frpc.ini 配置文件详解
[common] #远程frp服务器地址，可ip可域名 server_addr = frp02.wefinger.club #远程frp服务器通信端口 server_port = 7000 #特权密钥 token = 12345678 #http穿透 [demo-http] #穿透类型 type = http #本地监听ip local_ip = 127.0.0.1 #本地监听端口，欲穿透转发端口。 local_port = 8080 #自定义穿透域名，该域名需要解析至frp服务器。 custom_domains = testhttp.frp02.wefinger.club #https穿透 [demo-https] type = https local_ip = 127.0.0.1 local_port = 8088 custom_domains = testhttps.frp02.wefinger.club #tcp穿透，例如ssh、ftp服务 [demo-tcp] type = tcp #欲穿透地址，本地必须可访问。 local_ip = 127.0.0.1 #可批量绑定，使用`,`分隔，或者使用`-`定义端口段。 local_port = 22 #绑定远程端口，可批量绑定，使用`,`分隔，或者使用`-`定义端口段。 remote_port = 20022 #udp穿透,例如转发dns服务 [demo-udp] type = udp local_ip = 8.8.8.8 local_port = 53 remote_port = 20053 3.2 启动 配置文件根据各网站的粘贴过来就行
3.2.1 直接启动 启动
./frpc -c ./frpc.ini &amp;amp; 3.2.2 后台启动 配置后台自动启动
sudo vim /lib/systemd/system/frpc.service [Unit] Description=Frp Client Service After=network.target [Service] Type=simple User=nobody Restart=on-failure RestartSec=5s ExecStart=/usr/local/bin/frpc -c /etc/frpc/frpc.ini ExecReload=/usr/local/bin/frpc reload -c /etc/frpc/frpc.ini LimitNOFILE=1048576 [Install] WantedBy=multi-user.target sudo systemctl daemon-reload sudo systemctl start frpc.service sudo systemctl enable frpc.service 3.3 配置多个隧道 创建配置文件目录
mkdir -p /etc/frpc 打开配置文件的目录，编写对应的配置文件
cd /etc/frpc vim 102SSH.ini 配置示例如下
[common] server_addr = cn-gydx-bgp-1.openfrp.top server_port = 8120 tls_enable = true tcp_mux = true protocol = tcp user = 8022c3fe7ba2d9d8c953f899b86da17a tls_enable = true token = mnE3A8hIWapwShje dns_server = 114.114.114.114 [102UH] privilege_mode = true type = tcp local_ip = 192.168.5.102 local_port = 1022 remote_port = 60856 use_encryption = false use_compression = false 配置System服务
vim /lib/systemd/system/frpc@.service [Unit] Description=Frp Client Service After=network.target [Service] Type=simple User=nobody Restart=on-failure RestartSec=5s ExecStart=/usr/local/bin/frpc -c /etc/frpc/%i.ini ExecReload=/usr/local/bin/frpc reload -c /etc/frpc/%i.ini LimitNOFILE=1048576 [Install] WantedBy=multi-user.target 根据配置文件名称来启动服务
systemctl daemon-reload systemctl start frpc@102SSH systemctl status frpc@102SSH systemctl enable frpc@102SSH 如果您忘记了之前开启过哪些隧道，使用下面的命令可以列出当前运行中的隧道
systemctl list-units frpc@* 如果您忘记了之前设置过的自启隧道，可以使用下面的命令列出
systemctl list-units --all frpc@*</content></entry><entry><title>GitHub代理加速</title><url>/posts/git/github%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[项目地址： https://github.com/hunshcn/gh-proxy 使用cloudflare免费的代理加速 网址： https://workers.cloudflare.com 先登录或注册 将下面的放入左侧的方框中(不需要任何的改动)
&#39;use strict&#39; /** * static files (404.html, sw.js, conf.js) */ const ASSET_URL = &#39;https://hunshcn.github.io/gh-proxy/&#39; // 前缀，如果自定义路由为example.com/gh/*，将PREFIX改为 &#39;/gh/&#39;，注意，少一个杠都会错！ const PREFIX = &#39;/&#39; // 分支文件使用jsDelivr镜像的开关，0为关闭，默认关闭 const Config = { jsdelivr: 0 } const whiteList = [] // 白名单，路径里面有包含字符的才会通过，e.g. [&#39;/username/&#39;] /** @type {RequestInit} */ const PREFLIGHT_INIT = { status: 204, headers: new Headers({ &#39;access-control-allow-origin&#39;: &#39;*&#39;, &#39;access-control-allow-methods&#39;: &#39;GET,POST,PUT,PATCH,TRACE,DELETE,HEAD,OPTIONS&#39;, &#39;access-control-max-age&#39;: &#39;1728000&#39;, }), } const exp1 = /^(?:https?:\/\/)?github\.com\/.+?\/.+?\/(?:releases|archive)\/.*$/i const exp2 = /^(?:https?:\/\/)?github\.com\/.+?\/.+?\/(?:blob|raw)\/.*$/i const exp3 = /^(?:https?:\/\/)?github\.com\/.+?\/.+?\/(?:info|git-).*$/i const exp4 = /^(?:https?:\/\/)?raw\.(?:githubusercontent|github)\.com\/.+?\/.+?\/.+?\/.+$/i const exp5 = /^(?:https?:\/\/)?gist\.(?:githubusercontent|github)\.com\/.+?\/.+?\/.+$/i const exp6 = /^(?:https?:\/\/)?github\.com\/.+?\/.+?\/tags.*$/i /** * @param {any} body * @param {number} status * @param {Object&lt;string, string&gt;} headers */ function makeRes(body, status = 200, headers = {}) { headers[&#39;access-control-allow-origin&#39;] = &#39;*&#39; return new Response(body, {status, headers}) } /** * @param {string} urlStr */ function newUrl(urlStr) { try { return new URL(urlStr) } catch (err) { return null } } addEventListener(&#39;fetch&#39;, e =&gt; { const ret = fetchHandler(e) .catch(err =&gt; makeRes(&#39;cfworker error:\n&#39; + err.stack, 502)) e.respondWith(ret) }) function checkUrl(u) { for (let i of [exp1, exp2, exp3, exp4, exp5, exp6]) { if (u.search(i) === 0) { return true } } return false } /** * @param {FetchEvent} e */ async function fetchHandler(e) { const req = e.request const urlStr = req.url const urlObj = new URL(urlStr) let path = urlObj.searchParams.get(&#39;q&#39;) if (path) { return Response.redirect(&#39;https://&#39; + urlObj.host + PREFIX + path, 301) } // cfworker 会把路径中的 `//` 合并成 `/` path = urlObj.href.substr(urlObj.origin.length + PREFIX.length).replace(/^https?:\/+/, &#39;https://&#39;) if (path.search(exp1) === 0 || path.search(exp5) === 0 || path.search(exp6) === 0 || path.search(exp3) === 0 || path.search(exp4) === 0) { return httpHandler(req, path) } else if (path.search(exp2) === 0) { if (Config.jsdelivr) { const newUrl = path.replace(&#39;/blob/&#39;, &#39;@&#39;).replace(/^(?:https?:\/\/)?github\.com/, &#39;https://cdn.jsdelivr.net/gh&#39;) return Response.redirect(newUrl, 302) } else { path = path.replace(&#39;/blob/&#39;, &#39;/raw/&#39;) return httpHandler(req, path) } } else if (path.search(exp4) === 0) { const newUrl = path.replace(/(?&lt;=com\/.+?\/.+?)\/(.+?\/)/, &#39;@$1&#39;).replace(/^(?:https?:\/\/)?raw\.(?:githubusercontent|github)\.com/, &#39;https://cdn.jsdelivr.net/gh&#39;) return Response.redirect(newUrl, 302) } else { return fetch(ASSET_URL + path) } } /** * @param {Request} req * @param {string} pathname */ function httpHandler(req, pathname) { const reqHdrRaw = req.headers // preflight if (req.method === &#39;OPTIONS&#39; &amp;&amp; reqHdrRaw.has(&#39;access-control-request-headers&#39;) ) { return new Response(null, PREFLIGHT_INIT) } const reqHdrNew = new Headers(reqHdrRaw) let urlStr = pathname let flag = !Boolean(whiteList.length) for (let i of whiteList) { if (urlStr.includes(i)) { flag = true break } } if (!flag) { return new Response(&#34;blocked&#34;, {status: 403}) } if (urlStr.startsWith(&#39;github&#39;)) { urlStr = &#39;https://&#39; + urlStr } const urlObj = newUrl(urlStr) /** @type {RequestInit} */ const reqInit = { method: req.method, headers: reqHdrNew, redirect: &#39;manual&#39;, body: req.body } return proxy(urlObj, reqInit) } /** * * @param {URL} urlObj * @param {RequestInit} reqInit */ async function proxy(urlObj, reqInit) { const res = await fetch(urlObj.href, reqInit) const resHdrOld = res.headers const resHdrNew = new Headers(resHdrOld) const status = res.status if (resHdrNew.has(&#39;location&#39;)) { let _location = resHdrNew.get(&#39;location&#39;) if (checkUrl(_location)) resHdrNew.set(&#39;location&#39;, PREFIX + _location) else { reqInit.redirect = &#39;follow&#39; return proxy(newUrl(_location), reqInit) } } resHdrNew.set(&#39;access-control-expose-headers&#39;, &#39;*&#39;) resHdrNew.set(&#39;access-control-allow-origin&#39;, &#39;*&#39;) resHdrNew.delete(&#39;content-security-policy&#39;) resHdrNew.delete(&#39;content-security-policy-report-only&#39;) resHdrNew.delete(&#39;clear-site-data&#39;) return new Response(res.body, { status, headers: resHdrNew, }) } 点击保存并部署后可以点击发送测试是否成功 目前国内无法访问 *.workers.dev，需要cloudflare托管的域名反代进行CNAME解析 之后点击Worker路由-&gt; 添加路由 按照下图的形式编写进行保存即可 之后就能通过自定义的域名进行访问
终端使用方法 例如下载 Releases 文件
# 原来的使用方法 wget https://github.com/fatedier/frp/releases/download/v0.44.0/frp_0.44.0_linux_amd64.tar.gz # 代理使用方法 wget https://gitpy.colzry.tk/https://github.com/fatedier/frp/releases/download/v0.44.0/frp_0.44.0_linux_amd64.tar.gz clone也是如此
]]></content></entry><entry><title>Git的基本使用</title><url>/posts/git/git%E5%9F%BA%E6%9C%AC%E7%9A%84%E4%BD%BF%E7%94%A8/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[1. 设置签名 git config --global user.name tom #设置用户名tom git config --global user.email xxx@qq.com #设置用户邮箱 2. 创建本地仓库 $ git init 3. 版本提交 3.1 状态查看 git status #查看工作区、暂存区状态 3.2 添加 git add fileName #指定文件 git add . #所有 说明：将工作区的文件添加到暂存区 3.3 提交 git commit -m &#39;commit message&#39; 说明：将暂存区内容提交到本地库 3.4 查看历史记录 git log git reflog #常用 git log --greph #图形显示,更直观 git log --pretty=oneline #漂亮一行显示 git log --oneline #简洁显示 说明：HEAD@{移动到当前版本需要多少步} 4. 分支操作 4.1 创建分支 git branch 分支名 4.2 查看分支 git branch git branch -v 4.3 切换分支 git checkout 分支名 git checkout -b 分支名 #创建分支并直接切换到该分支 4.4 重命名分支 在当前分支
git branch -m new_branch_name 不在当前分支
git branch -m old_name new_name 4.5 合并分支 **相当于把修改了的文件拉过来**
git rebase &lt;branch&gt; 将指定的分支合并到当前分支 git merge --no-ff xxx 注意：合并分支的时候要明确谁谁合并 我在a分支里面修改了。要合并到master，就先切换到master，然后合并b 4.6 删除分支 git branch -d 分支名 5. 使用远程仓库 5.1 创建远程库地址别名 git remote -v #查看远程地址别名 git remote add 别名 远程地址 git remote set-url 别名 远程地址 例子：git remote add origin https://xx 5.2 推送 **开发修改完把本地库的文件推送到远程仓库**** ****前提是提交到了本地库才可以推送**
git push 别名 分支名 git push -u 别名 分支名 #-u指定默认主机 git push -f # 强制推送 例子：git push origin master 5.3 克隆 **完整的把远程库克隆到本地**** **克隆下来后不要在主分支里面做开发** ****clone进行一次，从无到有的过程，更新用pull**
git clone 远程地址 例子：git clone https://xx 5.4 拉取 **本地存在clone下来的文件 就用pull更新**
pull = fetch + merge git fetch 别名 分支名 git merge 别名 分支名 git pull 别名 分支名 5.5 解决冲突 注意：解决冲突后的提交是不能带文件名的 如果不是基于远程库最新版做的修改不能推送，必须先pull下来安装冲突办法解决
# 查看所有分支 git reflog # 回退到上一个版本 git rest --hard HEAD^ # 回退到上上个版本 git rest --hard HEAD^^ # 回退到commit id为ba7914b的版本 git rest --hard ba7914b git pull origin/master # 合并之后修改冲突 git diff origin/master ]]></content></entry><entry><title>Git设置代理</title><url>/posts/git/git%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[# 以下使用http代理 git config --global http.proxy http://127.0.0.1:10809 git config --global https.proxy https://127.0.0.1:10809 # 以下使用socks5代理 git config --global http.proxy socks5://127.0.0.1:10808 git config --global https.proxy socks5://127.0.0.1:10808 # 取消代理 git config --global --unset http.proxy git config --global --unset https.proxy git config --global url.&#34;https://gitpy.colzry.tk/&#34;.insteadOf https:// git config --global --remove-section url.&#34;https://gitpy.colzry.tk/&#34; ]]></content></entry><entry><title>go mod的使用</title><url>/posts/golang/go-mod/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[常用命令
# 初始化模块 cd &lt;mod_name&gt; go mod init &lt;mod_name&gt; # 删除没用的依赖，下载位拉取的依赖 go mod tidy go mod使用 | 全网最详细 ]]></content></entry><entry><title>go workspace快速使用</title><url>/posts/golang/go-workspace/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html">常用命令
# 初始化工作区 go work init [dirnames] # 添加模块 go work use [dirnames] 官方博文：Go 1.18工作区模式最佳实践 Go 1.18 workspace 使用初体验_Seekload的博客-CSDN博客</content></entry><entry><title>Gogs服务搭建</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/gogs%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>Gogs</tag></tags><content type="html">Gogs服务搭建 1. 安装 wget https://github.com/gogs/gogs/releases/download/v0.13.0/gogs_0.13.0_linux_amd64.tar.gz # 网络不好可以使用下面的 wget https://picture-czy.oss-cn-beijing.aliyuncs.com/shareFile/gogs_0.13.0_linux_amd64.tar.gz tar -zxvf gogs_0.13.0_linux_amd64.tar.gz -C /usr/local # 修改目录拥有者，如无用户先添加 U:G chown -R gogs:gogs gogs/ 无用户的先添加用户，并为用户赋予gogs目录的权限
#创建用户组 groupadd gogs #创建用户家目录 mkdir -p /home/gogs #创建用户 useradd -g gogs -d /home/gogs -s /bin/bash gogs #用户家目录赋权755 4-&amp;gt;r 2-&amp;gt;w 1-&amp;gt;x chmod -R 755 /home/gogs #修改gogs目录拥有者 chown -R gogs:gogs /usr/local/gogs/ 2. 添加守护进程 在安装目录的scripts/systemd下有官方的脚本可以参考 以下的内容经过修改，若启动不成功可以尝试更改custom/conf/目录下的配置文件
vim /lib/systemd/system/gogs.service [Unit] Description=Gogs After=syslog.target After=network.target [Service] Type=simple User=gogs Group=gogs WorkingDirectory=/usr/local/gogs ExecStart=/usr/local/gogs/gogs web Restart=always Environment=USER=gogs HOME=/home/gogs [Install] WantedBy=multi-user.target systemctl daemon-reload systemctl start gogs.service systemctl status gogs.service systemctl enable gogs.service --now</content></entry><entry><title>Golang1.18泛型新特性</title><url>/posts/golang/1.18-%E6%B3%9B%E5%9E%8B%E6%96%B0%E7%89%B9%E6%80%A7/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"> Go 1.18 泛型全面讲解：一篇讲清泛型的全部</content></entry><entry><title>Go语言快速上手</title><url>/posts/golang/go%E8%AF%AD%E8%A8%80%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[在Linux上安装GoLang wget https://golang.google.cn/dl/go1.19.1.linux-amd64.tar.gz rm -rf /usr/local/go &amp;&amp; tar -C /usr/local -xzf go1.19.1.linux-amd64.tar.gz echo &#39;export PATH=$PATH:/usr/local/go/bin&#39; &gt;&gt; $HOME/.profile source $HOME/.profile go version go env -w GO111MODULE=on go env -w GOPROXY=https://goproxy.cn,direct 在Windows上安装GoLang 官网地址 国内镜像地址 下载.msi文件安装后，配置环境变量
将安装的Go\bin 目录添加到 Path 环境变量中
将工作目录也添加到环境变量中
确认之后检查是否成功
配置开发环境 配置「七牛云」的代理服务
$ go env -w GO111MODULE=on $ go env -w GOPROXY=https://goproxy.cn,direct 配置工作路径
go env -w GOPATH=C:\WorkDir\Go # 这是我的工作路径，填自己的 打开vscode安装GO语言的插件
之后工作目录下新建一个src目录，在该目录下创建xxx.go文件，根据vscode的提示安装所有的包
变量的声明 // 法一 var num int = 100 var str string = &#34;123&#34; // 法二 知道变量的值后可以不用声明属性 var num = 100 var str = &#34;123&#34; // 法三 此方法只能用在局部变量中 num := 100 str := &#34;123&#34; // 多行声明 var num, str = 100, &#34;123&#34; var ( num = 100 str = &#34;123&#34; ) num, str := 100, &#34;123&#34; 常量的定义 // 常量只读，不允许修改 const num int = 100 // const 用来定义枚举类型 const ( // 可以在 const() 中添加关键字 iota(也只能在const 中使用), iota 会自增，第一行默认为 1 January = iota // iota = 0 February // iota = 1 March // iota = 2 April // iota = 3 May // ... ... June July ) 函数的返回值 package main import &#34;fmt&#34; // 1个匿名返回值 func demo1(a int) int { b := a * 2 return b } // 2个匿名返回值 func demo2(a int, b int) (int, int) { return a * 2, b * 3 } // 不匿名的返回 func demo3(a int, b int) (r1 int, r2 int) { r1 = a * 2 r2 = b * 3 return } func demo4(a int, b int) (r1, r2 int){ } func main() { ret1 := demo1(10) fmt.Printf(&#34;ret1 = %d\n&#34;, ret1) ret2, ret3 := demo2(10, 20) fmt.Printf(&#34;ret2 = %d, ret3 = %d\n&#34;, ret2, ret3) ret4, ret5 := demo3(100, 200) fmt.Printf(&#34;ret4 = %d, ret5 = %d\n&#34;, ret4, ret5) } init() 函数和import // 程序会先执行最里面的包的init()方法 **注意：**函数名开头大写表示函数是public, 小写表示函数是private
import ( _ &#34;$GOPATH/xxx/xxx&#34; // 匿名导包，不调用也会执行init() name &#34;$GOPATH/xxx/xxx&#34; // 起别名 . &#34;$GOPATH/xxx/xxx&#34; // 导入到当前程序中，可直接使用包内的方法 ) defer 语句的调用顺序 defer在函数的生命周期结束后调用(在return之后)，遵循先进后出原则
package main import &#34;fmt&#34; func fun1() { fmt.Println(&#34;this is fun1 called&#34;) } func fun2() int { fmt.Println(&#34;this is fun2 called&#34;) return fun3() } func fun3() int { fmt.Println(&#34;this is fun3 called&#34;) return 0 } func main() { defer fun1() defer fun2() } /* 结果 this is fun2 called this is fun3 called this is fun1 called */ 静态数组和动态数值 // 静态数组，上来就声明长度或者内容,有着固定长度 arr1 := [4]int{1,2,3,4} arr2 := [10]int{1,2,3,4} // 前四有值，后面的全为0 var arr3 [5]int // 定义五个为0的数组 // 动态数组没有固定的长度，也叫 切片 (其本质为指针) slice := []int{1,2,3} // 默认值 1 2 3 长度为3 len=3 , cap = 3 slice1 := make([]int, len, cap) // len &lt;= cap slice2 := make([]int, 3) // len = 3, cap = 3 // 切片的追加 slice1 = append(slice1, 1) // 向slice1追加一个值为1的元素 // 若向一个容量已满的切片追加，则会新建一个之前两倍容量的切片， // 之后将旧的切片赋值给新的切片，在新的切片上进行追加 // 切片的截取 slice4 := []int{1,2,3,4,5,6} // 若修改num，则slice4也会改变 浅拷贝 num := slice4[0:3] // 左闭右开 [:2] [1:] // 深拷贝 num2 := make([]int, 3) copy(num2, slice4) map的使用 和切片一样，是动态的，要分配空间
|-&gt;值 mymap := make(map[int]string, 10) // map[key]value / cap = 10 |-&gt; 键 mymap[0] = &#34;Jun&#34; mymap[1] = &#34;xxx&#34; ... ... mymap1 := make(map[int]string) // 可以不加容量 mymap := map[string]string{ &#34;one&#34;: &#34;Jun&#34;, &#34;tow&#34;: &#34;Fer&#34;, &#34;key&#34;: &#34;vlaue&#34; } // 删除 delete(mymap, &#34;key&#34;) // 遍历 for key, value := range mymap { fmt.Println(&#34;key = &#34;, key) fmt.Println(&#34;value = &#34;, value) } **注意：**map 和 切片 传参时传的是指针，因此改变值时，原来的也会改变
结构体 // 大写表示public 小写表示private type book struct{ name string autoh string price int } type Student struct { Name string Gender string Age int8 } 结构体之间的嵌套可以看作继承 type Personal struct { Name string Age int Gender string } // Student 继承 Personal type Student struct { Personal Classroom string } // 与结构体绑定方法 // 父类的方法 func (p Personal) Run() { fmt.Println(p.Name + &#34;在奔跑~~~~~~~~&#34;) } // 子类的方法 func (t Student) HaveClass() { fmt.Println(t.Name + &#34;在&#34; + t.Classroom + &#34;上课&#34;) } func main() { var s = Student{ Personal: Personal{ &#34;Colzry&#34;, 21, &#34;男&#34;, }, Classroom: &#34;16班&#34;, } fmt.Printf(&#34;%#v\n&#34;, s) // 调用父类的方法 s.Run() // 调用自己的方法 s.HaveClass() } 接口 使用接口来规范结构体的方法 package main import &#34;fmt&#34; //定义一个接口 type Operate interface { start() stop() } type Phone struct { Name string } // 让结构体实现接口 func (p Phone) start() { fmt.Println(p.Name + &#34;开机&#34;) } func (p Phone) stop() { fmt.Println(p.Name + &#34;关机&#34;) } func main() { // 实例化接口 var redmi Operate = Phone{Name: &#34;RedMi k40&#34;} // 调用实现的方法 redmi.start() redmi.stop() } 使用空接口来做泛型 var a interface{} a = 20 fmt.Printf(&#34;a的值: %v, a的类型: %T\n&#34;, a, a) a = &#34;Colzry&#34; fmt.Printf(&#34;a的值: %v, a的类型: %T\n&#34;, a, a) a = true fmt.Printf(&#34;a的值: %v, a的类型: %T\n&#34;, a, a) a = []int{1, 2, 3} fmt.Printf(&#34;a的值: %v, a的类型: %T\n&#34;, a, a) b := make(map[interface{}]interface{}) b[4] = true b[&#34;str&#34;] = 25 fmt.Println(b) c := []interface{}{1, 2, &#34;3&#34;, true} fmt.Println(c) ######## 打印 ########## a的值: 20, a的类型: int a的值: Colzry, a的类型: string a的值: true, a的类型: bool a的值: [1 2 3], a的类型: []int map[4:true str:25] [1 2 3 true] 常用在函数的参数和返回值处
func getObj(value interface{}) interface{} { return value } 类型断言 package main import &#34;fmt&#34; // 类型断言 func TypePrint(value interface{}) { // 两种判断类型的方法(if switch)，但是switch只能使用 x.(type) if _, ok := value.(string); ok { fmt.Println(&#34;它居然是个字符串&#34;) } else { fmt.Println(&#34;可惜它不是字符串&#34;) } switch value.(type) { case int: fmt.Println(&#34;int类型&#34;) case string: fmt.Println(&#34;string类型&#34;) case bool: fmt.Println(&#34;bool类型&#34;) case []int: fmt.Println(&#34;[]int类型&#34;) default: fmt.Println(&#34;不在列表范围内&#34;) } } func main() { a := 20 TypePrint(a) b := &#34;Colzry&#34; TypePrint(b) } 打印
可惜它不是字符串 int类型 它居然是个字符串 string类型 协程 使用关键字go可以将一个方法(函数)作为协程来使用
func main() { go test() for i := 0; i &lt; 10; i++ { fmt.Println(&#34;main ---------------&#34;, i) time.Sleep(time.Millisecond * 500) } } func test() { for i := 0; i &lt; 10; i++ { fmt.Println(&#34;test ---------------&#34;, i) time.Sleep(time.Millisecond * 1000) } } 这样main函数和test函数就能同时运行，但会出现一个问题，main函数会因为先结束而导致test函数没运行完就结束了，这时需要使用异步
import ( &#34;fmt&#34; &#34;sync&#34; &#34;time&#34; ) var wg sync.WaitGroup func main() { wg.Add(1) // 添加一个协程 go test() // 启动一个协程 for i := 0; i &lt; 10; i++ { fmt.Println(&#34;main ---------------&#34;, i) time.Sleep(time.Millisecond * 500) } wg.Wait() // 等待所有协程执行完 } func test() { for i := 0; i &lt; 10; i++ { fmt.Println(&#34;test ---------------&#34;, i) time.Sleep(time.Millisecond * 1000) } wg.Done() // 完成一个协程 } Add, Wait, Done 需要一起出现 管道 使用关键字chan定义一个管道(注意：管道也是地址引用型)
var ch chan int // 类型为 int 型 ch = make(chan int, 10) // 给管道ch分配10个空间 ch &lt;- 10 // 将10写入管道ch中 value := &lt;- ch // 取出管道中的第一个值，也可匿名取出 &lt;- ch close(ch) // 关闭管道 管道中的值遵循先进先出，一旦没有导致取不出或者满了导致放不了都会报错，错误如下
fatal error: all goroutines are asleep - deadlock! 使用for range 遍历管道时要先关闭管道
func main() { ch := make(chan int, 10) for i := 0; i &lt; 10; i++ { ch &lt;- i } close(ch) for v := range ch{ fmt.Println(v) } } 单向管道
chan&lt;- // 只写 &lt;-chan // 只读 ch1 = make(chan&lt;- int, 10) // 只写的int管道 ch2 = make(&lt;-chan int, 10) // 只读的int管道 // 形参表示 func fn1(ch chan&lt;- int){} func fn2(ch &lt;-chan int){} 管道和线程的使用 package main import ( &#34;fmt&#34; &#34;sync&#34; &#34;time&#34; ) var wg sync.WaitGroup func fn1(ch chan int){ for i := 1; i &lt;= 10; i++ { ch &lt;- i fmt.Println(&#34;写入&#34;, i, &#34;成功&#34;) time.Sleep(time.Millisecond * 100) } close(ch) wg.Done() } func fn2(ch chan int) { for v := range ch{ fmt.Println(&#34;读取&#34;, v, &#34;成功&#34;) time.Sleep(time.Millisecond * 10) } wg.Done() } func main() { ch := make(chan int, 10) wg.Add(2) go fn1(ch) go fn2(ch) wg.Wait() } package main import ( &#34;fmt&#34; &#34;sync&#34; ) var wg sync.WaitGroup func putNum(numChan chan int) { for i := 2; i &lt;= 1200000; i++ { numChan &lt;- i } close(numChan) wg.Done() } func getPrime(numChan chan int, primeChan chan int, exitChan chan bool) { for num := range numChan { flag := true for i := 2; i &lt; num; i++ { if num % i == 0 { flag = false break } } if flag { primeChan &lt;- num } } // 存放素数管道完成数 +1 exitChan &lt;- true wg.Done() } func printPrime(primeChan chan int) { for v := range primeChan{ fmt.Println(v) } wg.Done() } func main() { numChan := make(chan int, 1000) // 存放数字的管道 primeChan := make(chan int, 1000) // 存放素数的管道 exitChan := make(chan bool, 16) // 存放素数管道完成数 count := 20 // 判断素数的协程数 wg.Add(1) go putNum(numChan) for i := 0; i &lt; count; i++ { wg.Add(1) go getPrime(numChan, primeChan, exitChan) } wg.Add(1) go printPrime(primeChan) wg.Add(1) go func() { for i := 0; i &lt; count; i++ { &lt;- exitChan // 存放素数管道完成数 -1 } // 判断存放素数管道完成数都运行完后关闭管道 close(primeChan) wg.Done() }() wg.Wait() fmt.Println(&#34;执行结束......&#34;) } 多路复用 多路复用使用select关键字，通常搭配for使用，让case中的代码随机的执行，也叫并发
package main import &#34;fmt&#34; func main() { intChan := make(chan int, 10) strChan := make(chan string, 10) for i := 0; i &lt; 10; i++ { intChan &lt;- i strChan &lt;- &#34;hello&#34; + fmt.Sprint(i) } for { select { case v := &lt;- intChan: fmt.Println(&#34;intChan 读取的数据&#34;, v) case v := &lt;-strChan: fmt.Println(&#34;strChan 读取的数据&#34;, v) default: fmt.Println(&#34;结束&#34;) return } } } goroutine异常处理 使用defer + recover进行异常捕获
defer func(){ if err := recover(); err != nil { fmt.Println(&#34;发生错误&#34;, err) } }() package main import ( &#34;fmt&#34; &#34;time&#34; ) func fn1() { defer func(){ if err := recover(); err != nil { fmt.Println(&#34;发生错误&#34;, err) } }() var name map[int]string name[0] = &#34;test&#34; } func fn2() { for i := 0; i &lt; 10; i++ { fmt.Println(&#34;hell0&#34;, i) } } func main() { go fn1() go fn2() time.Sleep(time.Second * 5) } ]]></content></entry><entry><title>iperf3的使用</title><url>/posts/linux%E6%93%8D%E4%BD%9C/iperf3%E7%9A%84%E4%BD%BF%E7%94%A8/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html">1. 安装 1.1 linux # Debian sudo apt install iperf3 -y # Centos sudo yum install iperf3 -y 1.2 windows 官网下载地址 2. 使用 2.1 详细命令参数 -p, --port #，Server 端监听、Client 端连接的端口号； -f, --format [kmgKMG]，报告中所用的数据单位，Kbits, Mbits, KBytes, Mbytes； -i, --interval #，每次报告的间隔，单位为秒； -F, --file name，测试所用文件的文件名。如果使用在 Client 端，发送该文件用作测试；如果使用在 Server 端，则是将数据写入该文件，而不是丢弃； -A, --affinity n/n,m，设置 CPU 亲和力； -B, --bind ，绑定指定的网卡接口； -V, --verbose，运行时输出更多细节； -J, --json，运行时以 JSON 格式输出结果； --logfile f，输出到文件； -d, --debug，以 debug 模式输出结果； -v, --version，显示版本信息并退出； -h, --help，显示帮助信息并退出。 Server 端参数： -s, --server，以 Server 模式运行； -D, --daemon，在后台以守护进程运行； -I, --pidfile file，指定 pid 文件； -1, --one-off，只接受 1 次来自 Client 端的测试，然后退出。 Client 端参数 -c, --client ，以 Client 模式运行，并指定 Server 端的地址； -u, --udp，以 UDP 协议进行测试； -b, --bandwidth #[KMG][/#]，限制测试带宽。UDP 默认为 1Mbit/秒，TCP 默认无限制； -t, --time #，以时间为测试结束条件进行测试，默认为 10 秒； -n, --bytes #[KMG]，以数据传输大小为测试结束条件进行测试； -k, --blockcount #[KMG]，以传输数据包数量为测试结束条件进行测试； -l, --len #[KMG]，读写缓冲区的长度，TCP 默认为 128K，UDP 默认为 8K； --cport ，指定 Client 端运行所使用的 TCP 或 UDP 端口，默认为临时端口； -P, --parallel #，测试数据流并发数量； -R, --reverse，反向模式运行（Server 端发送，Client 端接收）； -w, --window #[KMG]，设置套接字缓冲区大小，TCP 模式下为窗口大小； -C, --congestion ，设置 TCP 拥塞控制算法（仅支持 Linux 和 FreeBSD ）； -M, --set-mss #，设置 TCP/SCTP 最大分段长度（MSS，MTU 减 40 字节）； -N, --no-delay，设置 TCP/SCTP no delay，屏蔽 Nagle 算法； -4, --version4，仅使用 IPv4； -6, --version6，仅使用 IPv6； -S, --tos N，设置 IP 服务类型（TOS，Type Of Service）； -L, --flowlabel N，设置 IPv6 流标签（仅支持 Linux）； -Z, --zerocopy，使用 “zero copy”（零拷贝）方法发送数据； -O, --omit N，忽略前 n 秒的测试； -T, --title str，设置每行测试结果的前缀； --get-server-output，从 Server 端获取测试结果； --udp-counters-64bit，在 UDP 测试包中使用 64 位计数器（防止计数器溢出）。 2.2 简单使用例子 # 示例1 正向测试 # Server iperf3 -s # Client iperf3 -c Server_IP地址 # 示例2 反向测试 iperf3 -s # Client iperf3 -c Server_IP地址 -R # 示例3 # Server iperf3 -s # Client iperf3 -c Server_IP地址 -b 1000M -t 60 -d -c 为客户端运行并要指定服务端的IP地址 -b 表示使用的测试带宽 -t 表示以时间为测试结束条件进行测试，默认为 10 秒 -d 打印出更详细的debug调试信息</content></entry><entry><title>Java多线程同步锁</title><url>/posts/java/java-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E9%94%81/</url><categories><category>Java</category></categories><tags><tag>Java</tag></tags><content type="html"><![CDATA[ 同步监视器必须为唯一的对象
例如：this, *.class
若使用*.class时，报以下错误
则原因为： 线程操作的wait()、notify()、notifyAll()方法只能在同步控制方法或同步控制块内调用。如果在非同步控制方法或控制块里调用，程序能通过编译，但运行的时候，将得到 java.lang.IllegalMonitorStateException 异常，并伴随着一些含糊信息，比如 current thread is not owner(当前线程不是拥有者)。其实异常的含义是 调用wait()、notify()、notifyAll()的任务在调用这些方法前必须 ‘拥有’（获取）对象的锁。
解决方法： 在wait()、notify()、notifyAll()方法调用是加上调用的对象，例如：*.class.wait();
具体实现 使用两个线程间隔递增的打印0到100
使用*.class同步监视器 public class demo implements Runnable{ public static int number = 0; @Override public void run() { while (true) { synchronized (demo.class) { demo.class.notify(); if (number &lt;= 100) { try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + &#34; : &#34; + number++); try { demo.class.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } else { System.exit(0); } } } } public static void main(String[] args) { demo demo = new demo(); Thread thread1 = new Thread(demo); Thread thread2 = new Thread(demo); thread1.setName(&#34;线程1&#34;); thread2.setName(&#34;线程2&#34;); thread1.start(); thread2.start(); } } 使用this同步监视器 public class demo implements Runnable{ public static int number = 0; @Override public void run() { while (true) { synchronized (this) { this.notify(); if (number &lt;= 100) { try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + &#34; : &#34; + number++); try { this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } else { System.exit(0); } } } } public static void main(String[] args) { demo demo = new demo(); Thread thread1 = new Thread(demo); Thread thread2 = new Thread(demo); thread1.setName(&#34;线程1&#34;); thread2.setName(&#34;线程2&#34;); thread1.start(); thread2.start(); } } ]]></content></entry><entry><title>Jupyter lab安装和配置</title><url>/posts/python/jupyter-lab-%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/</url><categories><category>Python</category></categories><tags><tag>Python</tag><tag>Jupyter</tag></tags><content type="html"><![CDATA[
通过pip安装 若没有pip可以先安装
sudo apt-get install python3-pip 安装 jupyter-lab
pip install jupyterlab 安装中文环境包
pip install jupyterlab-language-pack-zh-CN 配置局域网可以访问 先查看配置文件的位置
jupyter-lab --generate-config 编辑配置文件
sudo vim ~/.jupyter/jupyter_lab_config.py 找到下面的配置，取消注释并修改成下面的样子(可通过****进行查找)，保存后退出
**注意：**取消注释也要把注释后面的空格取消，不然启动时会报错
c.ServerApp.ip = &#39;*&#39; # 下面的设置为可选的，不想设置的可以跳过(要通过root用户进行设置/普通用户和root用户的配置目录不一样) # 设置默认打开的目录 c.ServerApp.root_dir = &#39;/home/debian/&#39; # 允许root用户运行登录 c.ServerApp.allow_root = True # 允许远程访问 c.ServerApp.allow_remote_access = True 设置jupyter-lab网页的密码 jupyter-lab password 密码要输入两次
设置中文 启动jupyter-lab
jupyter lab 在浏览器中输入 http://主机ip:8888/lab 访问
进入后输入刚才设置的密码，进入主页面后设置中文
插件安装 pip install ipympl pip install jupyterlab_github pip install nglview 自动补全插件安装
pip install &#34;jupyterlab-kite&gt;=2.0.2&#34; bash -c &#34;$(wget -q -O - https://linux.kite.com/dls/linux/current)&#34; 安装主题 pip install jupyterthemes # 主题安装 jt -l # 显示可用主题 jt -t chosen_theme # 切换主题 查看主题，携带的主题有7个：
onedork grade3 oceans16 chesterish monokai solarizedl solarizedd 设置开机自启动 以服务的形式，配置开机启动项
vim /etc/systemd/system/jupyter.service 添加如下代码：
[Unit] Description=Jupyter Notebook After=network.target [Service] Type=simple ExecStart=/usr/local/bin/jupyter-lab --config=/root/.jupyter/jupyter_server_config.json --no-browser User=root Group=root WorkingDirectory=/root/workDir Restart=always RestartSec=10 [Install] WantedBy=multi-user.target 设置自启动
sudo systemctl enable jupyter sudo systemctl start jupyter 安装Java内核 sudo apt install openjdk-8-jre-headless sudo apt install openjdk-8-jdk-headless 查看Java版本
java -version 安装IJava
wget https://github.com/SpencerPark/IJava/releases/download/v1.3.0/ijava-1.3.0.zip unzip ijava-1.3.0.zip python3 install.py --sys-prefix 查看内核
jupyter kernelspec list 对应的web页面也有了
]]></content></entry><entry><title>LambdaQueryWrapper使用</title><url>/posts/java/lambdaquerywrapper%E4%BD%BF%E7%94%A8/</url><categories><category>Java</category></categories><tags><tag>Java</tag></tags><content type="html"><![CDATA[// eq用法 LambdaQueryWrapper&lt;News&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;(); queryWrapper.eq(News::getNid, nid); News news = newsService.getOne(queryWrapper); // select用法 LambdaQueryWrapper&lt;User&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;(); queryWrapper.eq(User::getUid, uid).select(User::getUid, User::getUsername, User::getIsVip); User user = userService.getOne(queryWrapper); // and用法 Page&lt;User&gt; userPage = new Page&lt;&gt;(pageParam.getPage(), pageParam.getPageSize()); LambdaQueryWrapper&lt;User&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;(); queryWrapper.eq(User::getType, 1).and(u -&gt; u.eq(User::getStatus, 0)); Page&lt;User&gt; page = userService.page(userPage, queryWrapper); ]]></content></entry><entry><title>Linux JDK一键安装脚本</title><url>/posts/java/linux-jdk-%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url><categories><category>Java</category></categories><tags><tag>Java</tag><tag>JDK</tag></tags><content type="html"><![CDATA[bash &lt;(curl -Ssl https://picture-czy.oss-cn-beijing.aliyuncs.com/shareFile/jdk-install.sh) 下载不了的话，运行下面脚本
#!/bin/bash set -e java_dist=&#34;/root/jdk-8u202-linux-x64.tar.gz&#34; default_java_dir=&#34;/usr/local&#34; java_dir=&#34;$default_java_dir&#34; SUDO_USER=root function usage() { echo &#34;&#34; echo &#34;这个脚本会自动下载jdk 1.8. &#34; echo &#34;Usage: &#34; echo &#34;install-java.sh -f &lt;java_dist&gt; [-p &lt;java_dir&gt;]&#34; echo &#34;&#34; echo &#34;-f: The jdk tar.gz file. 默认安装的是/root/jdk-8u202-linux-x64.tar.gz&#34; echo &#34;-p: java默认安装在/usr/local目录中，你可以通过-p命令切换目录&#34; echo &#34;-h: 显示帮助.&#34; echo &#34;&#34; } function confirm() { # call with a prompt string or use a default read -r -p &#34;${1:-Are you sure?} [y/N] &#34; response case $response in [yY][eE][sS] | [yY]) true ;; *) false ;; esac } # Make sure the script is running as root. if [ &#34;$UID&#34; -ne &#34;0&#34; ]; then echo &#34;You must be root to run $0. Try following&#34; echo &#34;sudo $0&#34; exit 9 fi while getopts &#34;f:p:h&#34; opts; do case $opts in f) java_dist=${OPTARG} ;; p) java_dir=${OPTARG} ;; h) usage exit 0 ;; \?) usage exit 1 ;; esac done if ! [ -x &#34;$(command -v axel)&#34; ]; then wget https://mirrors.huaweicloud.com/java/jdk/8u202-b08/jdk-8u202-linux-x64.tar.gz -O /root/jdk-8u202-linux-x64.tar.gz else axel -n 10 -a https://mirrors.huaweicloud.com/java/jdk/8u202-b08/jdk-8u202-linux-x64.tar.gz -o /root/jdk-8u202-linux-x64.tar.gz fi if [[ ! -f $java_dist ]]; then echo &#34;Please specify the Java distribution file.&#34; echo &#34;Use -h for help.&#34; exit 1 fi # Validate Java Distribution java_dist_filename=$(basename $java_dist) if [[ ${java_dist_filename: -7} != &#34;.tar.gz&#34; ]]; then echo &#34;Java distribution must be a valid tar.gz file.&#34; exit 1 fi # Create the default directory if user has not specified any other path if [[ $java_dir == $default_java_dir ]]; then mkdir -p $java_dir fi #Validate java directory if [[ ! -d $java_dir ]]; then echo &#34;Please specify a valid Java installation directory.&#34; exit 1 fi echo &#34;Installing: $java_dist_filename&#34; # Check Java executable java_exec=&#34;$(tar -tzf $java_dist | grep ^[^/]*/bin/java$ || echo &#34;&#34;)&#34; if [[ -z $java_exec ]]; then echo &#34;Could not find \&#34;java\&#34; executable in the distribution. Please specify a valid Java distribution.&#34; exit 1 fi # JDK Directory with version jdk_dir=&#34;$(echo $java_exec | cut -f1 -d&#34;/&#34;)&#34; extracted_dirname=$java_dir&#34;/&#34;$jdk_dir # Extract Java Distribution if [[ ! -d $extracted_dirname ]]; then echo &#34;Extracting $java_dist to $java_dir&#34; tar -xof $java_dist -C $java_dir echo &#34;JDK is extracted to $extracted_dirname&#34; else echo &#34;WARN: JDK was not extracted to $java_dir. There is an existing directory with the name \&#34;$jdk_dir\&#34;.&#34; if ! (confirm &#34;Do you want to continue?&#34;); then exit 1 fi fi if [[ ! -f &#34;${extracted_dirname}/bin/java&#34; ]]; then echo &#34;ERROR: The path $extracted_dirname is not a valid Java installation.&#34; exit 1 fi # Oracle JDK: 7 to 8 java_78_dir_regex=&#34;^jdk1\.([0-9]*).*$&#34; # Oracle JDK / OpenJDK / AdoptOpenJDK: 9 and upwards java_9up_dir_regex=&#34;^jdk-([0-9]*).*$&#34; # JDK Major Version jdk_major_version=&#34;&#34; if [[ $jdk_dir =~ $java_78_dir_regex ]]; then jdk_major_version=$(echo $jdk_dir | sed -nE &#34;s/$java_78_dir_regex/\1/p&#34;) else jdk_major_version=$(echo $jdk_dir | sed -nE &#34;s/$java_9up_dir_regex/\1/p&#34;) fi # Install Demos if [[ $jdk_dir =~ $java_78_dir_regex ]]; then # Demos are only available for Java 7 and 8 demos_dist=$(dirname $java_dist)&#34;/&#34;$(echo $java_dist_filename | sed &#39;s/\.tar\.gz/-demos\0/&#39;) fi if [[ -f $demos_dist &amp;&amp; ! -d $extracted_dirname/demo ]]; then # No demo directory if (confirm &#34;Extract demos?&#34;); then echo &#34;Extracting $demos_dist to $java_dir&#34; tar -xf $demos_dist -C $java_dir fi fi # Install Unlimited JCE Policy (only for Oracle JDK 7 &amp; 8) # Java 9 and above: default JCE policy files already allow for \&#34;unlimited\&#34; cryptographic strengths. unlimited_jce_policy_dist=&#34;&#34; if [[ $jdk_dir =~ ^jdk1\.7.* ]]; then unlimited_jce_policy_dist=&#34;$(dirname $java_dist)/UnlimitedJCEPolicyJDK7.zip&#34; elif [[ $jdk_dir =~ ^jdk1\.8.* ]]; then unlimited_jce_policy_dist=&#34;$(dirname $java_dist)/jce_policy-8.zip&#34; fi if [[ -f $unlimited_jce_policy_dist ]]; then #Check whether unzip command exsits if ! command -v unzip &gt;/dev/null 2&gt;&amp;1; then echo &#34;Please install unzip (apt -y install unzip).&#34; exit 1 fi if (confirm &#34;Install Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files?&#34;); then echo &#34;Extracting policy jars in $unlimited_jce_policy_dist to $extracted_dirname/jre/lib/security&#34; unzip -j -o $unlimited_jce_policy_dist *.jar -d $extracted_dirname/jre/lib/security fi fi # Run update-alternatives commands if (confirm &#34;Run update-alternatives commands?&#34;); then echo &#34;Running update-alternatives...&#34; cmd=&#34;update-alternatives --install /usr/bin/java java $extracted_dirname/bin/java 10000&#34; declare -a commands=($(ls -1 ${extracted_dirname}/bin | grep -v ^java$)) for command in &#34;${commands[@]}&#34;; do command_path=$extracted_dirname/bin/$command if [[ -x $command_path ]]; then cmd=&#34;$cmd --slave /usr/bin/$command $command $command_path&#34; fi done lib_path=$extracted_dirname/jre/lib/amd64/libnpjp2.so if [[ -d &#34;/usr/lib/mozilla/plugins/&#34; ]] &amp;&amp; [[ -f $lib_path ]]; then cmd=&#34;$cmd --slave /usr/lib/mozilla/plugins/libjavaplugin.so mozilla-javaplugin.so $lib_path&#34; fi echo $cmd # Execute command $cmd update-alternatives --set java $extracted_dirname/bin/java fi # Create system preferences directory java_system_prefs_dir=&#34;/etc/.java/.systemPrefs&#34; if [[ ! -d $java_system_prefs_dir ]]; then if (confirm &#34;Create Java System Prefs Directory ($java_system_prefs_dir) and change ownership to $SUDO_USER:$SUDO_USER?&#34;); then echo &#34;Creating $java_system_prefs_dir&#34; mkdir -p $java_system_prefs_dir chown -R $SUDO_USER:$SUDO_USER $java_system_prefs_dir fi fi USER_HOME=&#34;$(getent passwd $SUDO_USER | cut -d: -f6)&#34; if [[ -d &#34;$USER_HOME&#34; ]] &amp;&amp; (confirm &#34;Do you want to set JAVA_HOME environment variable in $USER_HOME/.bashrc?&#34;); then if grep -q &#34;export JAVA_HOME=.*&#34; $USER_HOME/.bashrc; then sed -i &#34;s|export JAVA_HOME=.*|export JAVA_HOME=$extracted_dirname|&#34; $USER_HOME/.bashrc else echo &#34;export JAVA_HOME=$extracted_dirname&#34; &gt;&gt;$USER_HOME/.bashrc fi fi applications_dir=&#34;$USER_HOME/.local/share/applications&#34; create_jmc_shortcut() { shortcut_file=&#34;$applications_dir/jmc_$jdk_major_version.desktop&#34; cat &lt;&lt;_EOF_ &gt;$shortcut_file [Desktop Entry] Name=Java $jdk_major_version: JMC Comment=Oracle Java Mission Control for Java $jdk_major_version Type=Application Exec=$extracted_dirname/bin/jmc Icon=$extracted_dirname/lib/missioncontrol/icon.xpm Terminal=false _EOF_ chmod +x $shortcut_file } if [[ -d $applications_dir ]] &amp;&amp; [[ -f $extracted_dirname/bin/jmc ]]; then if (confirm &#34;Do you want to create a desktop shortcut to JMC?&#34;); then create_jmc_shortcut fi fi 添加执行权限并运行
chmod +x install-java.sh &amp;&amp; ./install-java.sh ]]></content></entry><entry><title>Linux usr文件概述</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux-usr%E6%96%87%E4%BB%B6%E6%A6%82%E8%BF%B0/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">/bin 存放所有用户皆可用的系统程序，系统启动或者系统修复时可用（在没有挂载 /usr 目录时就可以使用） /sbin 存放超级用户才能使用的系统程序 /usr/bin 存放所有用户都可用的应用程序 /usr/sbin 存放超级用户才能使用的应用程序 /usr/local/bin 存放所有用户都可用的与本地机器无关的程序 /usr/local/sbin 存放超级用户才能使用的与本地机器无关的程序</content></entry><entry><title>Linux安装最新的Node(LTS)</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux-%E5%AE%89%E8%A3%85%E6%9C%80%E6%96%B0%E7%9A%84nodelts/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>Node</tag></tags><content type="html"># 先更新软件源 $ sudo apt-get upadte # 安装npm $ sudo apt install npm # 使用npm全局安装n模块 $ sudo npm install n -g # 安装最新长期支持版node $ sudo n lts # 检查是否安装成功 $ node -v</content></entry><entry><title>Linux查看温度</title><url>/posts/linux%E6%93%8D%E4%BD%9C/%E6%9F%A5%E7%9C%8B%E6%B8%A9%E5%BA%A6/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">方法一 pi@RaspberryPi:~ $ /opt/vc/bin/vcgencmd measure_temp temp=51.5&amp;#39;C 方法二 pi@RaspberryPi:~ $ cat /sys/class/thermal/thermal_zone0/temp 50464 此处的数值除以1000，单位是℃。</content></entry><entry><title>Linux常用命令</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[
系统信息 arch #显示机器的处理器架构(1) uname -m #显示机器的处理器架构(2) uname -r #显示正在使用的内核版本 dmidecode -q #显示硬件系统部件 - (SMBIOS / DMI) hdparm -i /dev/hda #罗列一个磁盘的架构特性 hdparm -tT /dev/sda #在磁盘上执行测试性读取操作 cat /proc/cpuinfo #显示CPU info的信息 cat /proc/interrupts #显示中断 cat /proc/meminfo #校验内存使用 cat /proc/swaps #显示哪些swap被使用 cat /proc/version #显示内核的版本 cat /proc/net/dev #显示网络适配器及统计 cat /proc/mounts #显示已加载的文件系统 lspci -tv #罗列PCI设备 lsusb -tv #显示USB设备 date 显示系统日期 cal 2007 #显示2007年的日历表 date 041217002007.00 #设置日期和时间 - 月日时分年.秒 clock -w #将时间修改保存到 BIOS 关机 (系统的关机、重启以及登出 ) shutdown -h now #关闭系统(1) init 0 #关闭系统(2) telinit 0 #关闭系统(3) shutdown -h hours:minutes &amp; #按预定时间关闭系统 shutdown -c #取消按预定时间关闭系统 shutdown -r now #重启(1) reboot #重启(2) logout #注销 文件和目录 cd /home #进入 &#39;/ home&#39; 目录&#39; cd .. #返回上一级目录 cd ../.. #返回上两级目录 cd #进入个人的主目录 cd ~user1 #进入个人的主目录 cd - #返回上次所在的目录 pwd #显示工作路径 ls #查看目录中的文件 ls -F #查看目录中的文件 ls -l #显示文件和目录的详细资料 ls -a #显示隐藏文件 ls *[0-9]* #显示包含数字的文件名和目录名 tree #显示文件和目录由根目录开始的树形结构(1) lstree #显示文件和目录由根目录开始的树形结构(2) mkdir dir1 #创建一个叫做 &#39;dir1&#39; 的目录&#39; mkdir dir1 dir2 #同时创建两个目录 mkdir -p /tmp/dir1/dir2 #创建一个目录树 rm -f file1 #删除一个叫做 &#39;file1&#39; 的文件&#39; rmdir dir1 #删除一个叫做 &#39;dir1&#39; 的目录&#39; rm -rf dir1 #删除一个叫做 &#39;dir1&#39; 的目录并同时删除其内容 rm -rf dir1 dir2 #同时删除两个目录及它们的内容 mv dir1 new_dir #重命名/移动 一个目录 cp file1 file2 #复制一个文件 cp dir/* . #复制一个目录下的所有文件到当前工作目录 cp -a /tmp/dir1 . #复制一个目录到当前工作目录 cp -a dir1 dir2 #复制一个目录 ln -s file1 lnk1 #创建一个指向文件或目录的软链接 ln file1 lnk1 #创建一个指向文件或目录的物理链接 touch -t 0712250000 file1 #修改一个文件或目录的时间戳 - (YYMMDDhhmm) file file1 outputs the mime type of the file as text iconv -l #列出已知的编码 iconv -f fromEncoding -t toEncoding inputFile &gt; outputFile creates a new from the given input file by assuming it is encoded in fromEncoding and converting it to toEncoding. find . -maxdepth 1 -name *.jpg -print -exec convert &#34;{}&#34; -resize 80x60 &#34;thumbs/{}&#34; \; batch resize files in the current directory and send them to a thumbnails directory (requires convert from Imagemagick) 文件搜索 find / -name file1 #从 &#39;/&#39; 开始进入根文件系统搜索文件和目录 find / -user user1 #搜索属于用户 &#39;user1&#39; 的文件和目录 find /home/user1 -name \*.bin #在目录 &#39;/ home/user1&#39; 中搜索带有&#39;.bin&#39; 结尾的文件 find /usr/bin -type f -atime +100 #搜索在过去100天内未被使用过的执行文件 find /usr/bin -type f -mtime -10 #搜索在10天内被创建或者修改过的文件 find / -name \*.rpm -exec chmod 755 &#39;{}&#39; \; #搜索以 &#39;.rpm&#39; 结尾的文件并定义其权限 find / -xdev -name \*.rpm #搜索以 &#39;.rpm&#39; 结尾的文件，忽略光驱、捷盘等可移动设备 locate \*.ps #寻找以 &#39;.ps&#39; 结尾的文件 - 先运行 &#39;updatedb&#39; 命令 whereis halt #显示一个二进制文件、源码或man的位置 which halt #显示一个二进制文件或可执行文件的完整路径 挂载一个文件系统 mount /dev/hda2 /mnt/hda2 #挂载一个叫做hda2的盘 - 确定目录 &#39;/ mnt/hda2&#39; 已经存在 umount /dev/hda2 #卸载一个叫做hda2的盘 - 先从挂载点 &#39;/ mnt/hda2&#39; 退出 fuser -km /mnt/hda2 #当设备繁忙时强制卸载 umount -n /mnt/hda2 #运行卸载操作而不写入 /etc/mtab 文件- 当文件为只读或当磁盘写满时非常有用 mount /dev/fd0 /mnt/floppy #挂载一个软盘 mount /dev/cdrom /mnt/cdrom #挂载一个cdrom或dvdrom mount /dev/hdc /mnt/cdrecorder #挂载一个cdrw或dvdrom mount /dev/hdb /mnt/cdrecorder #挂载一个cdrw或dvdrom mount -o loop file.iso /mnt/cdrom #挂载一个文件或ISO镜像文件 mount -t vfat /dev/hda5 /mnt/hda5 #挂载一个Windows FAT32文件系统 mount /dev/sda1 /mnt/usbdisk #挂载一个usb 捷盘或闪存设备 mount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share #挂载一个windows网络共享 磁盘空间 df -h #显示已经挂载的分区列表 ls -lSr |more #以尺寸大小排列文件和目录 du -sh dir1 #估算目录 &#39;dir1&#39; 已经使用的磁盘空间&#39; du -sk * | sort -rn #以容量大小为依据依次显示文件和目录的大小 rpm -q -a --qf &#39;%10{SIZE}t%{NAME}n&#39; | sort -k1,1n #以大小为依据依次显示已安装的rpm包所使用的空间 (fedora, redhat类系统) dpkg-query -W -f=&#39;${Installed-Size;10}t${Package}n&#39; | sort -k1,1n #以大小为依据显示已安装的deb包所使用的空间 (ubuntu, debian类系统) 用户和群组 groupadd group_name #创建一个新用户组 groupdel group_name #删除一个用户组 groupmod -n new_group_name old_group_name #重命名一个用户组 useradd -c &#34;Name Surname &#34; -g admin -d /home/user1 -s /bin/bash user1 #创建一个属于 &#34;admin&#34; 用户组的用户 useradd user1 #创建一个新用户 userdel -r user1 #删除一个用户 ( &#39;-r&#39; 排除主目录) usermod -c &#34;User FTP&#34; -g system -d /ftp/user1 -s /bin/nologin user1 #修改用户属性 passwd #修改口令 passwd user1 #修改一个用户的口令 (只允许root执行) chage -E 2005-12-31 user1 #设置用户口令的失效期限 pwck #检查 &#39;/etc/passwd&#39; 的文件格式和语法修正以及存在的用户 grpck #检查 &#39;/etc/passwd&#39; 的文件格式和语法修正以及存在的群组 newgrp group_name #登陆进一个新的群组以改变新创建文件的预设群组 文件的权限 使用 &#34;+&#34; 设置权限，使用 &#34;-&#34; 用于取消 ls -lh #显示权限 ls /tmp | pr -T5 -W$COLUMNS #将终端划分成5栏显示 chmod ugo+rwx directory1 #设置目录的所有人(u)、群组(g)以及其他人(o)以读（r ）、写(w)和执行(x)的权限 chmod go-rwx directory1 #删除群组(g)与其他人(o)对目录的读写执行权限 chown user1 file1 #改变一个文件的所有人属性 chown -R user1 directory1 #改变一个目录的所有人属性并同时改变改目录下所有文件的属性 chgrp group1 file1 #改变文件的群组 chown user1:group1 file1 #改变一个文件的所有人和群组属性 find / -perm -u+s #罗列一个系统中所有使用了SUID控制的文件 chmod u+s /bin/file1 #设置一个二进制文件的 SUID 位 - 运行该文件的用户也被赋予和所有者同样的权限 chmod u-s /bin/file1 #禁用一个二进制文件的 SUID位 chmod g+s /home/public #设置一个目录的SGID 位 - 类似SUID ，不过这是针对目录的 chmod g-s /home/public #禁用一个目录的 SGID 位 chmod o+t /home/public #设置一个文件的 STIKY 位 - 只允许合法所有人删除文件 chmod o-t /home/public #禁用一个目录的 STIKY 位 文件的特殊属性 - 使用 &#34;+&#34; 设置权限，使用 &#34;-&#34; 用于取消 chattr +a file1 #只允许以追加方式读写文件 chattr +c file1 #允许这个文件能被内核自动压缩/解压 chattr +d file1 #在进行文件系统备份时，dump程序将忽略这个文件 chattr +i file1 #设置成不可变的文件，不能被删除、修改、重命名或者链接 chattr +s file1 #允许一个文件被安全地删除 chattr +S file1 #一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘 chattr +u file1 #若文件被删除，系统会允许你在以后恢复这个被删除的文件 lsattr #显示特殊的属性 打包和压缩文件 bunzip2 file1.bz2 #解压一个叫做 &#39;file1.bz2&#39;的文件 bzip2 file1 #压缩一个叫做 &#39;file1&#39; 的文件 gunzip file1.gz #解压一个叫做 &#39;file1.gz&#39;的文件 gzip file1 #压缩一个叫做 &#39;file1&#39;的文件 gzip -9 file1 #最大程度压缩 rar a file1.rar test_file #创建一个叫做 &#39;file1.rar&#39; 的包 rar a file1.rar file1 file2 dir1 #同时压缩 &#39;file1&#39;, &#39;file2&#39; 以及目录 &#39;dir1&#39; rar x file1.rar #解压rar包 unrar x file1.rar #解压rar包 tar -cvf archive.tar file1 #创建一个非压缩的 tarball tar -cvf archive.tar file1 file2 dir1 #创建一个包含了 &#39;file1&#39;, &#39;file2&#39; 以及 &#39;dir1&#39;的档案文件 tar -tf archive.tar #显示一个包中的内容 tar -xvf archive.tar #释放一个包 tar -xvf archive.tar -C /tmp #将压缩包释放到 /tmp目录下 tar -cvfj archive.tar.bz2 dir1 #创建一个bzip2格式的压缩包 tar -jxvf archive.tar.bz2 #解压一个bzip2格式的压缩包 tar -cvfz archive.tar.gz dir1 #创建一个gzip格式的压缩包 tar -zxvf archive.tar.gz #解压一个gzip格式的压缩包 zip file1.zip file1 #创建一个zip格式的压缩包 zip -r file1.zip file1 file2 dir1 #将几个文件和目录同时压缩成一个zip格式的压缩包 unzip file1.zip #解压一个zip格式压缩包 RPM 包 - （Fedora, Redhat及类似系统） rpm -ivh package.rpm #安装一个rpm包 rpm -ivh --nodeeps package.rpm #安装一个rpm包而忽略依赖关系警告 rpm -U package.rpm #更新一个rpm包但不改变其配置文件 rpm -F package.rpm #更新一个确定已经安装的rpm包 rpm -e package_name.rpm #删除一个rpm包 rpm -qa #显示系统中所有已经安装的rpm包 rpm -qa | grep httpd #显示所有名称中包含 &#34;httpd&#34; 字样的rpm包 rpm -qi package_name #获取一个已安装包的特殊信息 rpm -qg &#34;System Environment/Daemons&#34; #显示一个组件的rpm包 rpm -ql package_name #显示一个已经安装的rpm包提供的文件列表 rpm -qc package_name #显示一个已经安装的rpm包提供的配置文件列表 rpm -q package_name --whatrequires #显示与一个rpm包存在依赖关系的列表 rpm -q package_name --whatprovides #显示一个rpm包所占的体积 rpm -q package_name --scripts #显示在安装/删除期间所执行的脚本l rpm -q package_name --changelog #显示一个rpm包的修改历史 rpm -qf /etc/httpd/conf/httpd.conf #确认所给的文件由哪个rpm包所提供 rpm -qp package.rpm -l #显示由一个尚未安装的rpm包提供的文件列表 rpm --import /media/cdrom/RPM-GPG-KEY #导入公钥数字证书 rpm --checksig package.rpm #确认一个rpm包的完整性 rpm -qa gpg-pubkey #确认已安装的所有rpm包的完整性 rpm -V package_name #检查文件尺寸、 许可、类型、所有者、群组、MD5检查以及最后修改时间 rpm -Va #检查系统中所有已安装的rpm包- 小心使用 rpm -Vp package.rpm #确认一个rpm包还未安装 rpm2cpio package.rpm | cpio --extract --make-directories *bin* #从一个rpm包运行可执行文件 rpm -ivh /usr/src/redhat/RPMS/`arch`/package.rpm #从一个rpm源码安装一个构建好的包 rpmbuild --rebuild package_name.src.rpm #从一个rpm源码构建一个 rpm 包 YUM 软件包升级器 - （Fedora, RedHat及类似系统） yum install package_name #下载并安装一个rpm包 yum localinstall package_name.rpm #将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系 yum update package_name.rpm #更新当前系统中所有安装的rpm包 yum update package_name #更新一个rpm包 yum remove package_name #删除一个rpm包 yum list #列出当前系统中安装的所有包 yum search package_name #在rpm仓库中搜寻软件包 yum clean packages #清理rpm缓存删除下载的包 yum clean headers #删除所有头文件 yum clean all #删除所有缓存的包和头文件 DEB 包 (Debian, Ubuntu 以及类似系统) dpkg -i package.deb #安装/更新一个 deb 包 dpkg -r package_name #从系统删除一个 deb 包 dpkg -l #显示系统中所有已经安装的 deb 包 dpkg -l | grep httpd #显示所有名称中包含 &#34;httpd&#34; 字样的deb包 dpkg -s package_name #获得已经安装在系统中一个特殊包的信息 dpkg -L package_name #显示系统中已经安装的一个deb包所提供的文件列表 dpkg --contents package.deb #显示尚未安装的一个包所提供的文件列表 dpkg -S /bin/ping #确认所给的文件由哪个deb包提供 APT 软件工具 (Debian, Ubuntu 以及类似系统) apt-get install package_name #安装/更新一个 deb 包 apt-cdrom install package_name #从光盘安装/更新一个 deb 包 apt-get update #升级列表中的软件包 apt-get upgrade #升级所有已安装的软件 apt-get remove package_name #从系统删除一个deb包 apt-get check #确认依赖的软件仓库正确 apt-get clean #从下载的软件包中清理缓存 apt-cache search searched-package #返回包含所要搜索字符串的软件包名称 查看文件内容 cat file1 #从第一个字节开始正向查看文件的内容 tac file1 #从最后一行开始反向查看一个文件的内容 more file1 #查看一个长文件的内容 less file1 #类似于 &#39;more&#39; 命令，但是它允许在文件中和正向操作一样的反向操作 head -2 file1 #查看一个文件的前两行 tail -2 file1 #查看一个文件的最后两行 tail -f /var/log/messages #实时查看被添加到一个文件中的内容 文本处理 cat file1 file2 ... | command &lt;&gt; file1_in.txt_or_file1_out.txt general syntax for text manipulation using PIPE, STDIN and STDOUT cat file1 | command( sed, grep, awk, grep, etc...) &gt; result.txt #合并一个文件的详细说明文本，并将简介写入一个新文件中 cat file1 | command( sed, grep, awk, grep, etc...) &gt;&gt; result.txt #合并一个文件的详细说明文本，并将简介写入一个已有的文件中 grep Aug /var/log/messages #在文件 &#39;/var/log/messages&#39;中查找关键词&#34;Aug&#34; grep ^Aug /var/log/messages #在文件 &#39;/var/log/messages&#39;中查找以&#34;Aug&#34;开始的词汇 grep [0-9] /var/log/messages #选择 &#39;/var/log/messages&#39; 文件中所有包含数字的行 grep Aug -R /var/log/* #在目录 &#39;/var/log&#39; 及随后的目录中搜索字符串&#34;Aug&#34; sed &#39;s/stringa1/stringa2/g&#39; example.txt #将example.txt文件中的 &#34;string1&#34; 替换成 &#34;string2&#34; sed &#39;/^$/d&#39; example.txt #从example.txt文件中删除所有空白行 sed &#39;/ *#/d; /^$/d&#39; example.txt #从example.txt文件中删除所有注释和空白行 echo &#39;esempio&#39; | tr &#39;[:lower:]&#39; &#39;[:upper:]&#39; #合并上下单元格内容 sed -e &#39;1d&#39; result.txt #从文件example.txt 中排除第一行 sed -n &#39;/stringa1/p&#39; #查看只包含词汇 &#34;string1&#34;的行 sed -e &#39;s/ *$//&#39; example.txt #删除每一行最后的空白字符 sed -e &#39;s/stringa1//g&#39; example.txt #从文档中只删除词汇 &#34;string1&#34; 并保留剩余全部 sed -n &#39;1,5p;5q&#39; example.txt #查看从第一行到第5行内容 sed -n &#39;5p;5q&#39; example.txt #查看第5行 sed -e &#39;s/00*/0/g&#39; example.txt #用单个零替换多个零 cat -n file1 #标示文件的行数 cat example.txt | awk &#39;NR%2==1&#39; #删除example.txt文件中的所有偶数行 echo a b c | awk &#39;{print $1}&#39; #查看一行第一栏 echo a b c | awk &#39;{print $1,$3}&#39; #查看一行的第一和第三栏 paste file1 file2 #合并两个文件或两栏的内容 paste -d &#39;+&#39; file1 file2 #合并两个文件或两栏的内容，中间用&#34;+&#34;区分 sort file1 file2 #排序两个文件的内容 sort file1 file2 | uniq #取出两个文件的并集(重复的行只保留一份) sort file1 file2 | uniq -u #删除交集，留下其他的行 sort file1 file2 | uniq -d #取出两个文件的交集(只留下同时存在于两个文件中的文件) comm -1 file1 file2 #比较两个文件的内容只删除 &#39;file1&#39; 所包含的内容 comm -2 file1 file2 #比较两个文件的内容只删除 &#39;file2&#39; 所包含的内容 comm -3 file1 file2 #比较两个文件的内容只删除两个文件共有的部分 字符设置和文件格式转换 dos2unix filedos.txt fileunix.txt #将一个文本文件的格式从MSDOS转换成UNIX unix2dos fileunix.txt filedos.txt #将一个文本文件的格式从UNIX转换成MSDOS recode ..HTML &lt; page.txt &gt; page.html #将一个文本文件转换成html recode -l | more #显示所有允许的转换格式 文件系统分析 badblocks -v /dev/hda1 #检查磁盘hda1上的坏磁块 fsck /dev/hda1 #修复/检查hda1磁盘上linux文件系统的完整性 fsck.ext2 /dev/hda1 #修复/检查hda1磁盘上ext2文件系统的完整性 e2fsck /dev/hda1 #修复/检查hda1磁盘上ext2文件系统的完整性 e2fsck -j /dev/hda1 #修复/检查hda1磁盘上ext3文件系统的完整性 fsck.ext3 /dev/hda1 #修复/检查hda1磁盘上ext3文件系统的完整性 fsck.vfat /dev/hda1 #修复/检查hda1磁盘上fat文件系统的完整性 fsck.msdos /dev/hda1 #修复/检查hda1磁盘上dos文件系统的完整性 dosfsck /dev/hda1 #修复/检查hda1磁盘上dos文件系统的完整性 初始化一个文件系统 mkfs /dev/hda1 #在hda1分区创建一个文件系统 mke2fs /dev/hda1 #在hda1分区创建一个linux ext2的文件系统 mke2fs -j /dev/hda1 #在hda1分区创建一个linux ext3(日志型)的文件系统 mkfs -t vfat 32 -F /dev/hda1 #创建一个 FAT32 文件系统 fdformat -n /dev/fd0 #格式化一个软盘 mkswap /dev/hda3 #创建一个swap文件系统 SWAP文件系统 mkswap /dev/hda3 #创建一个swap文件系统 swapon /dev/hda3 #启用一个新的swap文件系统 swapon /dev/hda2 /dev/hdb3 #启用两个swap分区 备份 dump -0aj -f /tmp/home0.bak /home #制作一个 &#39;/home&#39; 目录的完整备份 dump -1aj -f /tmp/home0.bak /home #制作一个 &#39;/home&#39; 目录的交互式备份 restore -if /tmp/home0.bak #还原一个交互式备份 rsync -rogpav --delete /home /tmp #同步两边的目录 rsync -rogpav -e ssh --delete /home ip_address:/tmp #通过SSH通道rsync rsync -az -e ssh --delete ip_addr:/home/public /home/local #通过ssh和压缩将一个远程目录同步到本地目录 rsync -az -e ssh --delete /home/local ip_addr:/home/public #通过ssh和压缩将本地目录同步到远程目录 dd bs=1M if=/dev/hda | gzip | ssh user@ip_addr &#39;dd of=hda.gz&#39; #通过ssh在远程主机上执行一次备份本地磁盘的操作 dd if=/dev/sda of=/tmp/file1 #备份磁盘内容到一个文件 tar -Puf backup.tar /home/user 执行一次对 &#39;/home/user&#39; #目录的交互式备份操作 ( cd /tmp/local/ &amp;&amp; tar c . ) | ssh -C user@ip_addr &#39;cd /home/share/ &amp;&amp; tar x -p&#39; #通过ssh在远程目录中复制一个目录内容 ( tar c /home ) | ssh -C user@ip_addr &#39;cd /home/backup-home &amp;&amp; tar x -p&#39; #通过ssh在远程目录中复制一个本地目录 tar cf - . | (cd /tmp/backup ; tar xf - ) #本地将一个目录复制到另一个地方，保留原有权限及链接 find /home/user1 -name &#39;*.txt&#39; | xargs cp -av --target-directory=/home/backup/ --parents #从一个目录查找并复制所有以 &#39;.txt&#39; 结尾的文件到另一个目录 find /var/log -name &#39;*.log&#39; | tar cv --files-from=- | bzip2 &gt; log.tar.bz2 #查找所有以 &#39;.log&#39; 结尾的文件并做成一个bzip包 dd if=/dev/hda of=/dev/fd0 bs=512 count=1 #做一个将 MBR (Master Boot Record)内容复制到软盘的动作 dd if=/dev/fd0 of=/dev/hda bs=512 count=1 #从已经保存到软盘的备份中恢复MBR内容 光盘 cdrecord -v gracetime=2 dev=/dev/cdrom -eject blank=fast -force #清空一个可复写的光盘内容 mkisofs /dev/cdrom &gt; cd.iso #在磁盘上创建一个光盘的iso镜像文件 mkisofs /dev/cdrom | gzip &gt; cd_iso.gz #在磁盘上创建一个压缩了的光盘iso镜像文件 mkisofs -J -allow-leading-dots -R -V &#34;Label CD&#34; -iso-level 4 -o ./cd.iso data_cd #创建一个目录的iso镜像文件 cdrecord -v dev=/dev/cdrom cd.iso #刻录一个ISO镜像文件 gzip -dc cd_iso.gz | cdrecord dev=/dev/cdrom - #刻录一个压缩了的ISO镜像文件 mount -o loop cd.iso /mnt/iso #挂载一个ISO镜像文件 cd-paranoia -B #从一个CD光盘转录音轨到 wav 文件中 cd-paranoia -- &#34;-3&#34; #从一个CD光盘转录音轨到 wav 文件中（参数-3） cdrecord --scanbus #扫描总线以识别scsi通道 dd if=/dev/hdc | md5sum #校验一个设备的md5sum编码，例如一张 CD 网络 - （以太网和WIFI无线） ifconfig eth0 #显示一个以太网卡的配置 ifup eth0 #启用一个 &#39;eth0&#39; 网络设备 ifdown eth0 #禁用一个 &#39;eth0&#39; 网络设备 ifconfig eth0 192.168.1.1 netmask 255.255.255.0 #控制IP地址 ifconfig eth0 promisc #设置 &#39;eth0&#39; 成混杂模式以嗅探数据包 (sniffing) dhclient eth0 #以dhcp模式启用 &#39;eth0&#39; route -n #查看路由表 route add -net 0/0 gw IP_Gateway #配置默认网关 route add -net 192.168.0.0 netmask 255.255.0.0 gw 192.168.1.1 #配置静态路由到达网络&#39;192.168.0.0/16&#39; route del 0/0 gw IP_gateway #删除静态路由 hostname #查看机器名 host www.example.com #把一个主机名解析到一个网际地址或把一个网际地址解析到一个主机名。 nslookup www.example.com #用于查询DNS的记录，查看域名解析是否正常，在网络故障的时候用来诊断网络问题。 ip link show #查看网卡信息 mii-tool #用于查看、管理介质的网络接口的状态 ethtool #用于查询和设置网卡配置 netstat -tupl #用于显示TCP/UDP的状态信息 tcpdump tcp port 80 #显示所有http协议的流量 JPS工具 jps(Java Virtual Machine Process Status Tool)是JDK 1.5提供的一个显示当前所有java进程pid的命令，简单实用，非常适合在linux/unix平台上简单察看当前java进程的一些简单情况。
我想很多人都是用过unix系统里的ps命令，这个命令主要是用来显示当前系统的进程情况，有哪些进程，及其 id。jps 也是一样，它的作用是显示当前系统的java进程情况，及其id号。我们可以通过它来查看我们到底启动了几个java进程（因为每一个java程序都会独占一个java虚拟机实例），和他们的进程号（为下面几个程序做准备），并可通过opt来查看这些进程的详细启动参数。
**使用方法：**在当前命令行下打 jps(需要JAVA_HOME，没有的话，到改程序的目录下打) 。
jps存放在JAVA_HOME/bin/jps，使用时为了方便请将JAVA_HOME/bin/加入到Path. $&gt; jps 23991 Jps 23789 BossMain 23651 Resin 比较常用的参数： #-q 只显示pid，不显示class名称,jar文件名和传递给main 方法的参数 $&gt; jps -q 28680 23789 23651 #-m 输出传递给main 方法的参数，在嵌入式jvm上可能是null $&gt; jps -m 28715 Jps -m 23789 BossMain 23651 Resin -socketwait 32768 -stdout /data/aoxj/resin/log/stdout.log -stderr /data/aoxj/resin/log/stderr.log #-l 输出应用程序main class的完整package名 或者 应用程序的jar文件完整路径名 $&gt; jps -l 28729 sun.tools.jps.Jps 23789 com.asiainfo.aimc.bossbi.BossMain 23651 com.caucho.server.resin.Resin #-v 输出传递给JVM的参数 $&gt; jps -v 23789 BossMain 28802 Jps -Denv.class.path=/data/aoxj/bossbi/twsecurity/java/trustwork140.jar:/data/aoxj/bossbi/twsecurity/java/:/data/aoxj/bossbi/twsecurity/java/twcmcc.jar:/data/aoxj/jdk15/lib/rt.jar:/data/aoxj/jd k15/lib/tools.jar -Dapplication.home=/data/aoxj/jdk15 -Xms8m 23651 Resin -Xss1m -Dresin.home=/data/aoxj/resin -Dserver.root=/data/aoxj/resin -Djava.util.logging.manager=com.caucho.log.LogManagerImpl - Djavax.management.builder.initial=com.caucho.jmx.MBeanServerBuilderImpl jps 192.168.0.77 #列出远程服务器192.168.0.77机器所有的jvm实例，采用rmi协议，默认连接端口为1099（前提是远程服务器提供jstatd服务） #注：jps命令有个地方很不好，似乎只能显示当前用户的java进程，要显示其他用户的还是只能用unix/linux的ps命令 ]]></content></entry><entry><title>Linux创建守护进程</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux%E5%88%9B%E5%BB%BA%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">在 /etc/systemd/system/ 下新建并编辑 xxx.service 文件
这里以 code-server.service 为例
sudo vim /etc/systemd/system/code-server.service 写入下面的内容并根据自己创建的服务进行更改(带注释的为选填，看服务的需求开启)
[Unit] Description=code-server #描述要启动的进程 After=network.target [Service] Type=simple #WorkingDirectory=/root/workDir #启动进程的文件夹 #User=root #你想用什么用户启动该进程 #Group=root #你希望用什么用户组启动该进程 Restart=on-failure #进程错误时重启 RestartSec=10 ExecStart=/usr/bin/code-server#启动命，要用绝对路径，否则会报错 [Install] WantedBy=multi-user.target systemctl daemon-reload</content></entry><entry><title>Linux磁盘分区、格式化、挂载</title><url>/posts/linux%E6%93%8D%E4%BD%9C/%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%8C%82%E8%BD%BD/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html">一、插入U盘或者移动硬盘 1、若是一块新的移动硬盘，则需要对它进行分区和格式化 使用df -h可以查看当前系统中详细的存储设备挂载情况。
使用sudo fdisk -l可以查看磁盘分区情况
1.1进入fdisk操作模式，对磁盘进行分区 通过指令sudo fdisk /dev/sd*我们可以进入对应磁盘的fdisk操作模式，我们可以输入m来获取如下的帮助列表，并选择对应的功能进行后续操作。
Help: DOS (MBR) a toggle a bootable flag # 切换可引导的标识 b edit nested BSD disklabel # 编辑bsd磁盘标识 c toggle the dos compatibility flag # 切换dos兼容性标识 Generic d delete a partition # 删除磁盘分区 F list free unpartitioned space # 列出可用未分区空间 l list known partition types # 列出已知分区类型 n add a new partition # 添加一个新的分区 p print the partition table # 打印分区表 t change a partition type # 更改分区类型 v verify the partition table # 校验分区表 i print information about a partition # 打印有关分区的信息 Misc m print this menu # 打印help u change display/entry units # 改变 显示/接入 单元 x extra functionality (experts only) # 额外功能(仅限专家) Script I load disk layout from sfdisk script file # 从sfdisk脚本文件加载磁盘布局 O dump disk layout to sfdisk script file # 将磁盘布局转储到sfdisk脚本文件 Save &amp;amp; Exit w write table to disk and exit # 保存并退出 q quit without saving changes # 退出不保存 Create a new label g create a new empty GPT partition table # 创建一个新的gpt分区 G create a new empty SGI (IRIX) partition table o create a new empty DOS partition table s create a new empty Sun partition table 常用的就 n p w
1.2 对新分区进行格式化操作 有两种格式化方法：
sudo mkfs -t ext4 /dev/sda1 # 或者 sudo mkfs.ext4 /dev/sda1 # xfs文件系统 sudo mkfs -t xfs /dev/sdb1 sudo mkfs.xfs /dev/sdb1 1.3 磁盘挂载 sudo mount /dev/sda1 /data # 卸载命令 sudo umount /dev/sda1 最后通过df -h查看挂载情况
可以看到/dev/sda1已经挂载成功
1.4 设置磁盘的开机自动挂载 首先我们需要获取新的磁盘的UUID：
sudo blkid /dev/sda1 然后把UUID和相关信息按照格式写到/etc/fstab里面，主要增加UUID，挂载位置，FS格式这三点，之后保存即可。
sudo vim /etc/fstab</content></entry><entry><title>Linux磁盘清理</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux-%E7%A3%81%E7%9B%98%E6%B8%85%E7%90%86/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">1. 查看磁盘信息 df -lh 我们可以看见Filesystem下的挂载点 /dev/vda1 下的8.4G容量已经耗尽。接下来就是删除占用磁盘空间大，但又无用的文件。
2. 定位最大文件目录 cd / #寻找当前目录，哪个文件夹占用空间最大 du -h --max-depth=1 可以看到 /var 此路径占用较大磁盘空间，占用了6G。
重复上面的步骤，定位到最后的目录
可以看到 /log 此路径占用较大磁盘空间，占用了5.8G。
3. 定位最大文件 进入/log目录，查看里面的文件情况
可以看到里面有几个G的系统文件，查看之后再确认是否删除
4. 删除文件 rm -f messages*</content></entry><entry><title>Linux搭建Socks5代理</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/linux%E6%90%AD%E5%BB%BAsocks5%E4%BB%A3%E7%90%86/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>代理</tag></tags><content type="html"><![CDATA[ 说明： Socks5属于明文代理，可用于正常的跳板使用； 比如SSH转发加速国外VPS的连接速度，特别是一些延迟高或者丢包高的VPS； 使用Socks5转发后SSH就可以快速稳定的连接了，解决高丢包SSH断开的问题
项目地址： https://github.com/Lozy/danted 1. 安装 wget https://raw.githubusercontent.com/Lozy/danted/blob/master/install.sh # bash install.sh --port=端口 --user=用户名 --passwd=密码 bash install.sh --port=5566 --user=colzry --passwd=colzry_admin 下载不了的话可以直接写入下面的内容
#!/bin/bash # # Dante Socks5 Server AutoInstall # -- Owner: https://www.inet.no/dante # -- Provider: https://sockd.info # -- Author: Lozy # # Check if user is root if [ $(id -u) != &#34;0&#34; ]; then echo &#34;Error: You must be root to run this script, please use root to install&#34; exit 1 fi REQUEST_SERVER=&#34;https://raw.github.com/Lozy/danted/master&#34; SCRIPT_SERVER=&#34;https://public.sockd.info&#34; SYSTEM_RECOGNIZE=&#34;&#34; [ &#34;$1&#34; == &#34;--no-github&#34; ] &amp;&amp; REQUEST_SERVER=${SCRIPT_SERVER} if [ -s &#34;/etc/os-release&#34; ];then os_name=$(sed -n &#39;s/PRETTY_NAME=&#34;\(.*\)&#34;/\1/p&#39; /etc/os-release) if [ -n &#34;$(echo ${os_name} | grep -Ei &#39;Debian|Ubuntu&#39; )&#34; ];then printf &#34;Current OS: %s\n&#34; &#34;${os_name}&#34; SYSTEM_RECOGNIZE=&#34;debian&#34; elif [ -n &#34;$(echo ${os_name} | grep -Ei &#39;CentOS&#39;)&#34; ];then printf &#34;Current OS: %s\n&#34; &#34;${os_name}&#34; SYSTEM_RECOGNIZE=&#34;centos&#34; else printf &#34;Current OS: %s is not support.\n&#34; &#34;${os_name}&#34; fi elif [ -s &#34;/etc/issue&#34; ];then if [ -n &#34;$(grep -Ei &#39;CentOS&#39; /etc/issue)&#34; ];then printf &#34;Current OS: %s\n&#34; &#34;$(grep -Ei &#39;CentOS&#39; /etc/issue)&#34; SYSTEM_RECOGNIZE=&#34;centos&#34; else printf &#34;+++++++++++++++++++++++\n&#34; cat /etc/issue printf &#34;+++++++++++++++++++++++\n&#34; printf &#34;[Error] Current OS: is not available to support.\n&#34; fi else printf &#34;[Error] (/etc/os-release) OR (/etc/issue) not exist!\n&#34; printf &#34;[Error] Current OS: is not available to support.\n&#34; fi if [ -n &#34;$SYSTEM_RECOGNIZE&#34; ];then wget -qO- --no-check-certificate ${REQUEST_SERVER}/install_${SYSTEM_RECOGNIZE}.sh | \ bash -s -- $* else printf &#34;[Error] Installing terminated&#34; exit 1 fi exit 0 2. 服务端使用 卸载
bash install.sh --uninstall 增加用户
/etc/init.d/sockd adduser USERNAME PASSWORD command option description service sockd start /etc/init.d/sockd start start socks5 server daemon service sockd stop /etc/init.d/sockd stop stop socks5 server daemon service sockd restart /etc/init.d/sockd restart restart socks5 server daemon service sockd reload /etc/init.d/sockd reload reload socks5 server daemon service sockd status systemd process status service sockd state /etc/init.d/sockd state running state service sockd tail /etc/init.d/sockd tail sock log tail service sockd adduser /etc/init.d/sockd adduser add pam-auth user: service sockd adduser NAME PASSWORD service sockd deluser /etc/init.d/sockd deluser delete pam-auth user: service sockd deluser NAME 3. 客户端使用 proxychanins中使用（推荐）
vim /etc/proxychains.conf socks5 43.142.174.216 5566 colzry colzry_admin |-&gt;ip |-&gt;端口 |-&gt;用户名 |-&gt;密码 使用系统导出代理（不推荐）
export ALL_PROXY=socks5://colzry:colzry_admin@43.142.174.216:5566 # 取消代理 unset ALL_PROXY ]]></content></entry><entry><title>Linux搭建WebDav服务</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/linux%E6%90%AD%E5%BB%BAwebdav%E6%9C%8D%E5%8A%A1/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>WebDav</tag></tags><content type="html">WebDav Server WebDAV 是 GitHub 上开源的项目，基于 Go 语言实现，不仅跨平台，还支持 ARM 架构，可在㠌入式设备中部署 WebDAV 服务器。 项目地址： https://github.com/hacdias/webdav GitHub 下载对应的架构 WebDAV，解压后获得 webdav二进制文件
1. 解压 tar -zxvf linux-amd64-webdav.tar.gz mv webdav /usr/bin/ 2. 编写配置文件 vim /opt/webdav_config.yaml # Server related settings address: 0.0.0.0 port: 10105 # 如果无需验证填 false auth: true # 如果不需要 https 则填 false tls: false # https证书和密钥，如果 tls 为 false，cert 和 key 不需要 # cert: /data/www/cert/szhome.xf1024.com_nginx/cert.pem # key: /data/www/cert/szhome.xf1024.com_nginx/cert.key # 访问前缀，建议默认 prefix: / debug: false # 如果 auth 为 false 生效，文件共享的路径 scope: . modify: true rules: [] # 跨域设置 cors: enabled: true credentials: true allowed_headers: - Depth allowed_hosts: - http://localhost:10105 allowed_methods: - GET exposed_headers: - Content-Length - Content-Range # 用户信息，如果 auth 为 true 生效 users: - username: Colzry password: webdav_colzry scope: /mnt/hhd01/back/Video/ # 是否允许修改 modify: true - username: other_user password: xxxxx scope: /data/1/Video modify: true 使用命令
/usr/bin/webdav -c /opt/webdav_config.yaml 3. 添加守护进程 vim /usr/lib/systemd/system/webdav.service [Unit] Description=WebDAV server After=network.target [Service] Type=simple User=root ExecStart=/usr/bin/webdav -c /opt/webdav_config.yaml Restart=on-failure [Install] WantedBy=multi-user.target systemctl daemon-reload systemctl start webdav.service systemctl status webdav.service systemctl enable webdav.service 4. Linux 挂载 sudo apt install davfs2 sudo mount -t davfs http://192.168.5.254:10105/ /webdav 5. Nginx 开启 WebDAV 在Nginx中实现WebDAV需要安装 libnginx-mod-http-dav-ext 模块，以下是Nginx的配置：
server { listen 80; listen [::]:80; server_name dav.engr-z.com; location / { root /data/webdav; client_body_temp_path /var/temp; dav_methods PUT DELETE MKCOL COPY MOVE; dav_ext_methods PROPFIND OPTIONS; create_full_put_path on; client_max_body_size 10G; } } server { listen 443; listen [::]:443; server_name dav.engr-z.com; ssl on; ssl_certificate /data/www/cert/dav.engr-z.com_nginx/cert.pem; ssl_certificate_key /data/www/cert/dav.engr-z.com_nginx/cert.key; ssl_session_timeout 5m; ssl_protocols SSLv2 SSLv3 TLSv1; ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; ssl_prefer_server_ciphers on; location / { root /data/webdav; client_body_temp_path /var/temp; dav_methods PUT DELETE MKCOL COPY MOVE; dav_ext_methods PROPFIND OPTIONS; create_full_put_path on; client_max_body_size 10G; } }</content></entry><entry><title>Linux防火墙和Cockpit</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux%E9%98%B2%E7%81%AB%E5%A2%99%E5%92%8Ccockpit/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[1. firewall (RedHat系列) # 查看状态 firewall-cmd --state # 开启防火墙 systemctl start firewalld.service # 关闭并禁用防火墙 systemctl stop firewalld.service systemctl disable firewalld.service # 关闭SElinux 该为disable vim /etc/selinux/config # 开放端口 firewall-cmd --zone=public --add-port=8080/tcp --permanent firewall-cmd --reload # 关闭端口 firewall-cmd --zone=public --remove-port=8080/tcp --permanent firewall-cmd --reload # 查看以开放的端口 firewall-cmd --list-ports # 更新防火墙规则 firewall-cmd --reload 2. ufw (Ubuntu) # 查看状态 ufw status 3. Cockpit安装 dnf install cockpit cockpit-dashboard / cockpit-storaged cockpit-packagekit -y # 也可以安装其它的扩展包 dnf list cockpit* -------------------------- cockpit-bridge.x86_64 cockpit-composer.noarch cockpit-doc.noarch cockpit-machines.noarch cockpit-packagekit.noarch cockpit-pcp.x86_64 cockpit-podman.noarch cockpit-session-recording.noarch cockpit-storaged.noarch cockpit-system.noarch cockpit-ws.x86_64 -------------------------- # 启动cockpit并设为开启自启动 systemctl enable --now cockpit.socket / &amp;&amp; systemctl list-unit-files | grep cockpit / &amp;&amp; systemctl start cockpit # 有防火墙的话，记得开放 firewall-cmd --permanent --zone=public --add-service=cockpit firewall-cmd --reload 之后访问本机9090端口 ]]></content></entry><entry><title>Linux科学代理</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/linux-%E7%A7%91%E5%AD%A6%E4%BB%A3%E7%90%86/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>代理</tag></tags><content type="html"><![CDATA[官方文档： https://v2raya.org/docs/prologue/quick-start/ 安装v2ray内核，使用镜像脚本（不通过添加软件源安装）
# v2rayA 提供的镜像脚本 curl -Ls https://mirrors.v2raya.org/go.sh | sudo bash # 安装后可以关掉服务，因为 v2rayA 不依赖于该 systemd 服务 sudo systemctl disable v2ray --now 1. 安装 1.1 Fedora # 添加 copr 源 sudo dnf copr enable zhullyb/v2rayA # 安装 V2Ray 内核 sudo dnf install v2ray-core # 安装 v2rayA sudo dnf install v2raya # 启动 sudo systemctl start v2raya.service # 设置开机自启 sudo systemctl enable v2raya.service 1.2 Debian 请先通过顶上的方法安装v2ray内核
# 添加公钥 wget -qO - https://apt.v2raya.org/key/public-key.asc | sudo tee /etc/apt/trusted.gpg.d/v2raya.asc # 添加 V2RayA 软件源 echo &#34;deb https://apt.v2raya.org/ v2raya main&#34; | sudo tee /etc/apt/sources.list.d/v2raya.list sudo apt update # 安装 V2RayA sudo apt install v2raya # 启动 sudo systemctl start v2raya.service # 设置开机自启 sudo systemctl enable v2raya.service 切换 iptables 为 iptables-nft 对于 Debian11 用户来说，iptables 已被弃用。使用 nftables 作为 iptables 的后端以进行适配
update-alternatives --set iptables /usr/sbin/iptables-nft update-alternatives --set ip6tables /usr/sbin/ip6tables-nft update-alternatives --set arptables /usr/sbin/arptables-nft update-alternatives --set ebtables /usr/sbin/ebtables-nft 如果你想切换回 legacy 版本
update-alternatives --set iptables /usr/sbin/iptables-legacy update-alternatives --set ip6tables /usr/sbin/ip6tables-legacy update-alternatives --set arptables /usr/sbin/arptables-legacy update-alternatives --set ebtables /usr/sbin/ebtables-legacy 切换后重启即可
2. 使用 通过 2017 端口 如 http://localhost:2017 访问 UI 界面 记得调整防火墙
2.1 创建管理员账号 2.2 导入节点 vmess://ew0KICAidiI6ICIyIiwNCiAgInBzIjogIlZtZXNzIiwNCiAgImFkZCI6ICJwYW4uZ29zc2lwLnRrIiwNCiAgInBvcnQiOiAiNDQzIiwNCiAgImlkIjogIjcyNTQ0Nzk0LTRhYWUtNGVmNy1jMmRhLTUxOTRjN2RkOGI4NSIsDQogICJhaWQiOiAiMCIsDQogICJzY3kiOiAiYXV0byIsDQogICJuZXQiOiAid3MiLA0KICAidHlwZSI6ICJub25lIiwNCiAgImhvc3QiOiAicGFuLmdvc3NpcC50ayIsDQogICJwYXRoIjogIi9nb2ZpYyIsDQogICJ0bHMiOiAidGxzIiwNCiAgInNuaSI6ICIiLA0KICAiYWxwbiI6ICIiDQp9 2.3 启动 2.4 设置 2.5 开放代理端口 2.6 设置Linux代理 export ALL_PROXY=socks5://127.0.0.1:20170 # 取消代理 unset ALL_PROXY 2.7 使用proxychains设置代理（推荐） 安装
# Fedora sudo dnf install proxychains-ng # Debian sudo apt install proxychains-ng 配置
vim /etc/proxychains.conf socks5 127.0.0.1 20170 测试一下
[root@fedora ~]# proxychains curl cip.cc [proxychains] config file found: /etc/proxychains.conf [proxychains] preloading /usr/lib64/proxychains-ng/libproxychains4.so [proxychains] DLL init: proxychains-ng 4.16 [proxychains] Strict chain ... 127.0.0.1:20170 ... cip.cc:80 ... OK IP : 198.23.149.5 地址 : 美国 华盛顿州 西雅图 运营商 : colocrossing.com 数据二 : 美国 | 纽约州伊利县威廉斯维尔村ColoCrossing有限公司 数据三 : 美国华盛顿西雅图 URL : http://www.cip.cc/198.23.149.5 简化使用命令
echo &#34;alias pc=&#39;proxychains&#39;&#34; &gt;&gt; ~/.bashrc source ~/.bashrc [root@fedora ~]# pc curl cip.cc [proxychains] config file found: /etc/proxychains.conf [proxychains] preloading /usr/lib64/proxychains-ng/libproxychains4.so [proxychains] DLL init: proxychains-ng 4.16 [proxychains] Strict chain ... 192.168.211.99:20170 ... 122.51.162.249:80 ... OK IP : 198.23.149.5 地址 : 美国 华盛顿州 西雅图 运营商 : colocrossing.com 数据二 : 美国 | 纽约州伊利县威廉斯维尔村ColoCrossing有限公司 数据三 : 美国华盛顿西雅图 URL : http://www.cip.cc/198.23.149.5 2.8 设置局域网使用 3. 浏览器代理 SwitchyOmega 等浏览器插件可为浏览器提供代理服务。 ]]></content></entry><entry><title>Linux配置环境变量的建议</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux-%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%9A%84%E5%BB%BA%E8%AE%AE/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"> 若是普通用户，则在自己用户目录的.bashrc中配置，若使用了zsh，则在.zshrc中配置
若是root用户，则在/etc/profile.d/中新建一个my_env.sh文件
最后普通用户(source)刷新.bashrc或.zshrc文件，root用户刷新/etc/profile文件
其中$PAHT表示系统的环境变量，: 表示拼接在系统环境变量$PAHT之后
eg: root用户下的my_env.sh文件 #JAVA_HOME export JAVA_HOME=/opt/module/jdk1.8.0_212 export PATH=$PATH:$JAVA_HOME/bin #HADOOP_HOME export HADOOP_HOME=/opt/module/hadoop-3.1.3 export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin source /etc/profile 普通用户的.zshrc文件 export PATH=/home/colzry/.local/bin/:$PATH source .zshrc 最后 /etc/environment也可以更改，改完之后注销即可 或者执行下面语句
PATH=&amp;#34;$PATH&amp;#34;</content></entry><entry><title>Linux软件批量卸载</title><url>/posts/linux%E6%93%8D%E4%BD%9C/%E6%89%B9%E9%87%8F%E5%8D%B8%E8%BD%BD/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">rpm -e `rpm -qa | grep python`</content></entry><entry><title>Linux设置静态IP</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux%E8%AE%BE%E7%BD%AE%E9%9D%99%E6%80%81ip/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>静态IP</tag></tags><content type="html"><![CDATA[Centos 编辑em1对应的配置文件，位于/etc/sysconfig/network-scripts/ifcfg-你的网卡名字 vim /etc/sysconfig/network-scripts/ifcfg-eth0 主要修改BOOTPROTO, IPADDR, NETMASK, GATEWAY也就是带注释的内容
# Generated by dracut initrd NAME=&#34;eth0&#34; HWADDR=&#34;52:54:00:e1:fa:43&#34; ONBOOT=yes NETBOOT=yes UUID=&#34;d30acbe4-f24c-40d2-be6a-f474d8b7d3f2&#34; IPV6INIT=yes BOOTPROTO=&#34;static&#34; # 使用静态IP，默认为dhcp IPADDR=&#34;192.168.0.100&#34; # 静态IP NETMASK=&#34;255.255.255.0&#34; # 子网掩码 GATEWAY=&#34;192.168.0.1&#34; # 网关 TYPE=Ethernet 保存后重启网络服务
service network restart Almalinux vim /etc/NetworkManager/system-connections/ens18.nmconnection nmcli c reload nmcli c down ens18 &amp;&amp; nmcli c up ens18 Debian 首选备份原始的网络配置文件，
sudo cp /etc/network/interfaces /etc/network/interfacesbak 编辑文件 /etc/network/interfaces，内容如下：
auto lo auto eth0 # 设置开机自动连接网络 iface lo inet loopback allow-hotplug eth0 iface eth0 inet static # static表示使用固定IP地址上网，dhcp表示使用动态ip address 192.168.9.100 # 设置静态ip地址 netmask 255.255.255.0 # 子网掩码 gateway 192.168.9.254 # 网关 保存后重启网络服务
service networking restart Ubuntu 更改/etc/netplan/*.yaml下的yaml文件
vim /etc/netplan/00-installer-config.yaml # This is the network config written by &#39;subiquity&#39; network: ethernets: enp1s0: dhcp4: no # 关闭dhcp addresses: [192.168.0.200/24] # 设置IP和掩码 gateway4: 192.168.0.1 # 网关 nameservers: # 设置DNS addresses: [192.168.0.1, 114.114.114.114] version: 2 保存后使用netplan命令应用最近的网络更改
netplan apply ]]></content></entry><entry><title>Linux输入输出重定向</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%87%8D%E5%AE%9A%E5%90%91/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[说明 0 标准输入 1 标准输出 2 标准错误 下面命令表示把输出结果重定向到file文件中，而错误重定向到标准输出，此时的标准输出为重定向到file文件中，所以错误也会输出到file文件中
command &gt; file 2&gt;&amp;1 解释 何2&gt;&amp;1要写在后面？
command &gt; file 2&gt;&amp;1
首先是command &gt; file将标准输出重定向到file中， 2&gt;&amp;1 是标准错误拷贝了标准输出的行为，也就是同样被重定向到file中，最终结果就是标准输出和错误都被重定向到file中。
command 2&gt;&amp;1 &gt;file
2&gt;&amp;1 标准错误拷贝了标准输出的行为，但此时标准输出还是在终端。&gt;file 后输出才被重定向到file，但标准错误仍然保持在终端。
用strace可以看到：
command &gt; file 2&gt;&amp;1 这个命令中实现重定向的关键系统调用序列是：
open(file) == 3
dup2(3,1)
dup2(1,2)
command 2&gt;&amp;1 &gt;file 这个命令中实现重定向的关键系统调用序列是：
dup2(1,2)
open(file) == 3
dup2(3,1)
为什么会有&amp;
当没有&amp;时，1会被认为是一个普通的文件，有&amp;表示重定向的目标不是一个文件，而是一个文件描述符。
为什么有&amp;1而没有&amp;2
2&gt;是一个整体，表示标准错误输出重定向，重定向至&amp;1，即标准输出，&amp;1是一个文件
常用命令 挂入后台命令
# 普通 断开终端就停止 command &gt;/dev/null 2&gt;&amp;1 &amp; # 高级 断开终端不停止 nohup command &gt;/dev/null 2&gt;&amp;1 &amp; # 或者 nohup command &gt;&amp; /dev/null &amp; 其他写法 command &gt; file 2&gt;&amp;1 等价写法 command &gt;&amp; file command &amp;&gt; file ]]></content></entry><entry><title>Linux文件恢复</title><url>/posts/linux%E6%93%8D%E4%BD%9C/%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html"> https://bbs.huaweicloud.com/blogs/345168 dd命令 https://blog.csdn.net/hezhanran/article/details/122662675 文件测速
hdparm -t /dev/sdxx</content></entry><entry><title>Linux文件拷贝</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux%E6%96%87%E4%BB%B6%E6%8B%B7%E8%B4%9D/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[scp 推送 scp -r 文件名 目标用户@主机名(host):目标目录 [colzry@hadoop102 ~]$ cd /opt/module/ [colzry@hadoop102 module]$ pwd /opt/module [colzry@hadoop102 module]$ ll 总用量 0 drwxr-xr-x. 9 colzry root 149 9月 12 2019 hadoop-3.1.3 drwxr-xr-x. 7 colzry root 245 4月 2 2019 jdk1.8.0_212 [colzry@hadoop102 module]$ scp -r jdk1.8.0_212/ colzry@hadoop103:/opt/module/ 拉取 scp -r 目标用户@主机名(host):目标目录 放置目录 [colzry@hadoop103 module]$ scp -r colzry@hadoop102:/opt/module/hadoop-3.1.3 ./ 中转 scp -r 目标用户@主机名(host):目标目录 目标用户@主机名(host):目标目录 [colzry@hadoop103 module]$ scp -r colzry@hadoop102:/opt/module/* colzry@hadoop104:/opt/module/ rsync(推荐使用) rsync -av 文件名 目标用户@主机名(host):目标目录 rsync -av 目标用户@主机名(host):目标目录 目标目录 rsync -av 目标用户@主机名(host):目标目录 目标用户@主机名(host):目标目录 集群分发脚本 #!/bin/bash #1. 判断参数个数 if [ $# -lt 1 ] then echo Not Enough Arguement! exit; fi #2. 遍历集群所有机器 for host in hadoop102 hadoop103 hadoop104 do echo ==================== $host ==================== #3. 遍历所有目录，挨个发送 for file in $@ do #4. 判断文件是否存在 if [ -e $file ] then #5. 获取父目录 pdir=$(cd -P $(dirname $file); pwd) #6. 获取当前文件的名称 fname=$(basename $file) ssh $host &#34;mkdir -p $pdir&#34; rsync -av $pdir/$fname $host:$pdir else echo $file does not exists! fi done done 使用方法 cd ~ mkdir bin vim xsync // 填入上面脚本内容 chmod 777 xsync xsync /etc/profile.d/my_env.sh 集群状态查看脚本 #!/bin/bash # 获取控制台指令 # 判断指令是否为空 if [ $# -lt 1 ] then echo &#34;command can not be null !&#34; exit fi # 获取当前登录用户 user=`whoami` source /etc/profile # 在从机执行指令,这里需要根据你具体的集群情况配置，host与具体主机名一致 for host in hadoop101 hadoop102 hadoop103 do echo ================ $host================= ssh $user@$host $@ done echo =========================================== 使用方法 cd ~ mkdir bin vim xcall // 填入上面脚本内容 chmod 777 xcall xcall jps ]]></content></entry><entry><title>Linux用户的管理</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux-%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[Linux 用户管理 一.用户管理命令 通过系统中的命令对用户进行相应的操作。在讲解命令之前，我们需要了解，在linux操作系统中，以下的几个概念：
UID：用户ID号，用户的唯一标识号，就相当于一个人的身份证号。 所属用户组：在linux操作系统中，一个用户必须有它的用户组，如果不给新用户指定用户组，那么该会默认创建一个与用户名相同的组。 GID：用户组的ID号。 家目录:与Windows系统相同，可理解为一个用户的用户文件夹，所有用户的家目录默认被创建在 /home 目录下。相当于Windows操作系统中的 C:/Users 目录。 1.1 创建用户 通过 useradd 命令来创建新的用户。
语法格式： useradd [参数] &lt;用户名&gt;
常用参数：
参数 作用 -u 指定用户UID -d 指定用户家目录位置 -c 添加用户说明/备注 -g 指定用户初始所属的用户组 -G 指定用户所属附加组 -s 指定用户登录的shell解释器 操作演示：
添加新用户 xiaobei
[root@localhost ~]# useradd xiaobei 添加新用户 test01 并且指定其家目录为 /test/test01
[root@localhost ~]# useradd -d /test/test01 test01 添加新用户 test01 并且指定ID为6666
[root@localhost ~]# useradd -u 6666 test01 添加新用户 test01 并且指定其所属组为root，并设置其登录shell为nologin
[root@localhost ~]# useradd -g root -s /sbin/nologin test01 1.2 设置密码 通过passwd命令来设置当前登录用户(自身)或者其他用户的密码。该命令如果不加用户名，即代表对当前登录的用户进行操作。不加参数，代表设置密码。这里我们需要知道，通常创建用户都是root来做的，所以设置密码也都是root用户身份来进行设置。如果是普通用户想设置root用户的密码，怎么办呢？不是不可以，只是该普通用户必须拥有sudo权限。本文我们只需要理解可以这么做就好。
语法格式： passwd [参数] [用户名]
常用参数：
参数 作用 -d 删除密码 -S 查询用户密码的状态 -l 锁定用户密码 -u 解锁用户密码 操作演示：
设置当前登录用户的密码：
[root@localhost ~]# passwd 设置用户xiaobei的密码
[root@localhost ~]# passwd xiaobei 清除用户 xiaobei 的密码
[root@localhost ~]# passwd -d xiaobei 1.3 查看当前登录用户 使用命令who 与 w 命令可以查询当前系统上已登录用户的相关信息。
语法格式： who [参数]
常用参数：
参数 作用 -a 打印全面信息 -b 打印系统最近引导时间 -H 带有列名打印信息 -u 打印已登录用户列表 操作演示： 输出当前已登录的用户信息(带列名打印)
[root@localhost ~]# who -H 名称 线路 时间 备注 root pts/0 2020-12-30 16:16 (192.168.3.8) 123 注释：线路列表中的 pts/0 ，pts代表远程终端登录，如果输出了 tty1，则tty代表本地终端登录。
语法格式： w [参数]
常用参数：
参数 作用 -h 不带列名输出 -s 使用短格式输出 操作演示： 输出当前已登录用户信息(带列名输出)
[root@localhost ~]# w USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 192.168.3.8 16:16 0.00s 0.46s 0.01s w 123 注释：LOGIN@ 代表登录时间，IDLE表示空闲时间，JCPU是与该终端连接的进程占用的时间，PCPU 是用户当前进程所占用的时间。
1.4 修改用户属性 使用usermod命令，可以修改用户相关属性和信息。
语法格式： usermod [参数] &lt;用户名&gt;
常用参数：
参数 作用 -u 修改用户UID -c 修改用户的说明/备注 -g 修改用户的所属用户组 -G 修改用户的附加组 -L 锁定用户密码 -U 解锁用户密码 -s 修改用户的登录shell 操作演示：
设置用户xiaobei的登录shell为nologin 使其无法登录
[root@localhost ~]# usermod -s /sbin/nologin xiaobei 1.5 用户密码有效性 使用chage命令修改用户和用户密码的有效期限，这个信息由系统用于确定用户何时必须更改其密码。
语法格式： chage [参数] [用户名]
常用参数：
参数 作用 -M 密码保持有效的最大天数 -W 用户密码到期前，提前收到警告信息的天数 -E 帐号到期的日期，会禁止此帐号 -d 上一次更改的日期 -l 显示用户的密码相关信息 操作演示：
使用户 xiaobei 的密码有效期最大为30天。
[root@localhost ~]# chage -M 30 xiaobei 1.6 删除用户 使用命令userdel删除用户。在删除之前确定用户没有登录。
语法格式： userdel [参数] [用户名]
常用参数：
参数 作用 -f 强制删除用户账号 -r 同时删除用户的家目录 操作演示： 删除用户 test01 同时删除该用户的家目录
[root@localhost ~]# userdel -r test01 1.7 切换登录用户 使用 su 命令切换当前登录用户。root 用户切换普通用户时不需要输入密码，反之需要。
语法格式： su [用户名]
常用参数：
参数 作用 -c 仅执行一次命令，不切换用户身份 操作演示：
切换到用户 xiaobei
[root@localhost ~]# su xiaobei 切换到用户 root 同时一起切换环境变量。
[xiaobei@localhost ~]$ su - root 用root用户执行一条命令 useradd
[xiaobei@localhost ~]$ su - root -c &#34;useradd test01&#34; 1.8 踢出当前登录中的用户 我们想对某用户进行删除操作的时候，发现该用户正在被登录，这个时候我们就可以用命令 pkill ，使该用户被迫下线。知晓linux系统的同仁应该会了解，该命令其实是一个杀死进程的命令。其实在这里可以踢出登录的用户，也是可以理解的，因为一个用户在系统上登录，是会产生对应的进程的。因为在本贴我们主讲用户管理，所以在这里只介绍这一种用法。
语法格式： pkill -9 -t &lt;终端号&gt;
操作演示：
踢出在远程终端 终端号为 pts/1 登录的用户。
[root@localhost ~]# pkill -9 -t pts/1 操作解释：
这里的 -9 参数，是linux系统中的kill信号，在这里我们只需要知道这条命令可以立即踢出一个用户即可。 参数 -t 代表指定终端号。前面我们讲到过，可以通过 w 命令和 who 命令查询当前都有哪些用户登录，这里就是要配合这两个命令使用的，我们需要知道要踢出的用户所登录的终端号，一般踢出的都是远程用户，所以基本都是pts开头，这两个查询命令都可以查到用户登录的终端号，这个时候再使用该命令按终端号踢出用户，该用户就会立即下线。
1.9 查询用户登录信息 在Linux系统中可以查询到所有用户的登录信息，以及系统上近期的登录信息，通过两个命令可以查询：lastlog 和 last。
语法格式： lastlog [参数]
常用参数：
参数 作用 -b 显示指定天数前的登录信息 -t 显示指定天数以来的登录信息 -u 显示指定用户的最后一次的登录信息 操作演示：
查询root用户最后一次的登录信息
[root@localhost ~]# lastlog -u root 查询UID为 1000 的用户最近7天有没有登录过(有就会输出信息)。
[root@localhost ~]# lastlog -t 7 -u 1000 使用last命令查看的是系统上的用户登录记录及信息，以时间排序。
语法格式： last [参数]
常用参数：
参数 作用 -R 简略输出(短格式) -n 指定最近几条记录 操作演示：
查询系统上最近的十条登录信息。
[root@localhost ~]# last -n 10 使用lastb命令查看的是系统上的用户登录失败的记录及信息
语法格式： lastb [参数]
常用参数：
参数 作用 -a 把从何处登入系统的主机名称或ip地址显示在最后一行 -n 设置列出名单的显示列数 -R 不显示登入系统的主机名称或IP地址 -x 显示系统关机，重新开机，以及执行等级的改变等信息 操作演示： 查询登录失败所有的信息
[root@localhost ~]#lastb 1.10 查询用户UID及GID信息 使用 id 命令可以查询用户的UID以及所属用户组的GID信息。
语法格式： id [参数] [用户名]
常用参数：
参数 作用 -r 显示实际ID -u 显示用户ID -g 显示用户所属群组的ID -G 显示用户所属附加群组的ID -n 显示用户，所属群组或附加群组的名称 操作演示：
查询用户 xiaobei 的所有ID的信息
[root@localhost ~]# id xiaobei 1.11 退出登录 使用命令 logout 退出登录。远程终端以及su命令登录的用户也可用 exit 退出。
二.用户组管理命令 在前面我们提到过，在创建新用户时，会同时创建一个与该用户同名的用户组。这是因为Linux中的用户，必须有一个所属组，如果在创建用户时指定一个所属组，就不会创建与其同名的组了。下面我们只简单介绍几个组管理的命令。
2.1 添加用户组 使用命令groupadd 添加用户组。
语法格式： groupadd [参数] &lt;组名&gt;
常用参数：
参数 作用 -g 创建的同时制定用户组ID 操作演示：
添加用户组 userg 并指定id为6666
[root@localhost ~]# groupadd -g 6666 userg 2.2 修改组属性 使用命令groupmod 修改用户组的信息。
语法格式： groupmod [参数] &lt;组名&gt;
常用参数：
参数 作用 -n 修改组名 -g 修改新的GUID 操作演示：
修改用户组 userg 组名为testgroup
[root@localhost ~]# groupmod testgroup userg 2.3 设置用户组 使用命令gpasswd 来设置组和组内成员
语法格式： gpasswd &lt;参数 &gt; &lt;组名&gt;
常用参数：
参数 作用 -a 添加用户到组 -d 从组删除用户 操作演示：
把用户 xiaobei 添加到 group01 用户组
[root@localhost ~]# gpasswd -a xiaobei group01 2.4 删除用户组 使用命令groupdel 来设置组和组内成员。如果组内有初始用户，则不能删除，如果组内有附加用户，也可以删除。
语法格式： groupdel [参数] &lt;组名&gt;
操作演示：
删除用户组 test01
[root@localhost ~]# groupdel test01 三.用户管理相关的配置文件 以上所有的用户管理、组管理命令，包括用户的添加、删除，密码的修改，有效期设置等命令的操作，均会保存在配置文件中，也就是命令的操作也就是修改配置文件。换一种说法，例如我们要修改某用户的密码有效期，除了可以使用命令，还可以直接修改Linux中记录用户信息的配置文件。都可以达到同样的效果。
3.1 用户信息配置文件 通过命令进行创建、修改用户以及相关操作，都是对配置文件/etc/passwd的修改。比如修改用户家目录，可以用命令 usermod 修改，也可以直接修改文件中的第六个字段。该文件除了记录普通用户的信息，也记录了系统用户的信息。切记，系统用户的信息不要轻易更改，否则进行某相关操作时，会导致系统错误。 通过命令 less /etc/passwd 或者 vim /etc/passwd 可以查看以及修改该配置文件。
文件概览： 字段对应信息：
1.用户名称：2.密码标志：3.UID：4.GID ：5.用户说明/备注：6.家目录：7.登录的shell
字段解释：
密码标志 x 代表该用户有密码。 UID中 0 代表超级用户，RedHat、CentOS系列的发行版中，1-499为系统用户(伪用户),通过配置文件可以看到它们的shell解释器都为nologin也就是不登录。500-65535为普通用户可用的UID。 用户的附加组可以有多个。
3.2 用户密码信息配置文件 在Linux系统中/etc/shadow文件存放用户密码信息，又称为“影子文件”。由于存放了密码信息，为了保证安全性，该文件只有root用户可以读取。
文件概览： 字段对应信息：
1.用户名称：2.加密密码：3.密码最后一次修改日期：4.两次密码的修改间隔：5.密码有效期：6.有效期到期前的警告天数：7.宽限天数：8.账号失效时间
字段解释：
加密密码采用了SHA512散列加密算法。如果该字段为 !! 或 * 就代表该用户不能登录。 该文件所有的日期格式均采用时间戳。 两次密码的修改间隔为天数，10 就代表修改过一次密码后十天内不能再次修改。
unix时间戳是从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数，不考虑闰秒。 Unix时间戳（英文为Unix epoch, Unix time, POSIX time 或 Unix timestamp） 是从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数，不考虑闰秒。 UNIX时间戳的0按照ISO 8601规范为 ：1970-01-01T00:00:00Z. 一个小时表示为UNIX时间戳格式为：3600秒；一天表示为UNIX时间戳为86400秒，闰秒不计算。 在大多数的UNIX系统中UNIX时间戳存储为32位，这样会引发2038年问题或Y2038。 &mdash;&mdash;&ndash; 百度百科
第七字段宽限天数，代表用户封禁前的缓冲天数，如果该值为3，就代表有效期过三天后再进行用户封禁。
3.3 创建用户默认配置信息文件 在创建用户时，我们可以手动指定家目录。如果不指定，就会默认把家目录放到/home目录下。如果我想让它默认创建到其他位置呢？我们就可以通过修改配置文件/etc/default/useradd文件来实现。
文件概览： 字段解释：
HOME字段控制创建用户时默认的家目录位置 INACTIVE为密码过期的宽限天数 SHELL创建用户默认的登录shell SKEL为家目录的模板目录 CREATE_MAIL_SPOOL是否建立邮箱 GROUP用户的默认组 EXPIRE密码失效时间
3.4 用户限制设定配置文件 在配置文件/etc/login.defs中，记录了用户限制设定。该文件的作用是为了对用户更为规范的管理，例如用户默认的密码有效期，就可以通过该文件进行修改，就是前面有讲到的chage命令相关的，不过该文件修改的是用户创建时的默认项，相当于一个模板文件。注意，该文件设置对用户root不生效。
文件概览： 部分字段解释： PASS_MAX_DAYS 默认密码有效期 UID_MIN UID的最小值 PASS_MIN_DAYS 两次密码修改的间隔。
四.组管理相关的配置文件 与用户管理相同，除了命令，也可以通过直接修改配置文件来达到对组的配置。
4.1 组信息配置文件 用户组的配置文件位置为/etc/group。
文件概览： 字段对应信息：
1.组名：2.组密码标志：3.GID：4.组中附加用户
4.2 组密码信息配置文件 组密码信息文件/etc/gshadow中存放着用户组的密码以及管理员用户名。
文件概览： 字段对应信息：
1.组名：2.组密码：3.组管理员用户名：4.组中附加用户
五. 快速创建示例 #查看用户信息 less /etc/passwd #查看组信息 less /etc/group #创建用户组 groupadd colzry #创建用户家目录 mkdir -p /home/colzry #创建用户 useradd -d /home/colzry -s /bin/bash colzry #设置用户密码 passwd colzry #用户家目录赋权755 chmod -R 755 /home/colzry #切换用户 su colzry #修改文件所属用户:组 chown -R colzry:colzry filename ]]></content></entry><entry><title>Maven快速入门</title><url>/posts/java/maven-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url><categories><category>Java</category></categories><tags><tag>Java</tag><tag>Maven</tag></tags><content type="html"><![CDATA[Maven的作用 项目的自动构建，帮助开发人员做项目代码的编译，测试， 打包，安装，部署等工作。 管理依赖（管理项目中使用的各种jar包）。 依赖：项目中需要使用的其他资源， 常见的是jar 。 比如项目要使用mysql驱动。我们就说项目依赖mysql驱动。 Maven 安装 确定JAVA_HOME 指定jdk的安装目录， 如果没有JAVA_HOME， 需要在windows的环境变量中创建JAVA_HOME, 它的值是jdk的安装目录 解压缩 apache-maven-3.3.9-bin.zip ，把解压后的文件放到一个目录中。 目录的路径不要有中文，不要有空格。 把maven安装目录中下的bin的路径添加到path中 测试maven的安装。 在命令行执行 mvn -v C:\Users\NING MEI&gt;mvn -v Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00) Maven home: D:\tools\apache-maven-3.3.9\bin\.. Java version: 1.8.0_101, vendor: Oracle Corporation Java home: C:\Program Files\Java\jdk1.8.0_101\jre Default locale: zh_CN, platform encoding: GBK OS name: &#34;windows 10&#34;, version: &#34;10.0&#34;, arch: &#34;amd64&#34;, family: &#34;dos&#34; maven解压后的目录结构 maven的其他安装方式：
确定JAVA_HOME是否有效 在环境变量中，创建一个叫做M2_HOME (或者MAVEN_HOME) ，它的值是maven的安装目录 M2_HOME=D:\tools\apache-maven-3.3.9 在path环境变量中，加入 %M2_HOME%\bin 测试maven的安装，在命令行执行 mvn -v C:\Users\NING MEI&gt;mvn -v Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00) Maven home: D:\tools\apache-maven-3.3.9\bin\.. Java version: 1.8.0_101, vendor: Oracle Corporation Java home: C:\Program Files\Java\jdk1.8.0_101\jre Default locale: zh_CN, platform encoding: GBK OS name: &#34;windows 10&#34;, version: &#34;10.0&#34;, arch: &#34;amd64&#34;, family: &#34;dos&#34; Maven的核心概念 目录结构 一个maven项目是一个文件夹。 比如项目叫做Hello
Hello 项目文件夹 \src \main	叫做主程序目录（完成项目功能的代码和配置文件） \java 源代码（包和相关的类定义） \resources	配置文件 \test 放置测试程序代码的（开发人员自己写的测试代码） \java 测试代码的（junit） \resources 测试程序需要的配置文件 \pom.xml maven的配置文件， 核心文件 POM POM： Project Object Model 项目对象模型， maven把项目当做模型处理。 操作这个模型就是操作项目。
maven通过pom.xml文件实现 项目的构建和依赖的管理。
&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt; &lt;!-- project是根标签， 后面的是约束文件 --&gt; &lt;project xmlns=&#34;http://maven.apache.org/POM/4.0.0&#34; xmlns:xsi=&#34;http://www.w3.org/2001/XMLSchema-instance&#34; xsi:schemaLocation=&#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&#34;&gt; &lt;!-- pom模型的版本， 就是4.0.0 --&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 坐标 --&gt; &lt;groupId&gt;com.bjpowernode&lt;/groupId&gt; &lt;artifactId&gt;ch01-maven&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;/project&gt; 坐标 坐标组成是 groupid, artifiactId, version。
坐标作用：确定资源的，是资源的唯一标识。 在maven中，每个资源都是坐标。 坐标值是唯一的。简称叫gav
&lt;groupId&gt;com.bjpowernode&lt;/groupId&gt; &lt;artifactId&gt;ch01-maven&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; groupId: 组织名称，代码。 公司，团体或者单位的标识。 这个值常使用的公司域名的倒写。 例如：学校的网站 www.bjpowernode.com, groupId: com.bjpowernode 如果项目规模比较大， 也可以是 域名倒写+大项目名称。 例如： www.baidu.com , 无人车： com.baidu.appollo artifactId:项目名称， 如果groupId中有项目， 此时当前的值就是子项目名。 项目名称是唯一的。 version：版本， 项目的版本号， 使用的数字。 三位组成。 例如 主版本号.次版本号.小版本号， 例如： 5.2.5。 注意：版本号中有-SNAPSHOT， 表示快照，不是稳定的版本。 packaging 项目打包的类型， 有jar ，war， ear， pom等等 默认是jar 依赖 dependency 依赖：项目中要使用的其他资源（jar）。
需要使用maven表示依赖，管理依赖。 通过使用dependency和gav一起完成依赖的使用
需要在pom.xml文件中，使用dependencies 和dependency， 还有gav 完成依赖的说明。
格式：
&lt;dependencies&gt; &lt;!-- 日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; maven使用gav作为标识，从互联网下载依赖的jar。 下载到你的本机上。 由maven管理项目使用的这些jar 搜索依赖的地址： https://mvnrepository.com/ 仓库 仓库是存东西的，maven的仓库存放的是：
maven工具自己的jar包。 第三方的其他jar， 比如项目中要使用mysql驱动。 自己写的程序，可以打包为jar 。 存放到仓库。 仓库的分类：
本地仓库：默认路径，是你登录操作系统的账号的目录中%HOMEPATH%/.m2/repository C:\Users\NING MEI\.m2\repository 修改本地仓库的位置：修改maven工具的配置文件（maven的安装路径\conf\setting.xml） 步骤： 1）创建一个目录，作为仓库使用。 目录不要有中文和空格。 目录不要太深。 例如： D:\openrepository 2）修改setting.xml文件，指定 D:\openrepository这个目录
远程仓库： 需要通过联网访问的 1）中央仓库： 一个ftp服务器， 存放了所有的资源。 2）中央仓库的镜像： 就是中央仓库的拷贝。 在各大主要城市都有镜像。 3）私服：在局域网中使用的。 私服就是自己的仓库服务器。 在公司内部使用的。 maven使用仓库： maven自动使用仓库， 当项目启动后， 执行了maven的命令， maven首先访问的是本地仓库， 从仓库中获取所需的jar， 如果本地仓库没有 ，需要访问私服或者中央仓库或者镜像。
maven的生命周期 maven的生命周期： 项目构建的各个阶段。 包括 清理， 编译， 测试，报告，打包，安装，部署
命令 mvn clean	清理命令 mvn compile	编译命令 mvn test	测试命令 mvn package	打包 mvn install 把生成的打包的文件 ，安装到maven仓库。 mvn deploy	部署 IDEA的使用 在IDEA中创建Maven项目
pom.xml的配置 &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt; &lt;project xmlns=&#34;http://maven.apache.org/POM/4.0.0&#34; xmlns:xsi=&#34;http://www.w3.org/2001/XMLSchema-instance&#34; xsi:schemaLocation=&#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&#34;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;MavenDemo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;14&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;14&lt;/maven.compiler.target&gt; &lt;!--项目构建使用的编码，避免中文乱码--&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;!--生成报告的编码--&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!--自定义Spring版本变量--&gt; &lt;spring.version&gt;5.2.12.RELEASE&lt;/spring.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13.1&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 更改IDEA中的Maven成本地安装的Maven Maven 配置阿里镜像 在Maven的安装目录的conf下修改settings.xml文件，添加下面的内容
&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;huaweicloud&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus huaweicloud&lt;/name&gt; &lt;url&gt;https://repo.huaweicloud.com/repository/maven/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;nexus-tencentyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus tencentyun&lt;/name&gt; &lt;url&gt;http://mirrors.cloud.tencent.com/nexus/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; 修改UTF-8为默认编码 设置环境变量
变量名 MAVEN_OPTS
变量值 -Xms256m -Xmx512m -Dfile.encoding=UTF-8
Linux安装Maven wget https://repo.huaweicloud.com/apache/maven/maven-3/3.9.0/binaries/apache-maven-3.9.0-bin.tar.gz tar -zxvf apache-maven-3.9.0-bin.tar.gz -C /usr/local/ cat &gt; /etc/profile.d/my_env.sh &lt;&lt;-EOF export M2_HOME=/usr/local/apache-maven-3.9.0 export PATH=$M2_HOME/bin:$PATH EOF source /etc/profile ]]></content></entry><entry><title>MyBatis使用示例</title><url>/posts/java/mybatis%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/</url><categories><category>Java</category></categories><tags><tag>Java</tag><tag>MyBatis</tag></tags><content type="html"><![CDATA[什么是 MyBatis？ MyBatis 是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。MyBatis 可以通过简单的 XML 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。
创建MyBatis项目 使用 IDEA 建立一个 SpringBoot 项目，初始化组件部分选择 Web、JDBC API、MyBatis Framework、MySQL Driver
若创建失败或者创建太慢，可以更换阿里镜像： https://start.aliyun.com 创建数据库 CREATE DATABASE IF NOT EXISTS mybatis; USE mybatis; 其对应的数据库 Schema 脚本如下：
DROP TABLE IF EXISTS user; CREATE TABLE user ( id BIGINT(20) NOT NULL COMMENT &#39;主键ID&#39;, name VARCHAR(30) NULL DEFAULT NULL COMMENT &#39;姓名&#39;, age INT(11) NULL DEFAULT NULL COMMENT &#39;年龄&#39;, email VARCHAR(50) NULL DEFAULT NULL COMMENT &#39;邮箱&#39;, PRIMARY KEY (id) ); 其对应的数据库 Data 脚本如下：
INSERT INTO user (id, name, age, email) VALUES (1, &#39;Jone&#39;, 18, &#39;test1@baomidou.com&#39;), (2, &#39;Jack&#39;, 20, &#39;test2@baomidou.com&#39;), (3, &#39;Tom&#39;, 28, &#39;test3@baomidou.com&#39;), (4, &#39;Sandy&#39;, 21, &#39;test4@baomidou.com&#39;), (5, &#39;Billie&#39;, 24, &#39;test5@baomidou.com&#39;); 创建对应的程序目录和类 controller层负责具体的业务模块流程的控制 dao层主要是做数据持久层的工作，负责与数据库联络，封装了增删改查基本操作 entity层用于存放我们的实体类，与数据库中的属性值基本保持一致，实现set和get的方法 service层主要负责业务模块的逻辑应用设计，具体要调用到已定义的DAO层的接口 package com.colzry.mybatis.entity; import lombok.Data; @Data public class User { private Integer id; private String name; private Integer age; private String email; } package com.colzry.mybatis.dao; import com.colzry.mybatis.entity.User; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; import org.apache.ibatis.annotations.Select; import org.springframework.stereotype.Repository; import java.util.List; @Mapper @Repository public interface UserDao { @Select(&#34;select * from user where id=#{id}&#34;) public User getUserById(@Param(&#34;id&#34;) Integer id); @Select(&#34;select * from user where age &gt;= #{age}&#34;) public List&lt;User&gt; getUserByGtAge(@Param(&#34;age&#34;) int age); } package com.colzry.mybatis.service; import com.colzry.mybatis.dao.UserDao; import com.colzry.mybatis.entity.User; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import java.util.List; @Service public class UserService { @Autowired private UserDao userDao; public User queryUser(int id) { return userDao.getUserById(id); } public List&lt;User&gt; queryUser01(int age) { return userDao.getUserByGtAge(age); } } package com.colzry.mybatis.controller; import com.colzry.mybatis.entity.User; import com.colzry.mybatis.service.UserService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import java.util.List; @RestController public class UserController { @Autowired private UserService userService; @RequestMapping(&#34;/user&#34;) public User getUser(@RequestParam(&#34;id&#34;) int id) { return userService.queryUser(id); } @RequestMapping(&#34;/user01&#34;) public List&lt;User&gt; getUserByAge(@RequestParam(&#34;age&#34;) int age) { return userService.queryUser01(age); } } 编写配置文件 对应的application.yml文件
server: port: 9090 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC username: mybatis password: 123456 mybatis: mapper-locations: classpath:/mappers/*.xml type-aliases-package: com.colzry.mybatis.entity 运行项目 运行MyBatisApplication主程序
在浏览器中访问本地的9090端口，输入以下两个内容进行测试
http://localhost:9090/user?id=1 http://localhost:9090/user01?age=18 ]]></content></entry><entry><title>mycli的安装和使用</title><url>/posts/mysql/mycli%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/</url><categories><category>MySQL</category></categories><tags><tag>MySQL</tag></tags><content type="html">1. 安装 dnf install python3 pip3 install mycli 2. 使用 mycli -u user -h host database</content></entry><entry><title>MySQL对用户的管理</title><url>/posts/mysql/mysql%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E7%AE%A1%E7%90%86/</url><categories><category>MySQL</category></categories><tags><tag>MySQL</tag></tags><content type="html"><![CDATA[1. 查看用户 use mysql; select * from user; 示例
kylin@kylin:~$ mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 14 Server version: 5.7.33 MySQL Community Server (GPL) Copyright (c) 2000, 2021, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement. mysql&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) mysql&gt; use mysql; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql&gt; select * from user; 2. 创建用户 create user &#39;user_name&#39;@&#39;host&#39; identified by &#39;passwd&#39;; user_name 表示要创建的用户名 host 表示新创建的用户允许从哪台机器登录，&rsquo;localhost&rsquo;表示本机登录，&rsquo;%&rsquo; 表示远程登录 passwd 表示新用户的密码
示例
// 用户名为 mysql 只允许从本地登录 密码为 mysql create user &#39;mysql&#39;@&#39;localhost&#39; identified by &#39;mysql&#39;; // 用户名为 mysql 允许远程登录 密码为 mysql create user &#39;mysql&#39;@&#39;%&#39; identified by &#39;mysql&#39;; 3. 授权用户 grant privileges on database_name.table_name to &#39;user_name&#39;@&#39;host&#39;; privileges 表示要授予的权力，有 **select，insert，delete，update **等，如果要授予全部权力，就填 all database_name.table_name 表示用户的权限能在某库某表中使用，如果要作用于数据库中的所有表，则填 . user_name 表示授权的用户 host 可填 localhost 或 %
示例
// 给test用户授予employee库job表的插入和查询权限 grant inster,select on employess.job to &#39;test&#39;@&#39;%&#39;; // 给mysql用户授予所有库所有表的所示权限 grant all on *.* to &#39;mysql&#39;@&#39;%&#39;; 提示：如果当前是普通用户在执行命令则不能给其他用户授权，要想授权，需要在后面加上 with grant option
grant all on *.* to &#39;mysql&#39;@&#39;%&#39; with grant option; 4. 更改用户的登录方式和密码 将本地登录改为可远程登录
use mysql; // 其中user_name为要更改的用户名 update user set host=&#39;%&#39; where user = &#39;user_name&#39;; // 刷新权限 flush privileges; 更改密码
// 法一 // user_name为要更改的用户名 new_passwd为要更改的密码 set password for user_name@localhost = password(&#39;new_passwd&#39;); // 法二 // name为要更改的用户名 new_passwd为要更改的密码 set password=password(&#39;new_passwd&#39;); grant all on *.* to &#39;user_name&#39;@&#39;%&#39; identified by &#39;new_passwd&#39;; flush privileges; 5. 撤销用户的权限 revoke privileges on database_name.table_name from &#39;user_name&#39;@&#39;host&#39;; 6. 删除用户 drop user &#39;usre_name&#39;@&#39;host&#39;; ]]></content></entry><entry><title>MySQL入门</title><url>/posts/mysql/mysql%E5%85%A5%E9%97%A8/</url><categories><category>MySQL</category></categories><tags><tag>MySQL</tag></tags><content type="html"><![CDATA[1. MySQL的介绍 1.1 MySQL的背景 前身属于瑞典的一家公司，MySQL AB 08年被sun公司收购 09年sun被oracle收购
1.2 MySQL的优点 1、开源、免费、成本低 2、性能高、移植性也好 3、体积小，便于安装
2. 准备操作 win10安装 Linux安装 打开管理员控制台
mysql -u root -p 查看数据库
show databases; 选择要操作的数据库
use 库名; 看看该库里面的表
show tables; 查看某个表的结构
desc 表名; 3. 查询语言的分类 在了解 SQL 之前我们需要知道下面这几个概念
数据定义语言：简称DDL (Data Definition Language)，用来定义数据库对象:数据库、表、列等； 数据操作语言：简称DML (Data Manipulation Language)，用来对数据库中表的记录进行更新。关键字：insert、update、delete等 数据控制语言：简称DCL(Data Control Language)，用来定义数据库访问权限和安全级别，创建用户等。关键字：grant等 数据查询语言：简称DQL(Data Query Language)，用来查询数据库中表的记录，关键字：select from where等 4. DDL语言 4.1 库的管理 注：方括号内的为选填内容【选填内容】
4.1.1 创建数据库 create database 【if not exists】 库名; 4.1.2 修改数据库 alter database 库名 character set 字符集名; 查看MYSQL数据库服务器和数据库字符集 show variables like &#39;%character%&#39;; 查看MYSQL所支持的字符集 show charset; 4.1.3 删除数据库 drop database 【if exists】 库名; 4.2 表的管理 在这之前先了解一下字段类型和约束
4.2.1 字段类型 整型 类型名称 所占字节大小 tinyint 1 byte smallint 2 byte mediumint 3 byte int/integer 4 byte bigint 8 byte 特点： ①都可以设置无符号和有符号，默认有符号，通过unsigned设置无符号 ②如果超出了范围，会报out or range异常，插入临界值 ③长度可以不指定，默认会有一个长度（长度代表显示的最大宽度，如果不够则左边用0填充，但需要搭配zerofill，并且默认变为无符号整型）
浮点型 定点数：decimal(M,D) 浮点数: float(M,D)	4 byte double(M,D)	8 byte 特点： ①M代表整数部位+小数部位的个数，D代表小数部位 ②如果超出范围，则报out or range异常，并且插入临界值 ③M和D都可以省略，但对于定点数，M默认为10，D默认为0 ④如果精度要求较高，则优先考虑使用定点数
字符型 char：固定长度的字符，写法为char(M)，最大长度不能超过M，其中M可以省略，默认为1 varchar：可变长度的字符，写法为varchar(M)，最大长度不能超过M，其中M不可以省略
日期型 year 年 date 日期 time 时间 datetime 日期+时间	8 byte timestamp 日期+时间	4 byte 比较容易受时区、语法模式、版本的影响，更能反映当前时区的真实时间
4.2.2 约束 常见的约束 NOT NULL：非空，该字段的值必填 UNIQUE：唯一，该字段的值不可重复 DEFAULT：默认，该字段的值不用手动插入有默认值 PRIMARY KEY：主键，该字段的值不可重复并且非空 unique+not null FOREIGN KEY：外键，该字段的值引用了另外的表的字段
主键和唯一
区别： ① 一个表至多有一个主键，但可以有多个唯一 ② 主键不允许为空，唯一可以为空 相同点： 都具有唯一性 都支持组合键，但不推荐 4.2.3 创建表 create table 【if not exists】表名( 字段名 字段类型 【约束】, 字段名 字段类型 【约束】, ...... 字段名 字段类型 【约束】 ); create table 表名( 字段名 字段类型 not null, #非空 字段名 字段类型 primary key, #主键 字段名 字段类型 unique, #唯一 字段名 字段类型 default 值, #默认 字段名 enum(&#39;值1&#39;,&#39;值2&#39;,&#39;值3&#39;...) not null default &#39;值1&#39; constraint 约束名 foreign key(字段名) references 主表(被引用列) ); 创建表时设置自增长列
create table 表( 字段名 字段类型 约束 auto_increment ) 4.2.4 修改表 alter table 表名 add|drop|modify|change column 列名 【列类型 约束】; # 1. 添加列 alter table 表名 add column 列名 类型 【first|after 字段名】; # 2. 修改列的类型或约束 alter table 表名 modify column 列名 新类型 【新约束】; # 3. 修改列名 alter table 表名 change column 旧列名 新列名 类型; # 4. 删除列 alter table 表名 drop column 列名; # 5. 修改表名 alter table 表名 rename 【to】 新表名; # 6.设定必须值 alter table 表名 modify column 字段 enum(&#39;教授&#39;,&#39;副教授&#39;,&#39;讲师&#39;,&#39;助教&#39;) not null default &#39;教授&#39;; 修改表时设置自增长列
alter table 表 modify column 字段名 字段类型 约束 auto_increment; 4.2.5 删除表 drop table 【if exists】 表名; 删除自增长列
alter table 表 modify column 字段名 字段类型 约束; 4.2.6 复制表 # 1. 复制表的结构 create table 表名 like 旧表; # 2. 复制表的结构+数据 create table 表名; select 查询列表 from 旧表【where 筛选】; 5. DQL语言 5.1 基础查询 1、查询单个字段 select 字段名 from 表名; 2、查询多个字段 select 字段名，字段名 from 表名; 3、查询所有字段 select * from 表名 4、查询常量 select 常量值; 注意：字符型和日期型的常量值必须用单引号引起来，数值型不需要 5、查询函数 select 函数名(实参列表); 6、查询表达式 select 100/1234; 5.2 条件查询 select 查询列表 from 表名 where 筛选条件; 筛选条件的分类 简单条件运算符 &lt; = &lt;&gt; != &gt;= &lt;= &lt;=&gt;安全等于
逻辑运算符 &amp;&amp; and || or ! not 5.3 排序查询 select 查询列表 from 表 where 筛选条件 order by 排序列表 【asc | desc】; 说明：
asc ：升序，如果不写默认升序 desc：降序 order by 的位置一般放在查询语句的最后（limit语句除外） 5.4 分页查询 对于排序后的字段，或者不排序的字段，如果只希望显示一部分的话，就会使用 LIMIT 关键字来实现，比如我们只想取前三条记录
select * from 表名 limit 3; 或者我们对排序后的字段取前三条记录
select * from 表名 order by 排序列表 desc limit 3; 上面这种 limit 是从表记录的第 0 条开始取，如果从指定记录开始取，比如从第二条开始取，取三条记录
select * from 表名 order by 排序列表 desc limit 2,3; 注意：limit 是 MySQL 扩展 SQL92 之后的语法，在其他数据库比如 Oracle 上就不通用
5.5 分组查询 select 分组函数，分组后的字段 from 表 【where 筛选条件】 group by 分组的字段 【having 分组后的筛选】 【order by 排序列表】; 5.6 聚合查询 下面我们来看一下对记录进行汇总的操作，这类操作主要有
汇总函数，比如 sum 求和、count 统计数量、max 最大值、min 最小值等 group by，关键字表示对分类聚合的字段进行分组，比如按照部门统计员工的数量，那么 group by 后面就应该跟上部门 with 是可选的语法，它表示对汇总之后的记录进行再次汇总 having 关键字表示对分类后的结果再进行条件的过滤。 看起来 where 和 having 意思差不多，不过它们用法不一样，where 是使用在统计之前，对统计前的记录进行过滤，having 是用在统计之后，是对聚合之后的结果进行过滤。也就是where 永远用在 having 之前，我们应该先对筛选的记录进行过滤，然后再对分组的记录进行过滤。
可以对 employees表中员工薪水进行统计，选出总共的薪水、最大薪水、最小薪水
select sum(salary) from employees; select max(salary),min(salary) from employees; 统计 employees表中人员的数量
# as 别名 select count(1) as Persons from employees; 5.7 连接查询 select 表1的字段 left|right|inner join 表2的字段 on 连接条件; 内连接：选出两张表中互相匹配的记录 外连接：不仅选出匹配的记录，也会选出不匹配的记录 外连接分为两种
左外连接：筛选出包含左表的记录并且右表没有和它匹配的记录(以左表的内容为主，右表中没有的内容为空) 右外连接：筛选出包含右表的记录并且左表没有和它匹配的记录(以右表的内容为主，左表中没有的内容为空) 使用左外连接查询
select employees.name,departments.name from employees left join departments on employees.department_id = departments.id; 使用右外连接查询
select employees.name,departments.name from employees right join departments on employees.department_id = departments.id; 5.8 子查询 嵌套在其他语句内部的select语句称为子查询或内查询， 外面的语句可以是insert、update、delete、select等，一般select作为外面语句较多 外面如果为select语句，则此语句称为外查询或主查询 子查询的一些关键字 「in、not in、=、!=、exists、not exists」 等
# 最低工资 select min(salary) from employees; # 查询员工的姓名和工资，要求工资=最低工资 select name,salary from employees where salary=( select min(salary) from employees ); # 查询出每个人的工作类型，没有的则不显示 select * from employees where department_id in ( select id from departments ); 5.9 联合查询 我们还经常会遇到这样的场景，将两个表的数据单独查询出来之后，将结果合并到一起进行显示，这个时候就需要 UNION 和 UNION ALL 这两个关键字来实现这样的功能，UNION 和 UNION ALL 的主要区别是 UNION ALL 是把结果集直接合并在一起，而 UNION 是将 UNION ALL 后的结果进行一次 DISTINCT 去除掉重复数据。
select gender from employees union all select department_id from employees; select gender from employees union select department_id from employees; 6. DML语言 6.1 插入 insert into 表名 values(值,...); 假如表中有可以为null的字段，注意可以通过以下两种方式插入null值
insert into 表名(字段名,...) values(值,...); insert into 表名 set 字段=值,字段=值,...; 6.2 修改 修改单表的记录
update 表名 set 字段=值,字段=值 【where 筛选条件】; # 将Mike的薪水更改为12000 update employees set salary=12000 where name=&#39;Mike&#39;; 修改多表的记录
update 表1 别名 left|right|inner join 表2 别名 on 连接条件 set 字段=值,字段=值 【where 筛选条件】; 6.3 删除 法一：使用delete 删除单表的记录
delete from 表名 【where 筛选条件】; 删除多表的记录
delete 别名1,别名2 from 表1 别名 inner|left|right join 表2 别名 on 连接条件 【where 筛选条件】; 法二：使用truncate
truncate table 表名; 两种方式的区别：
truncate删除后，如果再插入，标识列从1开始 delete删除后，如果再插入，标识列从断点开始 delete可以添加筛选条件 truncate不可以添加筛选条件 truncate效率较高 truncate没有返回值 delete可以返回受影响的行数 truncate不可以回滚 delete可以回滚 7. TCL语言 7.1 事务 一、含义 事务：一条或多条sql语句组成一个执行单位，一组sql语句要么都执行要么都不执行
二、特点（ACID） A 原子性：一个事务是不可再分割的整体，要么都执行要么都不执行 C 一致性：一个事务可以使数据从一个一致状态切换到另外一个一致的状态 I 隔离性：一个事务不受其他事务的干扰，多个事务互相隔离的 D 持久性：一个事务一旦提交了，则永久的持久化到本地
三、事务的使用步骤 开启事务
set autocommit=0; start transaction; #可以省略 设置回滚点
savepoint 回滚点名; 结束事务
commit; #提交 rollback; #回滚 rollback to 回滚点名; #回滚到指定的地方 设置事务隔离级别
read uncommitted:读未提交 read committed：读已提交 repeatable read：可重复读 serializable：串行化
set transaction isolation level read committed; ]]></content></entry><entry><title>MySQL数据库的备份和恢复</title><url>/posts/mysql/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8D/</url><categories><category>MySQL</category></categories><tags><tag>MySQL</tag></tags><content type="html"><![CDATA[1. 备份 1.1创建备份脚本 在/usr/local/sbin/下新建mysql_backup.sh
sudo vim /usr/local/sbin/mysql_backup.sh 填入下面的内容
#!/bin/bash bakdir=/data/back # 定义备份文件存放目录 d=`date +%F` # 以日期(Y-M-D)为命名格式 user=colzry # 数据库用户名 (!自行更改) passwd=passwd # 密码 (!自行更改) # 备份两个数据库 typecho lsky (!自行更改) # 若要备份所以的数据库,则下面的整条for语句改为下面注释的内容 # mysqldump -u$user -p$passwd -A &gt; $bakdir/$db\_$d.sql for db in typecho lsky do mysqldump -u$user -p$passwd $db &gt; $bakdir/$db\_$d.sql done cd $bakdir # 对备份文件进行压缩 gzip *_$d.sql # 对备份时间超过一个月的文件进行删除 find ./ -name &#34;*.gz&#34; -mtime +30 | xargs rm -f 1.2 创建定时任务 用法 格式为 :
* * * * * 分 时 天 月 周 示例:
*/1 * * * * Command 每f分钟执行 0 */1 * * * Command 每小时执行 5 * * * * Command 每小时的第5分钟执行一次命令 30 18 * * * Command 指定每天下午的 6:30 执行一次命令 30 7 8 * * Command 指定每月8号的7：30分执行一次命令 30 5 8 6 * Command 指定每年的6月8日5：30执行一次命令 30 6 * * 0 Command 指定每星期日的6:30执行一次命令 crontab -e 编辑某个用户的cron服务 crontab -l 列出某个用户cron服务的详细内容 1.3 开始创建定时任务 sudo crontab -e # 每天凌晨3:30执行数据库的备份 30 3 * * * /bin/bash /usr/local/sbin/mysql_back.sh 2. 恢复 来到备份的目录
cd /data/back # lsky 为要恢复的数据库，回车后输入该用户的数据库密码即可 gunzip &lt; lsky_2021-08-19.sql.gz | mysql -u colzry -p lsky 3. 对Docker里的数据库备份 3.1 本地版 #!/bin/bash backdir=/data/back # 定义备份文件存放目录 d=`date +%F` # 以日期(Y-M-D)为命名格式 user=colzry # 数据库用户名 (!自行更改) passwd=colzry_admin # 密码 (!自行更改) # 检查本地文件夹是否存在 if [ ! -d $backdir ];then mkdir -p $backdir fi docker exec mysql sh -c &#39;exec mysqldump -u&#39;${user}&#39; -p&#39;${passwd}&#39; -A&#39; &gt; $backdir/$d.sql cd $backdir # 对备份文件进行压缩 gzip $d.sql # 对备份时间超过10天的文件进行删除 find ./ -name &#34;*.gz&#34; -mtime +10 | xargs rm -f 3.2 远程版 #!/bin/bash backdir=/data/back # 定义备份文件存放目录 d=`date +%F` # 以日期(Y-M-D)为命名格式 user=colzry # 数据库用户名 (!自行更改) passwd=colzry_admin # 密码 (!自行更改) host=root@47.120.35.102 # 服务器用户名和地址，使用前先上传ssh公钥 # 检查本地文件夹是否存在 if [ ! -d $backdir ];then mkdir -p $backdir fi docker exec mysql sh -c &#39;exec mysqldump -u&#39;${user}&#39; -p&#39;${passwd}&#39; -A&#39; &gt; $backdir/$d.sql cd $backdir # 对备份文件进行压缩 gzip $d.sql # 对备份时间超过10天的文件进行删除 find ./ -name &#34;*.gz&#34; -mtime +10 | xargs rm -f # 上传文件到服务器 rsync -av $d.sql.gz $host:$backdir ]]></content></entry><entry><title>MySQL一键安装脚本</title><url>/posts/mysql/mysql%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url><categories><category>MySQL</category></categories><tags><tag>MySQL</tag></tags><content type="html"><![CDATA[1. 安装脚本 wget https://files.catbox.moe/lwh5vs.sh -O /root/install-mysql.sh &amp;&amp; chmod +x /root/install-mysql.sh &amp;&amp; /root/install-mysql.sh 2. 默认密码 user: root password: admin
3. 其他方式 下载不了的话，运行下面脚本
3.1 使用yum的(建议使用) #!/bin/bash . /etc/init.d/functions SRC_DIR=`pwd` #MYSQL=&#39;mysql-5.7.33-linux-glibc2.12-x86_64.tar.gz&#39; MYSQL=&#39;mysql-5.7.35-linux-glibc2.12-x86_64.tar.gz&#39; COLOR=&#39;echo -e \E[01;31m&#39; END=&#39;\E[0m&#39; MYSQL_ROOT_PASSWORD=admin check (){ if [ $UID -ne 0 ]; then action &#34;当前用户不是root,安装失败&#34; false exit 1 fi cd $SRC_DIR `wget -c https://repo.huaweicloud.com/mysql/Downloads/MySQL-5.7/mysql-5.7.35-linux-glibc2.12-x86_64.tar.gz` if [ ! -e $MYSQL ];then $COLOR&#34;缺少${MYSQL}文件&#34;$END $COLOR&#34;请将相关软件放在${SRC_DIR}目录下&#34;$END exit elif [ -e /usr/local/mysql ];then action &#34;数据库已存在，安装失败&#34; false exit else return fi } install_mysql(){ $COLOR&#34;开始安装MySQL数据库...&#34;$END yum -y -q install chkconfig libncurses* libaio numactl-libs libaio &amp;&gt; /dev/null cd $SRC_DIR tar xf $MYSQL -C /usr/local/ MYSQL_DIR=`echo $MYSQL| sed -nr &#39;s/^(.*[0-9]).*/\1/p&#39;` ln -s /usr/local/$MYSQL_DIR /usr/local/mysql ln -s /usr/lib64/libtinfo.so.6.1 /usr/lib64/libtinfo.so.5 mkdir -p /data/mysql chown -R root.root /usr/local/mysql/ id mysql &amp;&gt; /dev/null || { useradd -s /sbin/nologin -r mysql ; action &#34;创建mysql用户&#34;; } echo &#39;PATH=/usr/local/mysql/bin/:$PATH&#39; &gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh ln -s /usr/local/mysql/bin/* /usr/bin/ cat &gt; /etc/my.cnf &lt;&lt;-EOF [mysqld] server-id=1 log-bin datadir=/data/mysql socket=/data/mysql/mysql.sock log-error=/data/mysql/mysql.log pid-file=/data/mysql/mysql.pid [client] socket=/data/mysql/mysql.sock EOF mysqld --initialize --user=mysql --datadir=/data/mysql cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld chkconfig mysqld on service mysqld start [ $? -ne 0 ] &amp;&amp; { $COLOR&#34;数据库启动失败，退出!&#34;$END;exit; } MYSQL_OLDPASSWORD=`awk &#39;/A temporary password/{print $NF}&#39; /data/mysql/mysql.log` mysqladmin -uroot -p$MYSQL_OLDPASSWORD password $MYSQL_ROOT_PASSWORD &amp;&gt;/dev/null action &#34;数据库安装完成&#34; } check install_mysql 运行mysql的命令报错：mysql: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory。
解决办法
yum install libncurses* 3.2 使用apt的系统 #!/bin/bash SRC_DIR=`pwd` MYSQL=&#39;mysql-5.7.30-linux-glibc2.12-x86_64.tar.gz&#39; MYSQL_DOWNLOAD_URL=&#34;https://repo.huaweicloud.com/mysql/Downloads/MySQL-5.7/mysql-5.7.30-linux-glibc2.12-x86_64.tar.gz&#34; Green_font_prefix=&#34;\033[32m&#34; Red_font_prefix=&#34;\033[31m&#34; Green_background_prefix=&#34;\033[42;37m&#34; Red_background_prefix=&#34;\033[41;37m&#34; Font_color_suffix=&#34;\033[0m&#34; Info=&#34;[${Green_font_prefix}信息${Font_color_suffix}]&#34; Error=&#34;[${Red_font_prefix}错误${Font_color_suffix}]&#34; Tip=&#34;[${Green_font_prefix}注意${Font_color_suffix}]&#34; MYSQL_ROOT_PASSWORD=czyadmin check_root() { [[ $EUID != 0 ]] &amp;&amp; echo -e &#34;${Error} 当前非ROOT账号(或没有ROOT权限)，无法继续操作，请更换ROOT账号或使用 ${Green_background_prefix}sudo su${Font_color_suffix} 命令获取临时ROOT权限（执行后可能会提示输入当前账号的密码）。&#34; &amp;&amp; exit 1 } check_is_installed() { if [ ! -e $MYSQL ];then echo -e &#34;${Error} 缺少${MYSQL}文件&#34; echo -e &#34;${Error} 请将相关软件放在${SRC_DIR}目录下&#34; exit 1 elif [ -e /usr/local/mysql ];then echo -e &#34;${Error} 数据库已存在，安装失败&#34; exit 1 else return fi } download_mysql() { cd $SRC_DIR if [ ! -e $MYSQL ];then echo -e &#34;${Tip} ${MYSQL}文件已下载到${SRC_DIR}目录下&#34; else wget &#34;${MYSQL_DOWNLOAD_URL}&#34; fi } install_mysql() { echo -e &#34;${Info} 开始安装MySql......&#34; echo -e &#34;${Info} 开始安装依赖...&#34; apt install sysv-rc-conf libaio.* libnuma.* libncurses.* -y &amp;&gt; /dev/null echo -e &#34;${Info} 依赖安装完成，开始解压MySql文件...&#34; cd $SRC_DIR tar zxf $MYSQL -C /usr/local/ echo -e &#34;${Info} 解压完成，开始配置MySql环境...&#34; MYSQL_DIR_NAME=`echo $MYSQL| sed -nr &#39;s/^(.*[0-9]).*/\1/p&#39;` mv /usr/local/$MYSQL_DIR_NAME /usr/local/mysql groupadd mysql useradd -g mysql mysql mkdir /usr/local/mysql/data chown -R mysql.mysql /usr/local/mysql/ echo &#39;PATH=/usr/local/mysql/bin/:$PATH&#39; &gt; /etc/profile.d/mysql.sh `source /etc/profile` cat &gt; /etc/my.cnf &lt;&lt;-EOF [mysql] # 设置mysql字符集 default-character-set=utf8 socket=/var/lib/mysql/mysql.sock [mysqld] skip-name-resolve #设置3306端口 port = 3306 socket=/var/lib/mysql/mysql.sock # 设置mysql的安装目录 basedir=/usr/local/mysql # 设置mysql数据库的数据存放目录 datadir=/usr/local/mysql/data # 设置最大连接数 max_connections=200 # 设置默认字符集 character-set-server=utf8 # 创建新表时将使用的默认存储引擎 default-storage-engine=INNODB lower_case_table_names=1 max_allowed_packet=16M EOF mkdir /var/lib/mysql chmod 777 /var/lib/mysql basedir=/usr/local/mysql datadir=/usr/local/mysql/data cd $basedir ./bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data cp ./support-files/mysql.server /etc/init.d/mysqld MYSQL_OLDPASSWORD=`awk &#39;/A temporary password/{print $NF}&#39; /usr/local/mysql/data/mysql.log` echo $MYSQL_OLDPASSWORD &gt; /usr/local/mysql/data/init_password.txt chmod +x /etc/init.d/mysqld sysv-rc-conf --add mysqld sysv-rc-conf mysqld on systemctl daemon-reload service mysqld start ln -s /var/lib/mysql/mysql.sock /tmp/mysql.sock ./bin/mysqladmin -uroot -p$MYSQL_OLDPASSWORD password $MYSQL_ROOT_PASSWORD &amp;&gt;/dev/null `source /etc/profile` echo -e &#34;${Info} MySql安装成功! &#34; } check_root download_mysql check_is_installed install_mysql ]]></content></entry><entry><title>NFS服务搭建</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/nfs%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>NFS</tag></tags><content type="html"><![CDATA[1.安装服务端 # Debian sudo apt install nfs-kernel-server # RedHat sudo yum install rpcbind nfs-utils 2. 更改配置文件 sudo vim /etc/exports 填入一下内容
# * 表示允许任何网段 IP 的系统访问该 NFS 目录 /nfs *(rw,sync,no_root_squash) 配置说明
NFS配置参数权限： ro 只读访问 rw 读写访问 --------------- sync 同步方式存储数据直接将数据保存到磁盘（数据存储安全） async 异步方式存储数据直接将数据保存到内存（提高数据存储效率） all_squash 将所有用户身份都进行转换匿名用户anonymous，适合公用目录。 no_all_squash 不要将普通用户身份进行转换 root_squash 将root用户身份进行转换,root用户的所有请求映射成如anonymous用户一样的权限（默认） no_root_squas 不要将root用户身份进行转换 3.创建目录并赋予权限 sudo mkdir /nfs sudo chown nobody:nogroup /nfs sudo chmod -R 777 /nfs 4.启动NFS服务 sudo /etc/init.d/nfs-kernel-server restart 或者 systemctl restart nfs-kernel-server.service 5. 写入测试内容 echo &#34;test&#34; &gt;&gt; /nfs/test.txt 到此服务器端的安装配置完毕
6.客户端操作 安装客户端
sudo apt install nfs-common 挂载
sudo mount -t nfs 192.168.5.103:/nfs /mnt/nfs -o nolock 设置开机自动挂载
sudo vim /etc/fstab 192.168.5.103:/nfs /mnt/nfs nfs rw 0 0 ]]></content></entry><entry><title>Nginx location匹配</title><url>/posts/nginx/location%E5%8C%B9%E9%85%8D/</url><categories><category>Nginx</category></categories><tags><tag>Nginx</tag></tags><content type="html">location语法 location [=|~|~|^~] /url/ { &amp;hellip; } 注：uri是指匹配路径， [ =| ~ | ~ | ^~ | @ ] 是指匹配规则（可选）
= : 完全匹配，表示精确匹配后面的url ^~ : 无正则普通匹配（ ^ 表示“非”，~ 表示“正则”，字符意思是：不会继续匹配正则），表示普通字符匹配，如果该选项匹配，只匹配该选项，不匹配别的选项，一般用来匹配目录 / : 普通匹配（/xxx） ~ : 表示正则匹配，区分大小写 ~* : 表示正则匹配，不区分大小写 @ : “@” 定义一个命名的 location，使用在内部定向时，例如 error_page
= 进行普通字符精确匹配。也就是完全匹配。 ^~ 前缀匹配。如果匹配成功，则不再匹配其他location。 ~ 表示执行一个正则匹配，区分大小写 ~* 表示执行一个正则匹配，不区分大小写 /xxx/ 常规字符串路径匹配 / 通用匹配，任何请求都会匹配到
1. 匹配的先后顺序 = 前缀的指令严格匹配这个查询，优先级最高，一旦匹配成功，则停止搜索其他localtion的匹配项； 所有剩下的常规字符串（^~和普通匹配），‘最长命中’规则，优先使用匹配最长的结果。 正则表达式，在配置文件中定义的顺序 注： ^~ 和普通匹配。使用前缀匹配，不支持正则表达式，如果有多个location匹配成功的话，不会终止匹配过程，会记忆表达式最长的那个，如果得到的最长的location为 ^~ 类型，则表示阻断正则表达式，不再匹配正则表达式。如果得到的最长的location不是 ^~ 类型，继续匹配正则表达式，只要有一个正则成功，则使用这个正则的location，立即返回结果，并结束解析过程。
location = / { # 精确匹配/，主机名后面不能带任何字符串 / [ configuration A ] } location / { # 匹配所有以 / 开头的请求。 # 但是如果有更长的同类型的表达式，则选择更长的表达式。 # 如果有正则表达式可以匹配，则优先匹配正则表达式。 [ configuration B ] } location /documents/ { # 匹配所有以 /documents/ 开头的请求，匹配符合以后，还要继续往下搜索。 # 但是如果有更长的同类型的表达式，则选择更长的表达式。 # 如果有正则表达式可以匹配，则优先匹配正则表达式。 [ configuration C ] } location ^~ /images/ { # 匹配所有以 /images/ 开头的表达式，如果匹配成功，则停止匹配查找，停止搜索。 # 所以，即便有符合的正则表达式location，也不会被使用 [ configuration D ] } location ~* \.(gif|jpg|jpeg)$ { # 匹配所有以 gif jpg jpeg结尾的请求。 # 但是 以 /images/开头的请求，将使用 Configuration D，D具有更高的优先级 [ configuration E ] } location /images/ { # 字符匹配到 /images/，还会继续往下搜索 [ configuration F ] } location = /test.htm { root /usr/local/var/www/htm; index index.htm; } https://blog.csdn.net/beichengliulixue/article/details/121971227 https://zhuanlan.zhihu.com/p/389438482</content></entry><entry><title>Nginx 常用命令</title><url>/posts/nginx/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url><categories><category>Nginx</category></categories><tags><tag>Nginx</tag></tags><content type="html">nginx -t 测试配置文件 nginx -s reload 修改配置后重载生效 nginx -s reopen 重新打开日志文件 nginx -s stop 快速停止 nginx -s quit</content></entry><entry><title>Nginx 高级配置</title><url>/posts/nginx/%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/</url><categories><category>Nginx</category></categories><tags><tag>Nginx</tag></tags><content type="html"><![CDATA[高级配置 原文地址：https://juejin.cn/post/7112826654291918855
1. Nginx反向代理-负载均衡 首先通过SpringBoot+Freemarker快速搭建一个WEB项目：springboot-web-nginx，然后在该项目中，创建一个IndexNginxController.java文件，逻辑如下：
@Controller public class IndexNginxController { @Value(&#34;${server.port}&#34;) private String port; @RequestMapping(&#34;/&#34;) public ModelAndView index(){ ModelAndView model = new ModelAndView(); model.addObject(&#34;port&#34;, port); model.setViewName(&#34;index&#34;); return model; } } 在该Controller类中，存在一个成员变量：port，它的值即是从application.properties配置文件中获取server.port值。当出现访问/资源的请求时，跳转前端index页面，并将该值携带返回。
前端的index.ftl文件代码如下：
&lt;html&gt; &lt;head&gt; &lt;title&gt;Nginx演示页面&lt;/title&gt; &lt;link href=&#34;nginx_style.css&#34; rel=&#34;stylesheet&#34; type=&#34;text/css&#34;/&gt; &lt;/head&gt; &lt;body&gt; &lt;div style=&#34;border: 2px solid red;margin: auto;width: 800px;text-align: center&#34;&gt; &lt;div id=&#34;nginx_title&#34;&gt; &lt;h1&gt;欢迎来到熊猫高级会所，我是竹子${port}号！&lt;/h1&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 从上可以看出其逻辑并不复杂，仅是从响应中获取了port输出。
OK~，前提工作准备就绪后，再简单修改一下nginx.conf的配置即可：
upstream nginx_boot{ # 30s内检查心跳发送两次包，未回复就代表该机器宕机，请求分发权重比为1:2 server 192.168.0.000:8080 weight=100 max_fails=2 fail_timeout=30s; server 192.168.0.000:8090 weight=200 max_fails=2 fail_timeout=30s; # 这里的IP请配置成你WEB服务所在的机器IP } server { location / { root html; # 配置一下index的地址，最后加上index.ftl。 index index.html index.htm index.jsp index.ftl; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 请求交给名为nginx_boot的upstream上 proxy_pass http://nginx_boot; } } 至此，所有的前提工作准备就绪，紧接着再启动Nginx，然后再启动两个web服务，第一个WEB服务启动时，在application.properties配置文件中，将端口号改为8080，第二个WEB服务启动时，将其端口号改为8090。
最终来看看效果： 因为配置了请求分发的权重，8080、8090的权重比为2:1，因此请求会根据权重比均摊到每台机器，也就是8080一次、8090两次、8080一次&hellip;&hellip;
1.1 Nginx请求分发原理 客户端发出的请求192.168.12.129最终会转变为：http://192.168.12.129:80/，然后再向目标IP发起请求，流程如下： 由于Nginx监听了192.168.12.129的80端口，所以最终该请求会找到Nginx进程； Nginx首先会根据配置的location规则进行匹配，根据客户端的请求路径/，会定位到location /{}规则； 然后根据该location中配置的proxy_pass会再找到名为nginx_boot的upstream； 最后根据upstream中的配置信息，将请求转发到运行WEB服务的机器处理，由于配置了多个WEB服务，且配置了权重值，因此Nginx会依次根据权重比分发请求。
2. Nginx动静分离 动静分离应该是听的次数较多的性能优化方案，那先思考一个问题：为什么需要做动静分离呢？它带来的好处是什么？ 其实这个问题也并不难回答，当你搞懂了网站的本质后，自然就理解了动静分离的重要性。先来以淘宝为例分析看看： 当浏览器输入www.taobao.com访问淘宝首页时，打开开发者调试工具可以很明显的看到，首页加载会出现100+的请求数，而正常项目开发时，静态资源一般会放入到resources/static/目录下： 在项目上线部署时，这些静态资源会一起打成包，那此时思考一个问题：假设淘宝也是这样干的，那么首页加载时的请求最终会去到哪儿被处理？ 答案毋庸置疑，首页100+的所有请求都会来到部署WEB服务的机器处理，那则代表着一个客户端请求淘宝首页，就会对后端服务器造成100+的并发请求。毫无疑问，这对于后端服务器的压力是尤为巨大的。
但此时不妨分析看看，首页100+的请求中，是不是至少有60+是属于*.js、*.css、*.html、*.jpg.....这类静态资源的请求呢？答案是Yes。
既然有这么多请求属于静态的，这些资源大概率情况下，长时间也不会出现变动，那为何还要让这些请求到后端再处理呢？能不能在此之前就提前处理掉？当然OK，因此经过分析之后能够明确一点：做了动静分离之后，至少能够让后端服务减少一半以上的并发量。 到此时大家应该明白了动静分离能够带来的性能收益究竟有多大。
OK~，搞清楚动静分离的必要性之后，如何实现动静分离呢？其实非常简单，实战看看。
①先在部署Nginx的机器，Nginx目录下创建一个目录static_resources：
mkdir static_resources ②将项目中所有的静态资源全部拷贝到该目录下，而后将项目中的静态资源移除重新打包。
③稍微修改一下nginx.conf的配置，增加一条location匹配规则：
location ~ .*\.(html|htm|gif|jpg|jpeg|bmp|png|ico|txt|js|css){ root /soft/nginx/static_resources; expires 7d; } 然后照常启动nginx和移除了静态资源的WEB服务，你会发现原本的样式、js效果、图片等依旧有效，如下： 其中static目录下的nginx_style.css文件已被移除，但效果依旧存在（绿色字体+蓝色大边框）： 最后解读一下那条location规则： location ~ .*\.(html|htm|gif|jpg|jpeg|bmp|png|ico|txt|js|css) ~代表匹配时区分大小写 .*代表任意字符都可以出现零次或多次，即资源名不限制 \.代表匹配后缀分隔符. (html|...|css)代表匹配括号里所有静态资源类型 综上所述，简单一句话概述：该配置表示匹配以.html~.css为后缀的所有资源请求。
最后提一嘴，也可以将静态资源上传到文件服务器中，然后location中配置一个新的upstream指向。
3. 资源压缩 建立在动静分离的基础之上，如果一个静态资源的Size越小，那么自然传输速度会更快，同时也会更节省带宽，因此我们在部署项目时，也可以通过Nginx对于静态资源实现压缩传输，一方面可以节省带宽资源，第二方面也可以加快响应速度并提升系统整体吞吐。
在Nginx也提供了三个支持资源压缩的模块ngx_http_gzip_module、ngx_http_gzip_static_module、ngx_http_gunzip_module，其中ngx_http_gzip_module属于内置模块，代表着可以直接使用该模块下的一些压缩指令，后续的资源压缩操作都基于该模块，先来看看压缩配置的一些参数/指令：
参数项 释义 参数值 gzip 开启或关闭压缩机制 on/off; gzip_types 根据文件类型选择性开启压缩机制 image/png、text/css... gzip_comp_level 用于设置压缩级别，级别越高越耗时 1~9（越高压缩效果越好） gzip_vary 设置是否携带Vary:Accept-Encoding头域的响应头部 on/off; gzip_buffers 设置处理压缩请求的缓冲区数量和大小 数量 大小，如16 8k; gzip_disable 针对不同客户端的请求来设置是否开启压缩 如 .*Chrome.*; gzip_http_version 指定压缩响应所需要的最低HTTP请求版本 如1.1; gzip_min_length 设置触发压缩的文件最低大小 如512k; gzip_proxied 对于后端服务器的响应结果是否开启压缩 off、expired、no-cache... 了解了Nginx中的基本压缩配置后，接下来可以在Nginx中简单配置一下：
http{ # 开启压缩机制 gzip on; # 指定会被压缩的文件类型(也可自己配置其他类型) gzip_types text/plain application/javascript text/css application/xml text/javascript image/jpeg image/gif image/png; # 设置压缩级别，越高资源消耗越大，但压缩效果越好 gzip_comp_level 5; # 在头部中添加Vary: Accept-Encoding（建议开启） gzip_vary on; # 处理压缩请求的缓冲区数量和大小 gzip_buffers 16 8k; # 对于不支持压缩功能的客户端请求不开启压缩机制 gzip_disable &#34;MSIE [1-6]\.&#34;; # 低版本的IE浏览器不支持压缩 # 设置压缩响应所支持的HTTP最低版本 gzip_http_version 1.1; # 设置触发压缩的最小阈值 gzip_min_length 2k; # 关闭对后端服务器的响应结果进行压缩 gzip_proxied off; } 在上述的压缩配置中，最后一个gzip_proxied选项，可以根据系统的实际情况决定，总共存在多种选项：
off：关闭Nginx对后台服务器的响应结果进行压缩。 expired：如果响应头中包含Expires信息，则开启压缩。 no-cache：如果响应头中包含Cache-Control:no-cache信息，则开启压缩。 no-store：如果响应头中包含Cache-Control:no-store信息，则开启压缩。 private：如果响应头中包含Cache-Control:private信息，则开启压缩。 no_last_modified：如果响应头中不包含Last-Modified信息，则开启压缩。 no_etag：如果响应头中不包含ETag信息，则开启压缩。 auth：如果响应头中包含Authorization信息，则开启压缩。 any：无条件对后端的响应结果开启压缩机制。 OK~，简单修改好了Nginx的压缩配置后，可以在原本的index页面中引入一个jquery-3.6.0.js文件：
&lt;script type=&#34;text/javascript&#34; src=&#34;jquery-3.6.0.js&#34;&gt;&lt;/script&gt; 分别来对比下压缩前后的区别： 从图中可以很明显看出，未开启压缩机制前访问时，js文件的原始大小为230K，当配置好压缩后再重启Nginx，会发现文件大小从230KB→69KB，效果立竿见影！
注意点： ①对于图片、视频类型的数据，会默认开启压缩机制，因此一般无需再次开启压缩。 ②对于.js文件而言，需要指定压缩类型为application/javascript，而并非text/javascript、application/x-javascript。
4. Nginx缓冲 4.1 Nginx缓冲区 先来思考一个问题，接入Nginx的项目一般请求流程为：“客户端→Nginx→服务端”，在这个过程中存在两个连接：“客户端→Nginx、Nginx→服务端”，那么两个不同的连接速度不一致，就会影响用户的体验（比如浏览器的加载速度跟不上服务端的响应速度）。 其实也就类似电脑的内存跟不上CPU速度，所以对于用户造成的体验感极差，因此在CPU设计时都会加入三级高速缓冲区，用于缓解CPU和内存速率不一致的矛盾。在Nginx也同样存在缓冲区的机制，主要目的就在于：用来解决两个连接之间速度不匹配造成的问题，有了缓冲后，Nginx代理可暂存后端的响应，然后按需供给数据给客户端。先来看看一些关于缓冲区的配置项：
proxy_buffering：是否启用缓冲机制，默认为on关闭状态。
client_body_buffer_size：设置缓冲客户端请求数据的内存大小。
proxy_buffers：为每个请求/连接设置缓冲区的数量和大小，默认4 4k/8k。
proxy_buffer_size：设置用于存储响应头的缓冲区大小。
proxy_busy_buffers_size：在后端数据没有完全接收完成时，Nginx可以将busy状态的缓冲返回给客户端，该参数用来设置busy状态的buffer具体有多大，默认为proxy_buffer_size*2。
proxy_temp_path ：当内存缓冲区存满时，可以将数据临时存放到磁盘，该参数是设置存储缓冲数据的目录。
语法：
proxy_temp_path path; path是临时目录的路径。 proxy_temp_file_write_size：设置每次写数据到临时文件的大小限制。
proxy_max_temp_file_size：设置临时的缓冲目录中允许存储的最大容量。
非缓冲参数项：
proxy_connect_timeout：设置与后端服务器建立连接时的超时时间。 proxy_read_timeout：设置从后端服务器读取响应数据的超时时间。 proxy_send_timeout：设置向后端服务器传输请求数据的超时时间。 具体的nginx.conf配置如下：
http{ proxy_connect_timeout 10; proxy_read_timeout 120; proxy_send_timeout 10; proxy_buffering on; client_body_buffer_size 512k; proxy_buffers 4 64k; proxy_buffer_size 16k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 128k; proxy_temp_path /soft/nginx/temp_buffer; } 上述的缓冲区参数，是基于每个请求分配的空间，而并不是所有请求的共享空间。当然，具体的参数值还需要根据业务去决定，要综合考虑机器的内存以及每个请求的平均数据大小。
最后提一嘴：使用缓冲也可以减少即时传输带来的带宽消耗。
4.2 Nginx缓冲机制 对于性能优化而言，缓存是一种能够大幅度提升性能的方案，因此几乎可以在各处都能看见缓存，如客户端缓存、代理缓存、服务器缓存等等，Nginx的缓存则属于代理缓存的一种。对于整个系统而言，加入缓存带来的优势额外明显：
减少了再次向后端或文件服务器请求资源的带宽消耗。 降低了下游服务器的访问压力，提升系统整体吞吐。 缩短了响应时间，提升了加载速度，打开页面的速度更快。 那么在Nginx中，又该如何配置代理缓存呢？先来看看缓存相关的配置项：
proxy_cache_path ：代理缓存的路径。
语法：proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 是的，你没有看错，就是这么长&hellip;.，解释一下每个参数项的含义： path：缓存的路径地址。 levels：缓存存储的层次结构，最多允许三层目录。 use_temp_path：是否使用临时目录。 keys_zone：指定一个共享内存空间来存储热点Key(1M可存储8000个Key)。 inactive：设置缓存多长时间未被访问后删除（默认是十分钟）。 max_size：允许缓存的最大存储空间，超出后会基于LRU算法移除缓存，Nginx会创建一个Cache manager的进程移除数据，也可以通过purge方式。 manager_files：manager进程每次移除缓存文件数量的上限。 manager_sleep：manager进程每次移除缓存文件的时间上限。 manager_threshold：manager进程每次移除缓存后的间隔时间。 loader_files：重启Nginx载入缓存时，每次加载的个数，默认100。 loader_sleep：每次载入时，允许的最大时间上限，默认200ms。 loader_threshold：一次载入后，停顿的时间间隔，默认50ms。 purger：是否开启purge方式移除数据。 purger_files：每次移除缓存文件时的数量。 purger_sleep：每次移除时，允许消耗的最大时间。 purger_threshold：每次移除完成后，停顿的间隔时间。 proxy_cache ：开启或关闭代理缓存，开启时需要指定一个共享内存区域。
语法：
proxy_cache zone | off; zone为内存区域的名称，即上面中keys_zone设置的名称。 proxy_cache_key ：定义如何生成缓存的键。
语法：
proxy_cache_key string; string为生成Key的规则，如$scheme$proxy_host$request_uri。 proxy_cache_valid ：缓存生效的状态码与过期时间。
语法：
proxy_cache_valid [code ...] time; code为状态码，time为有效时间，可以根据状态码设置不同的缓存时间。 例如：proxy_cache_valid 200 302 30m; proxy_cache_min_uses ：设置资源被请求多少次后被缓存。
语法：
proxy_cache_min_uses number; number为次数，默认为1。 proxy_cache_use_stale ：当后端出现异常时，是否允许
Nginx 返回缓存作为响应。
语法：
proxy_cache_use_stale error; error为错误类型，可配置timeout|invalid_header|updating|http_500...。 proxy_cache_lock ：对于相同的请求，是否开启锁机制，只允许一个请求发往后端。
语法：proxy_cache_lock on | off; proxy_cache_lock_timeout ：配置锁超时机制，超出规定时间后会释放请求。
proxy_cache_lock_timeout time; proxy_cache_methods ：设置对于那些
HTTP 方法开启缓存。
语法：
proxy_cache_methods method; method为请求方法类型，如GET、HEAD等。 proxy_no_cache ：定义不存储缓存的条件，符合时不会保存。
语法：
proxy_no_cache string...; string为条件，例如$cookie_nocache $arg_nocache $arg_comment; proxy_cache_bypass ：定义不读取缓存的条件，符合时不会从缓存中读取。
语法：
proxy_cache_bypass string...; 和上面proxy_no_cache的配置方法类似。 add_header ：往响应头中添加字段信息。
语法：add_header fieldName fieldValue; $upstream_cache_status ：记录了缓存是否命中的信息，存在多种情况：
MISS：请求未命中缓存。 HIT：请求命中缓存。 EXPIRED：请求命中缓存但缓存已过期。 STALE：请求命中了陈旧缓存。 REVALIDDATED：Nginx验证陈旧缓存依然有效。 UPDATING：命中的缓存内容陈旧，但正在更新缓存。 BYPASS：响应结果是从原始服务器获取的。 PS：这个和之前的不同，之前的都是参数项，这个是一个Nginx内置变量。 OK~，对于Nginx中的缓存配置项大概了解后，接着来配置一下Nginx代理缓存：
http{ # 设置缓存的目录，并且内存中缓存区名为hot_cache，大小为128m， # 三天未被访问过的缓存自动清楚，磁盘中缓存的最大容量为2GB。 proxy_cache_path /soft/nginx/cache levels=1:2 keys_zone=hot_cache:128m inactive=3d max_size=2g; server{ location / { # 使用名为nginx_cache的缓存空间 proxy_cache hot_cache; # 对于200、206、304、301、302状态码的数据缓存1天 proxy_cache_valid 200 206 304 301 302 1d; # 对于其他状态的数据缓存30分钟 proxy_cache_valid any 30m; # 定义生成缓存键的规则（请求的url+参数作为key） proxy_cache_key $host$uri$is_args$args; # 资源至少被重复访问三次后再加入缓存 proxy_cache_min_uses 3; # 出现重复请求时，只让一个去后端读数据，其他的从缓存中读取 proxy_cache_lock on; # 上面的锁超时时间为3s，超过3s未获取数据，其他请求直接去后端 proxy_cache_lock_timeout 3s; # 对于请求参数或cookie中声明了不缓存的数据，不再加入缓存 proxy_no_cache $cookie_nocache $arg_nocache $arg_comment; # 在响应头中添加一个缓存是否命中的状态（便于调试） add_header Cache-status $upstream_cache_status; } } } 接着来看一下效果，如下： 第一次访问时，因为还没有请求过资源，所以缓存中没有数据，因此没有命中缓存。第二、三次，依旧没有命中缓存，直至第四次时才显示命中，这是为什么呢？因为在前面的缓存配置中，我们配置了加入缓存的最低条件为：资源至少要被请求三次以上才会加入缓存。 这样可以避免很多无效缓存占用空间。
4.3 缓存清理 当缓存过多时，如果不及时清理会导致磁盘空间被“吃光”，因此我们需要一套完善的缓存清理机制去删除缓存，在之前的proxy_cache_path参数中有purger相关的选项，开启后可以帮我们自动清理缓存，但遗憾的是：purger系列参数只有商业版的NginxPlus才能使用，因此需要付费才可使用。
不过天无绝人之路，我们可以通过强大的第三方模块ngx_cache_purge来替代，先来安装一下该插件： ①首先去到Nginx的安装目录下，创建一个cache_purge目录：
[root@localhost]# mkdir cache_purge &amp;&amp; cd cache_purge ②通过wget指令从github上拉取安装包的压缩文件并解压：
[root@localhost]# wget https://github.com/FRiCKLE/ngx_cache_purge/archive/2.3.tar.gz [root@localhost]# tar -xvzf 2.3.tar.gz ③再次去到之前Nginx的解压目录下：
[root@localhost]# cd /soft/nginx/nginx1.21.6 ④重新构建一次Nginx，通过--add-module的指令添加刚刚的第三方模块：
[root@localhost]# ./configure --prefix=/soft/nginx/ --add-module=/soft/nginx/cache_purge/ngx_cache_purge-2.3/ ⑤重新根据刚刚构建的Nginx，再次编译一下，但切记不要make install：
[root@localhost]# make ⑥删除之前Nginx的启动文件，不放心的也可以移动到其他位置：
[root@localhost]# rm -rf /soft/nginx/sbin/nginx ⑦从生成的objs目录中，重新复制一个Nginx的启动文件到原来的位置：
[root@localhost]# cp objs/nginx /soft/nginx/sbin/nginx 至此，第三方缓存清除模块ngx_cache_purge就安装完成了，接下来稍微修改一下nginx.conf配置，再添加一条location规则：
location ~ /purge(/.*) { # 配置可以执行清除操作的IP（线上可以配置成内网机器） # allow 127.0.0.1; # 代表本机 allow all; # 代表允许任意IP清除缓存 proxy_cache_purge $host$1$is_args$args; } 然后再重启Nginx，接下来即可通过http://xxx/purge/xx的方式清除缓存。
5. Nginx实现IP黑白名单 有时候往往有些需求，可能某些接口只能开放给对应的合作商，或者购买/接入API的合作伙伴，那么此时就需要实现类似于IP白名单的功能。而有时候有些恶意攻击者或爬虫程序，被识别后需要禁止其再次访问网站，因此也需要实现IP黑名单。那么这些功能无需交由后端实现，可直接在Nginx中处理。
Nginx做黑白名单机制，主要是通过allow、deny配置项来实现：
allow xxx.xxx.xxx.xxx; # 允许指定的IP访问，可以用于实现白名单。 deny xxx.xxx.xxx.xxx; # 禁止指定的IP访问，可以用于实现黑名单。 要同时屏蔽/开放多个IP访问时，如果所有IP全部写在nginx.conf文件中定然是不显示的，这种方式比较冗余，那么可以新建两个文件BlocksIP.conf、WhiteIP.conf：
# --------黑名单：BlocksIP.conf--------- deny 192.177.12.222; # 屏蔽192.177.12.222访问 deny 192.177.44.201; # 屏蔽192.177.44.201访问 deny 127.0.0.0/8; # 屏蔽127.0.0.1到127.255.255.254网段中的所有IP访问 # --------白名单：WhiteIP.conf--------- allow 192.177.12.222; # 允许192.177.12.222访问 allow 192.177.44.201; # 允许192.177.44.201访问 allow 127.45.0.0/16; # 允许127.45.0.1到127.45.255.254网段中的所有IP访问 deny all; # 除开上述IP外，其他IP全部禁止访问 分别将要禁止/开放的IP添加到对应的文件后，可以再将这两个文件在nginx.conf中导入：
http{ # 屏蔽该文件中的所有IP include /soft/nginx/IP/BlocksIP.conf; server{ location xxx { # 某一系列接口只开放给白名单中的IP include /soft/nginx/IP/blockip.conf; } } } 对于文件具体在哪儿导入，这个也并非随意的，如果要整站屏蔽/开放就在http中导入，如果只需要一个域名下屏蔽/开放就在sever中导入，如果只需要针对于某一系列接口屏蔽/开放IP，那么就在location中导入。
当然，上述只是最简单的IP黑/白名单实现方式，同时也可以通过ngx_http_geo_module、ngx_http_geo_module第三方库去实现（这种方式可以按地区、国家进行屏蔽，并且提供了IP库）。
6. Nginx跨域配置 跨域问题在之前的单体架构开发中，其实是比较少见的问题，除非是需要接入第三方SDK时，才需要处理此问题。但随着现在前后端分离、分布式架构的流行，跨域问题也成为了每个Java开发必须要懂得解决的一个问题。
跨域问题产生的原因 产生跨域问题的主要原因就在于同源策略，为了保证用户信息安全，防止恶意网站窃取数据，同源策略是必须的，否则cookie可以共享。由于http无状态协议通常会借助cookie来实现有状态的信息记录，例如用户的身份/密码等，因此一旦cookie被共享，那么会导致用户的身份信息被盗取。 同源策略主要是指三点相同，协议+域名+端口 相同的两个请求，则可以被看做是同源的，但如果其中任意一点存在不同，则代表是两个不同源的请求，同源策略会限制了不同源之间的资源交互。
Nginx解决跨域问题 弄明白了跨域问题的产生原因，接下来看看Nginx中又该如何解决跨域呢？其实比较简单，在nginx.conf中稍微添加一点配置即可：
location / { # 允许跨域的请求，可以自定义变量$http_origin，*表示所有 add_header &#39;Access-Control-Allow-Origin&#39; *; # 允许携带cookie请求 add_header &#39;Access-Control-Allow-Credentials&#39; &#39;true&#39;; # 允许跨域请求的方法：GET,POST,OPTIONS,PUT add_header &#39;Access-Control-Allow-Methods&#39; &#39;GET,POST,OPTIONS,PUT&#39;; # 允许请求时携带的头部信息，*表示所有 add_header &#39;Access-Control-Allow-Headers&#39; *; # 允许发送按段获取资源的请求 add_header &#39;Access-Control-Expose-Headers&#39; &#39;Content-Length,Content-Range&#39;; # 一定要有！！！否则Post请求无法进行跨域！ # 在发送Post跨域请求前，会以Options方式发送预检请求，服务器接受时才会正式请求 if ($request_method = &#39;OPTIONS&#39;) { add_header &#39;Access-Control-Max-Age&#39; 1728000; add_header &#39;Content-Type&#39; &#39;text/plain; charset=utf-8&#39;; add_header &#39;Content-Length&#39; 0; # 对于Options方式的请求返回204，表示接受跨域请求 return 204; } } 在nginx.conf文件加上如上配置后，跨域请求即可生效了。
但如果后端是采用分布式架构开发的，有时候RPC调用也需要解决跨域问题，不然也同样会出现无法跨域请求的异常，因此可以在你的后端项目中，通过继承HandlerInterceptorAdapter类、实现WebMvcConfigurer接口、添加@CrossOrgin注解的方式实现接口之间的跨域配置。
7. Nginx防盗链设计 首先了解一下何谓盗链：盗链即是指外部网站引入当前网站的资源对外展示，来举个简单的例子理解：
好比壁纸网站X站、Y站，X站是一点点去购买版权、签约作者的方式，从而积累了海量的壁纸素材，但Y站由于资金等各方面的原因，就直接通过&lt;img src=&quot;X站/xxx.jpg&quot; /&gt;这种方式照搬了X站的所有壁纸资源，继而提供给用户下载。
那么如果我们自己是这个X站的Boss，心中必然不爽，那么此时又该如何屏蔽这类问题呢？那么接下来要叙说的防盗链 登场了！
Nginx的防盗链机制实现，跟上篇文章 《HTTP/HTTPS》 中分析到的一个头部字段：Referer有关，该字段主要描述了当前请求是从哪儿发出的，那么在Nginx中就可获取该值，然后判断是否为本站的资源引用请求，如果不是则不允许访问。Nginx中存在一个配置项为valid_referers，正好可以满足前面的需求，语法如下：
valid_referers none | blocked | server_names | string ...; none：表示接受没有Referer字段的HTTP请求访问。 blocked：表示允许http://或https//以外的请求访问。 server_names：资源的白名单，这里可以指定允许访问的域名。 string：可自定义字符串，支配通配符、正则表达式写法。 简单了解语法后，接下来的实现如下：
# 在动静分离的location中开启防盗链机制 location ~ .*\.(html|htm|gif|jpg|jpeg|bmp|png|ico|txt|js|css){ # 最后面的值在上线前可配置为允许的域名地址 valid_referers blocked 192.168.12.129; if ($invalid_referer) { # 可以配置成返回一张禁止盗取的图片 # rewrite ^/ http://xx.xx.com/NO.jpg; # 也可直接返回403 return 403; } root /soft/nginx/static_resources; expires 7d; } 根据上述中的内容配置后，就已经通过Nginx实现了最基本的防盗链机制，最后只需要额外重启一下就好啦！当然，对于防盗链机制实现这块，也有专门的第三方模块ngx_http_accesskey_module实现了更为完善的设计，感兴趣的小伙伴可以自行去看看。
PS：防盗链机制也无法解决爬虫伪造referers信息的这种方式抓取数据。
8. Nginx大文件传输配置 在某些业务场景中需要传输一些大文件，但大文件传输时往往都会会出现一些Bug，比如文件超出限制、文件传输过程中请求超时等，那么此时就可以在Nginx稍微做一些配置，先来了解一些关于大文件传输时可能会用的配置项：
配置项 释义 client_max_body_size 设置请求体允许的最大体积 client_header_timeout 等待客户端发送一个请求头的超时时间 client_body_timeout 设置读取请求体的超时时间 proxy_read_timeout 设置请求被后端服务器读取时，Nginx等待的最长时间 proxy_send_timeout 设置后端向Nginx返回响应时的超时时间 在传输大文件时，client_max_body_size、client_header_timeout、proxy_read_timeout、proxy_send_timeout这四个参数值都可以根据自己项目的实际情况来配置。
上述配置仅是作为代理层需要配置的，因为最终客户端传输文件还是直接与后端进行交互，这里只是把作为网关层的Nginx配置调高一点，调到能够“容纳大文件”传输的程度。 当然，Nginx中也可以作为文件服务器使用，但需要用到一个专门的第三方模块nginx-upload-module，如果项目中文件上传的作用处不多，那么建议可以通过Nginx搭建，毕竟可以节省一台文件服务器资源。但如若文件上传/下载较为频繁，那么还是建议额外搭建文件服务器，并将上传/下载功能交由后端处理。
]]></content></entry><entry><title>Nginx常用配置</title><url>/posts/nginx/%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/</url><categories><category>Nginx</category></categories><tags><tag>Nginx</tag></tags><content type="html"><![CDATA[1. 跨域配置 server { listen 80; server_name localhost 127.0.0.1; location / { # 允许跨域请求的“域”，此处可以填具体域名、地址或通配符* add_header &#39;Access-Control-Allow-Origin&#39; $http_origin always; # 允许客户端提交Cookie add_header &#39;Access-Control-Allow-Credentials&#39; &#39;true&#39;; # 允许客户端的请求方法 add_header &#39;Access-Control-Allow-Methods&#39; &#39;GET, POST, OPTIONS, DELETE, PUT&#39;; # 允许客户端提交的的请求头 add_header &#39;Access-Control-Allow-Headers&#39; &#39;Origin, x-requested-with, Content-Type, Accept, Authorization&#39;; # 允许客户端访问的响应头 add_header &#39;Access-Control-Expose-Headers&#39; &#39;Cache-Control, Content-Language, Content-Type, Expires, Last-Modified, Pragma&#39;; # 处理预检请求 if ($request_method = &#39;OPTIONS&#39;) { # 预检请求缓存时间 add_header &#39;Access-Control-Max-Age&#39; 1728000; add_header &#39;Content-Type&#39; &#39;text/plain; charset=utf-8&#39;; add_header &#39;Content-Length&#39; 0; return 204; } # 服务端访问路径 proxy_pass http://127.0.0.1:8080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_connect_timeout 600; proxy_read_timeout 600; } } 2. 80端口重定向443 server{ ssl on; listen 443; server_name pan.gossip.tk; ssl_certificate /root/cert.crt; ssl_certificate_key /root/private.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / { proxy_pass http://127.0.0.1:5210; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } server { listen 80; server_name pan.gossip.tk; rewrite ^(.*)$ https://$host$1 permanent; } ]]></content></entry><entry><title>Nmap主机扫描</title><url>/posts/linux%E6%93%8D%E4%BD%9C/nmap%E4%B8%BB%E6%9C%BA%E6%89%AB%E6%8F%8F/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html">ICMP协议探测 nmap -sn -PE -T4 192.168.5.0/24 ARP协议探测 nmap -sn -PR 192.168.5.0/24</content></entry><entry><title>pip换源</title><url>/posts/python/pip%E6%8D%A2%E6%BA%90/</url><categories><category>Python</category></categories><tags><tag>Python</tag><tag>pip</tag></tags><content type="html">安装pip 安装脚本链接 python get-pip.py install Linux Linux下，修改 ~/.pip/pip.conf (没有就创建一个文件夹及文件。文件夹要加“.”，表示是隐藏文件夹) 内容如下：
[global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple [install] trusted-host = https://pypi.tuna.tsinghua.edu.cn Windows windows下，直接在user目录中创建一个pip目录，如：C:\Users\xx\pip，然后新建文件pip.ini，即 %HOMEPATH%\pip\pip.ini，在pip.ini文件中输入以下内容（以豆瓣镜像为例）：
[global] index-url = http://pypi.douban.com/simple [install] trusted-host = pypi.douban.com</content></entry><entry><title>Python奇淫技巧</title><url>/posts/python/python%E5%A5%87%E6%B7%AB%E6%8A%80%E5%B7%A7/</url><categories><category>Python</category></categories><tags><tag>Python</tag></tags><content type="html"><![CDATA[1. 交换 # 交换 a = 3 b = 5 print(f&#39;a: {a}, b: {b}&#39;) a, b = b, a print(f&#39;a: {a}, b: {b}&#39;) # 输出 a: 3, b: 5 a: 5, b: 3 2. yield的使用 # yield的使用 def fibonacci(n): a = 0 b = 1 for _ in range(n): yield a a, b = a+b, a for i in fibonacci(10): print(i) # 输出 0 1 1 2 3 5 8 13 21 34 3. 列表循环 # 列表循环 list = [1, 3, 5, 7, 9] for li in list: print(li) # 进阶使用 for index, value in enumerate(list): print(f&#34;索引: {index}, 值: {value}&#34;) # 输出 1 3 5 7 9 索引: 0, 值: 1 索引: 1, 值: 3 索引: 2, 值: 5 索引: 3, 值: 7 索引: 4, 值: 9 4. 字典合并 # 字典合并 x = {&#39;1&#39;: &#39;admin&#39;, &#39;2&#39;: &#39;mike&#39;} y = {&#39;3&#39;: &#39;lula&#39;, &#39;4&#39;: &#39;lihua&#39;} z = {**x, **y} print(z) # 输出 {&#39;1&#39;: &#39;admin&#39;, &#39;2&#39;: &#39;mike&#39;, &#39;3&#39;: &#39;lula&#39;, &#39;4&#39;: &#39;lihua&#39;} 5. 三元运算符 # 三元运算符 # Ture if 条件 else False a = 10 b = 20 print(a) if a &lt; b else print(b) # 输出 10 6. 序列解包 # 序列解包 # eg1: name = &#34;Yong Zhong&#34; last_name, fist_name = name.split() print(f&#34;fist_name: {fist_name}, last_name: {last_name}&#34;) # eg2: list = [1, 2, 3] a, b, c = list print(a, b, c) # 输出 fist_name: Zhong, last_name: Yong 1 2 3 7. 关闭流 # with语句 # 相对于关闭流 with open(&#39;./test.txt&#39;, &#39;r+&#39;) as fp: str = fp.readline() print(str) ]]></content></entry><entry><title>Python视频爬虫</title><url>/posts/python/python-%E8%A7%86%E9%A2%91%E7%88%AC%E8%99%AB/</url><categories><category>Python</category></categories><tags><tag>Python</tag><tag>爬虫</tag></tags><content type="html"><![CDATA[import requests from lxml import etree import re import os import aiohttp import aiofiles import asyncio import shutil from Crypto.Cipher import AES headers = { &#39;user-agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) &#39; &#39;AppleWebKit/537.36 (KHTML, like Gecko) &#39; &#39;Chrome/91.0.4472.106 Safari/537.36&#39; } # 下载地址 path = &#34;D:/COLI/&#34; def login(url): session = requests.session() url = url + &#39;login.php?&#39; data = { &#39;pwuser&#39;: &#39;小车车压槽&#39;, &#39;pwpwd&#39;: &#39;qazwsxedc&#39;, &#39;hideid&#39;: 0, &#39;cktime&#39;: &#39;31536000&#39;, &#39;forward&#39;: &#39;https://www.d5034af6f919.xyz/&#39;, &#39;jumpurl&#39;: &#39;https://www.d5034af6f919.xyz/&#39;, &#39;step&#39;: 2 } session.post(url=url, data=data, headers=headers) return session # 封装网络请求 def requ(session, url): resp = session.get(url=url, headers=headers) resp.encoding = &#39;utf-8&#39; return resp # 使用模块区的链接获取 def serach_tody(session, url): today_url = url + &#39;&amp;search=today&#39; resp = requ(session, today_url) tree = etree.HTML(resp.text) tag_list = tree.xpath(&#39;//tr[@class=&#34;tr3 t_one tac&#34;]&#39;) link_list = [] print(&#39;------------------------今日内容--------------------------&#39;) for index, tag in enumerate(tag_list): title = tag.xpath(&#39;./td[2]/h3/a/text()&#39;)[0] time = tag.xpath(&#39;./td[3]/div/text()&#39;)[0] link = tag.xpath(&#39;./td[2]/h3/a/@href&#39;)[0] print(f&#39;{index}.----------------------------------------------{title} {time}&#39;) link_list.append(link) return link_list # 使用页面page的链接获取 def get_video_url(session, url): resp = requ(session, url) tree = etree.HTML(resp.text) video_url = tree.xpath(&#39;//*[@id=&#34;iframe1&#34;]/@src&#39;)[0] return video_url # 使用video的链接获取m3u8文件 def get_m3u8_url(session, url): resp = requ(session, url) rexp = re.compile(r&#34;url: &#39;(?P&lt;url&gt;.*?)\?t=3&#39;,&#34;, re.S) page_source = resp.text m3u8_url = rexp.search(page_source).group(&#34;url&#34;) rexp = re.compile(r&#34;&lt;title&gt;(?P&lt;title&gt;.*?)&lt;/title&gt;&#34;, re.S) title = rexp.search(page_source).group(&#34;title&#34;) return title, m3u8_url # 使用m3u8的链接下载 def down_m3u8(name, url): print(&#39;开始下载&#39;, name) if not os.path.exists(path + &#39;M3U8/&#39;): os.makedirs(path + &#39;M3U8/&#39;) file_path = path + &#39;M3U8/&#39; + name + &#39;.m3u8&#39; data = requests.get(url=url, headers=headers).content with open(file_path, &#39;wb&#39;) as f: f.write(data) print(name + &#39;.m3u8下载成功&#39;) async def down_ts(url, name, ts_key, session, title): file_path = path + &#39;Ts/&#39; + title.replace(&#34; &#34;, &#34;&#34;) + &#39;/&#39; if not os.path.exists(file_path): os.mkdir(file_path) aes = AES.new(key=ts_key, mode=AES.MODE_CBC) async with session.get(url) as resp: async with aiofiles.open(f&#39;{file_path}/{name}&#39;, mode=&#39;wb&#39;) as f: data = await resp.content.read() await f.write(aes.decrypt(data)) print(f&#39;{name}下载完成&#39;) def get_ts_key(url): ts_key = requests.get(url=url, headers=headers).content return ts_key async def down_video(name, ts_domain): tasks = [] file_path = path + &#39;M3U8/&#39; + name + &#39;.m3u8&#39; async with aiohttp.ClientSession() as session: async with aiofiles.open(file_path, mode=&#39;r&#39;, encoding=&#39;utf-8&#39;) as f: async for line in f: if &#39;.key&#39; in line: rexp = re.compile(r&#39;URI=&#34;(?P&lt;key_url&gt;.*?)&#34;,&#39;, re.S) key_url = rexp.search(line).group(&#34;key_url&#34;) ts_key = get_ts_key(ts_domain + key_url) if line.startswith(&#34;#&#34;): continue # 去掉多余的空格和换行 line = line.strip() # 拿到正真的ts地址 ts_url = ts_domain + line # 创建异步任务 task = asyncio.create_task(down_ts(ts_url, line, ts_key, session, title)) # 加入任务列表 tasks.append(task) await asyncio.wait(tasks) def merge_ts(name): print(f&#39;正在合并{name}.mp4 请稍后...........&#39;) name = name.replace(&#34; &#34;, &#34;&#34;) video_path = f&#39;{path}Video/&#39; if not os.path.exists(video_path): os.mkdir(video_path) os.chdir(path + &#39;/Ts/&#39; + name) os.system(f&#39;copy /b *.ts ..\\..\\Video\\{name}.mp4&#39;) print(f&#39;{name}.mp4 合并成功&#39;) if __name__ == &#39;__main__&#39;: # 进入地址 domain = &#39;https://www.d5034af6f919.xyz/&#39; print(&#39;正在登录，请稍后..........&#39;) # 拿到登录的会话 session = login(domain) # 进入主页 index_url = domain + &#39;index.php&#39; resp = requ(session, index_url) tree = etree.HTML(resp.text) # 拿到用户名 user = tree.xpath(&#39;//*[@id=&#34;header&#34;]/div[2]/span/text()&#39;)[0] # 拿到vip区的地址 vip_link = domain + tree.xpath(&#39;//*[@id=&#34;cate_1&#34;]/tr[2]/th[1]/h2/a/@href&#39;)[0] print(&#39;登录成功&#39;) print(&#39;用户名：&#39;, user) print(&#39;正在进入vip影视区.........&#39;) links = serach_tody(session, vip_link) if not os.path.exists(path + &#39;Ts/&#39;): os.mkdir(path + &#39;Ts/&#39;) else: shutil.rmtree(path + &#39;Ts/&#39;) os.mkdir(path + &#39;Ts/&#39;) loop = True while loop: index = int(input(&#39;请选择你要下载的索引[-1退出]：&#39;)) if index == -1: break elif index &lt; -1 and index &gt; len(links): index = int(input(&#39;你的输入有误，请重新输入[-1退出]：&#39;)) else: page_url = domain + links[index] video_url = domain + get_video_url(session, page_url) title, m3u8_url = get_m3u8_url(session, video_url) print(m3u8_url) m3u8_domain = m3u8_url.rsplit(&#39;/&#39;, 1)[0] + &#39;/&#39; down_m3u8(title, m3u8_url) asyncio.run(down_video(title, m3u8_domain)) merge_ts(title) ]]></content></entry><entry><title>Python图片爬虫</title><url>/posts/python/python-%E5%9B%BE%E7%89%87%E7%88%AC%E8%99%AB/</url><categories><category>Python</category></categories><tags><tag>Python</tag><tag>爬虫</tag></tags><content type="html"><![CDATA[图片爬取1.1 import requests import os from lxml import etree headers = { &#39;user-agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) &#39; &#39;AppleWebKit/537.36 (KHTML, like Gecko) &#39; &#39;Chrome/91.0.4472.106 Safari/537.36&#39; } def request(url): response = requests.get(url=url, headers=headers) # 中文乱码处理 response.encoding = &#39;utf-8&#39; return response.text def get_link(url): tree = etree.HTML(request(url)) li_list = tree.xpath(&#39;/html/body/div[2]/div[8]/ul/li&#39;) # print(li_list) for li in li_list: link = &#39;https://www.umei.net&#39; + li.xpath(&#39;./a/@href&#39;)[0] file_name = li.xpath(&#39;./a/span/text()&#39;)[0] print(&#39;开始下载:&#39; + file_name) path = &#39;D:/Img/&#39;+file_name if not os.path.exists(path): os.mkdir(path) img_src,next_page = get_allSrc(link) while next_page != &#39;&#39;: img_download(path,img_src) img_src, next_page = get_allSrc(next_page) def get_allSrc(url): tree = etree.HTML(request(url)) src = tree.xpath(&#39;//*[@id=&#34;ArticleId{dede:field.reid/}&#34;]/p/a/img/@src&#39;)[0] a_list = tree.xpath(&#39;/html/body/div[2]/div[12]/a&#39;) next_page = &#39;&#39; for a in a_list: if a.xpath(&#39;./text()&#39;)[0] == &#39;下一页&#39;: next_page = &#39;https://www.umei.net&#39; + a.xpath(&#39;./@href&#39;)[0] return src, next_page def img_download(path,img_src): name = img_src.rsplit(&#39;/&#39;, 1)[1] img_path= path + &#39;/&#39; + name img_data = requests.get(url=img_src, headers=headers).content with open(img_path,&#39;wb&#39;) as fp: fp.write(img_data) print(name, &#34;下载成功&#34;) if __name__ == &#39;__main__&#39;: url = &#39;https://www.umei.net/meinvtupian/meinvxiezhen/&#39; get_link(url) 图片爬取1.2 import requests import os from lxml import etree headers = { &#39;user-agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) &#39; &#39;AppleWebKit/537.36 (KHTML, like Gecko) &#39; &#39;Chrome/91.0.4472.106 Safari/537.36&#39; } def request(url): response = requests.get(url=url, headers=headers) # 中文乱码处理 response.encoding = &#39;utf-8&#39; return response.text def get_link(url): tree = etree.HTML(request(url)) li_list = tree.xpath(&#39;/html/body/div[2]/div[8]/ul/li&#39;) # print(li_list) for li in li_list: link = &#39;https://www.umei.net&#39; + li.xpath(&#39;./a/@href&#39;)[0] file_name = li.xpath(&#39;./a/span/text()&#39;)[0] print(&#39;开始下载:&#39; + file_name) path = &#39;D:/Img/&#39;+file_name if not os.path.exists(path): os.mkdir(path) img_src,next_page = get_allSrc(link) while next_page != &#39;&#39;: img_download(path,img_src) img_src, next_page = get_allSrc(next_page) def get_allSrc(url): tree = etree.HTML(request(url)) src = tree.xpath(&#39;//*[@id=&#34;ArticleId{dede:field.reid/}&#34;]/p/a/img/@src&#39;)[0] a_list = tree.xpath(&#39;/html/body/div[2]/div[12]/a&#39;) next_page = &#39;&#39; for a in a_list: if a.xpath(&#39;./text()&#39;)[0] == &#39;下一页&#39;: next_page = &#39;https://www.umei.net&#39; + a.xpath(&#39;./@href&#39;)[0] return src, next_page def img_download(path,img_src): name = img_src.rsplit(&#39;/&#39;, 1)[1] img_path= path + &#39;/&#39; + name img_data = requests.get(url=img_src, headers=headers).content with open(img_path,&#39;wb&#39;) as fp: fp.write(img_data) print(name, &#34;下载成功&#34;) if __name__ == &#39;__main__&#39;: url = &#39;https://www.umei.net/meinvtupian/meinvxiezhen/&#39; get_link(url) for i in range(146): if i &gt;= 2: index = f&#39;{i}&#39; url = &#39;https://www.umei.net/meinvtupian/meinvxiezhen/index_&#39; + index + &#39;.htm&#39; get_link(url) 图片爬虫1.3 import requests import os from lxml import etree headers = { &#39;user-agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) &#39; &#39;AppleWebKit/537.36 (KHTML, like Gecko) &#39; &#39;Chrome/91.0.4472.106 Safari/537.36&#39; } def request(url): response = requests.get(url=url, headers=headers) # 中文乱码处理 response.encoding = &#39;utf-8&#39; return response.text def get_link(url): tree = etree.HTML(request(url)) li_list = tree.xpath(&#39;/html/body/div[2]/div[8]/ul/li&#39;) # print(li_list) for li in li_list: link = &#39;https://www.umei.net&#39; + li.xpath(&#39;./a/@href&#39;)[0] file_name = li.xpath(&#39;./a/span/text()&#39;)[0] print(&#39;开始下载:&#39; + file_name) path = &#39;D:/Img/&#39;+file_name if not os.path.exists(path): os.mkdir(path) img_src,next_page = get_allSrc(link) while next_page != &#39;&#39;: img_download(path,img_src) img_src, next_page = get_allSrc(next_page) def get_allSrc(url): tree = etree.HTML(request(url)) a_list = tree.xpath(&#39;/html/body/div[2]/div[12]/a&#39;) next_page = &#39;&#39; if len(a_list) == 0: src = tree.xpath(&#39;//*[@id=&#34;ArticleId{dede:field.reid/}&#34;]/p/img/@src&#39;)[0] else: src = tree.xpath(&#39;//*[@id=&#34;ArticleId{dede:field.reid/}&#34;]/p/a/img/@src&#39;)[0] for a in a_list: if a.xpath(&#39;./text()&#39;)[0] == &#39;下一页&#39;: next_page = &#39;https://www.umei.net&#39; + a.xpath(&#39;./@href&#39;)[0] return src, next_page def img_download(path,img_src): name = img_src.rsplit(&#39;/&#39;, 1)[1] img_path= path + &#39;/&#39; + name img_data = requests.get(url=img_src, headers=headers).content with open(img_path,&#39;wb&#39;) as fp: fp.write(img_data) print(name, &#34;下载成功&#34;) if __name__ == &#39;__main__&#39;: url = &#39;https://www.umei.net/meinvtupian/meinvxiezhen/&#39; get_link(url) for i in range(146): if i &gt;= 2: index = f&#39;{i}&#39; url = &#39;https://www.umei.net/meinvtupian/meinvxiezhen/index_&#39; + index + &#39;.htm&#39; get_link(url) 图片爬虫1.4 import requests import os from lxml import etree headers = { &#39;user-agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) &#39; &#39;AppleWebKit/537.36 (KHTML, like Gecko) &#39; &#39;Chrome/91.0.4472.106 Safari/537.36&#39; } def request(url): response = requests.get(url=url, headers=headers) # 中文乱码处理 response.encoding = &#39;utf-8&#39; return response.text def get_link(url): tree = etree.HTML(request(url)) li_list = tree.xpath(&#39;/html/body/div[2]/div[8]/ul/li&#39;) # print(li_list) for li in li_list: link = &#39;https://www.umei.net&#39; + li.xpath(&#39;./a/@href&#39;)[0] file_name = li.xpath(&#39;./a/span/text()&#39;)[0] print(&#39;开始下载:&#39; + file_name) path = &#39;D:/Img/&#39;+file_name if not os.path.exists(path): os.mkdir(path) img_src,next_page = get_allSrc(link) while next_page != &#39;&#39;: img_download(path,img_src) img_src, next_page = get_allSrc(next_page) def get_allSrc(url): tree = etree.HTML(request(url)) a_list = tree.xpath(&#39;//div[@class=\&#39;NewPages\&#39;]/a&#39;) src = tree.xpath(&#39;//*[@id=&#34;ArticleId{dede:field.reid/}&#34;]/p/a/img/@src&#39;) next_page = &#39;&#39; if len(a_list) == 0 or len(src) == 0: src = tree.xpath(&#39;//*[@id=&#34;ArticleId{dede:field.reid/}&#34;]/p/img/@src&#39;)[0] else: src = tree.xpath(&#39;//*[@id=&#34;ArticleId{dede:field.reid/}&#34;]/p/a/img/@src&#39;)[0] for a in a_list: if a.xpath(&#39;./text()&#39;)[0] == &#39;下一页&#39;: next_page = &#39;https://www.umei.net&#39; + a.xpath(&#39;./@href&#39;)[0] return src, next_page def img_download(path,img_src): name = img_src.rsplit(&#39;/&#39;, 1)[1] img_path= path + &#39;/&#39; + name img_data = requests.get(url=img_src, headers=headers).content with open(img_path,&#39;wb&#39;) as fp: fp.write(img_data) print(name, &#34;下载成功&#34;) if __name__ == &#39;__main__&#39;: url = &#39;https://www.umei.net/meinvtupian/meinvxiezhen/&#39; get_link(url) for i in range(146): if i &gt;= 2: index = f&#39;{i}&#39; url = &#39;https://www.umei.net/meinvtupian/meinvxiezhen/index_&#39; + index + &#39;.htm&#39; get_link(url) 图片爬虫1.5（异步） import requests import asyncio import aiohttp import aiofiles import os from lxml import etree headers = { &#39;user-agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) &#39; &#39;AppleWebKit/537.36 (KHTML, like Gecko) &#39; &#39;Chrome/91.0.4472.106 Safari/537.36&#39; } def request(url): response = requests.get(url=url, headers=headers) # 中文乱码处理 response.encoding = &#39;utf-8&#39; return response.text def get_link(url): tree = etree.HTML(request(url)) li_list = tree.xpath(&#39;/html/body/div[2]/div[8]/ul/li&#39;) tasks = [] for li in li_list: link = &#39;https://www.umei.net&#39; + li.xpath(&#39;./a/@href&#39;)[0] file_name = li.xpath(&#39;./a/span/text()&#39;)[0] print(&#39;开始下载:&#39; + file_name) path = &#39;D:/ImgTest&#39; if not os.path.exists(path): os.mkdir(path) img_src,next_page = get_allSrc(link) tasks.append(download_img(path, img_src)) while next_page != &#39;&#39;: img_src, next_page = get_allSrc(next_page) tasks.append(download_img(path, img_src)) asyncio.run(asyncio.wait(tasks)) def get_allSrc(url): tree = etree.HTML(request(url)) a_list = tree.xpath(&#39;//div[@class=\&#39;NewPages\&#39;]/a&#39;) src = tree.xpath(&#39;//*[@id=&#34;ArticleId{dede:field.reid/}&#34;]/p/a/img/@src&#39;) next_page = &#39;&#39; if len(a_list) == 0 or len(src) == 0: src = tree.xpath(&#39;//*[@id=&#34;ArticleId{dede:field.reid/}&#34;]/p/img/@src&#39;)[0] else: src = tree.xpath(&#39;//*[@id=&#34;ArticleId{dede:field.reid/}&#34;]/p/a/img/@src&#39;)[0] for a in a_list: if a.xpath(&#39;./text()&#39;)[0] == &#39;下一页&#39;: next_page = &#39;https://www.umei.net&#39; + a.xpath(&#39;./@href&#39;)[0] return src, next_page async def download_img(path, img_src): name = img_src.rsplit(&#39;/&#39;, 1)[1] img_path = path + &#39;/&#39; + name print(f&#39;开始下载: {name} ......&#39;) async with aiohttp.ClientSession() as session: async with session.get(img_src) as resp: img_data = await resp.content.read() async with aiofiles.open(img_path, mode=&#39;wb&#39;) as fp: await fp.write(img_data) print(name, &#34;下载成功&#34;) if __name__ == &#39;__main__&#39;: url = &#39;https://www.umei.net/meinvtupian/meinvxiezhen/&#39; get_link(url) for i in range(146): if i &gt;= 2: index = f&#39;{i}&#39; url = &#39;https://www.umei.net/meinvtupian/meinvxiezhen/index_&#39; + index + &#39;.htm&#39; get_link(url) ]]></content></entry><entry><title>Screen的使用</title><url>/posts/linux%E6%93%8D%E4%BD%9C/screen%E7%9A%84%E4%BD%BF%E7%94%A8/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html"><![CDATA[# 新建会话 screen -S &lt;session_name&gt; # 快捷键Ctrl + A + D 分离当前会话到后台，返回到用户终端 C-a + d # 查看建立的会话 screen -ls # 连接建立的会话 screen -r &lt;session_name&gt; # 杀死建立的会话 screen -XS &lt;session_name&gt; quit ]]></content></entry><entry><title>SpeedTest测速</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/speedtest%E6%B5%8B%E9%80%9F/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>SpeedTest</tag></tags><content type="html"><![CDATA[1. 安装脚本 curl -fsSL git.io/speedtest-cli.sh | sudo bash 下载不了可以新建
#!/usr/bin/env bash # # Copyright (c) 2020-2021 P3TERX &lt;https://p3terx.com&gt; # # This is free software, licensed under the MIT License. # See /LICENSE for more information. # # https://github.com/P3TERX/script # File name: speedtest-cli.sh # Description: Install Ookla Speedtest CLI # System Required: GNU/Linux # Version: 1.3 # set -o errexit set -o errtrace set -o pipefail Green_font_prefix=&#34;\033[32m&#34; Red_font_prefix=&#34;\033[31m&#34; Green_background_prefix=&#34;\033[42;37m&#34; Red_background_prefix=&#34;\033[41;37m&#34; Font_color_suffix=&#34;\033[0m&#34; INFO=&#34;[${Green_font_prefix}INFO${Font_color_suffix}]&#34; ERROR=&#34;[${Red_font_prefix}ERROR${Font_color_suffix}]&#34; PROJECT_NAME=&#39;Ookla Speedtest CLI&#39; BIN_DIR=&#39;/usr/local/bin&#39; BIN_NAME=&#39;speedtest&#39; BIN_FILE=&#34;${BIN_DIR}/${BIN_NAME}&#34; if [[ $(uname -s) != Linux ]]; then echo -e &#34;${ERROR} This operating system is not supported.&#34; exit 1 fi if [[ $(id -u) != 0 ]]; then echo -e &#34;${ERROR} This script must be run as root.&#34; exit 1 fi echo -e &#34;${INFO} Get CPU architecture ...&#34; if [[ $(command -v apk) ]]; then PKGT=&#39;(apk)&#39; OS_ARCH=$(apk --print-arch) elif [[ $(command -v dpkg) ]]; then PKGT=&#39;(dpkg)&#39; OS_ARCH=$(dpkg --print-architecture | awk -F- &#39;{ print $NF }&#39;) else OS_ARCH=$(uname -m) fi case ${OS_ARCH} in *86) FILE_KEYWORD=&#39;i386&#39; ;; x86_64 | amd64) FILE_KEYWORD=&#39;x86_64&#39; ;; aarch64 | arm64) FILE_KEYWORD=&#39;aarch64&#39; ;; arm*) FILE_KEYWORD=&#39;arm&#39; ;; *) echo -e &#34;${ERROR} Unsupported architecture: ${OS_ARCH} ${PKGT}&#34; exit 1 ;; esac echo -e &#34;${INFO} Architecture: ${OS_ARCH} ${PKGT}&#34; echo -e &#34;${INFO} Get ${PROJECT_NAME} download URL ...&#34; DOWNLOAD_URL=&#34;https://install.speedtest.net/app/cli/ookla-speedtest-1.0.0-${FILE_KEYWORD}-linux.tgz&#34; echo -e &#34;${INFO} Download URL: ${DOWNLOAD_URL}&#34; echo -e &#34;${INFO} Installing ${PROJECT_NAME} ...&#34; curl -LS &#34;${DOWNLOAD_URL}&#34; | tar xzC ${BIN_DIR} ${BIN_NAME} chmod +x ${BIN_FILE} if [[ ! $(echo ${PATH} | grep ${BIN_DIR}) ]]; then ln -sf ${BIN_FILE} /usr/bin/${BIN_NAME} fi if [[ -s ${BIN_FILE} &amp;&amp; $(${BIN_NAME} --version) ]]; then echo -e &#34;${INFO} Done.&#34; else echo -e &#34;${ERROR} ${PROJECT_NAME} installation failed !&#34; exit 1 fi 安装完成后执行
speedtest ]]></content></entry><entry><title>SSL证书申请</title><url>/posts/nginx/ssl%E8%AF%81%E4%B9%A6%E7%94%B3%E8%AF%B7/</url><categories><category>Nginx</category></categories><tags><tag>Nginx</tag></tags><content type="html">1. Acme 脚本申请证书 Acme 脚本申请证书，是我们用到的最常见的一种证书的申请方式，它有很多的申请方法，大家只需要找到一种适合自己的也就好了。
不管用下面的何种方式申请，都需要安装 Acme，有一部分的申请场景需要用到相关的插件，所以我们需要提前安装。 下面环境的安装方式，大家根据自己的系统选择命令安装就好了。
apt update -y #Debian/Ubuntu 命令 apt install -y curl #Debian/Ubuntu 命令 apt install -y socat #Debian/Ubuntu 命令 yum update -y #CentOS 命令 yum install -y curl #CentOS 命令 yum install -y socat #CentOS 命令 # 关闭防火墙 systemctl disable firewalld.service systemctl stop firewalld.service 安装 Acme 脚本
curl https://get.acme.sh | sh 更换Acme的默认CA颁发机构
~/.acme.sh/acme.sh --set-default-ca --server letsencrypt 2. 申请时请先解析域名 2.1 80 端口空闲的验证申请(到此可以结束) 如果你还没有运行任何 web 服务, 80 端口是空闲的, 那么 Acme.sh 还能假装自己是一个 WebServer, 临时监听在 80 端口, 完成验证
~/.acme.sh/acme.sh --issue -d 填入你的域名 --standalone 2.2 指定空闲端口申请 如果80端口用不了，可以指定其他的端口
~/.acme.sh/acme.sh --issue -d 填入你的域名 --standalone --httpport 88 2.3 Nginx 的方式验证申请 这种方式需要你的服务器上面已经部署了 Nginx 环境，并且保证你申请的域名已经在 Nginx 进行了 conf 部署。（被申请的域名可以正常被打开）
~/.acme.sh/acme.sh --issue -d 填入你的域名 --nginx 2.4 http 的方式验证申请 这种方式需要你的服务器上面已经部署了网站环境。（被申请的域名可以正常被打开） 原理：Acme 自动在你的网站根目录下放置一个文件, （这个文件可以被互联网访问）来验证你的域名所有权,完成验证. 然后就可以生成证书了. 实例代码：（后面的路径请更改为你的 网站根目录 绝对路径 ）
~/.acme.sh/acme.sh --issue -d 填入你的域名 --webroot /home/wwwroot/网站目录/ 2.5 安装证书到指定文件夹 注意, 默认生成的证书都放在安装目录下: ~/.acme.sh/, 请不要直接使用此目录下的证书文件。 正确的使用方法是使用 --install-cert 命令,并指定目标位置, 然后证书文件会被copy到相应的位置，比如下面的代码
~/.acme.sh/acme.sh --installcert -d 填入你的域名 --key-file /root/private.key --fullchain-file /root/cert.crt 上面的 /root/private.key 以及 /root/cert.crt 是把密钥和证书安装到 /root 目录，并改名为 private.key 和 cert.crt
2.6 更新证书 目前证书在 60 天以后会自动更新, 你无需任何操作. 今后有可能会缩短这个时间, 不过都是自动的, 你不用关心.
2.6.1 查看更新证书列表 /root/.acme.sh/acme.sh --list 2.6.2 手动更新所有证书 /root/.acme.sh/acme.sh --renew-all 2.6.3 手动更新指定证书 /root/.acme.sh/acme.sh --renew -d 域名 2.6.4 停止自动更新 /root/.acme.sh/acme.sh --remove -d 要停止的域名 2.7 更新 Acme 脚本 升级 Acme.sh 到最新版本
~/.acme.sh/acme.sh --upgrade 如果你不想手动升级, 可以开启自动升级:
~/.acme.sh/acme.sh --upgrade --auto-upgrade 之后, acme.sh 就会自动保持更新了.</content></entry><entry><title>Tmux的使用</title><url>/posts/linux%E6%93%8D%E4%BD%9C/tmux%E7%9A%84%E4%BD%BF%E7%94%A8/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html"><![CDATA[Tmux的使用 说明：Ctrl+b 为快捷方式的前缀键，即先按下Ctrl+b，快捷键才会生效。
1. 会话管理 1.1 新建会话 tmux new -s &lt;session-name&gt; 1.2 分离会话 在 Tmux 窗口中，按下Ctrl+b d或者输入tmux detach命令，就会将当前会话与窗口分离。
tmux detach 上面命令执行后，就会退出当前 Tmux 窗口，但是会话和里面的进程仍然在后台运行。
tmux ls命令可以查看当前所有的 Tmux 会话。
tmux ls # or tmux list-session 1.3 接入会话 tmux attach命令用于重新接入某个已存在的会话
# 使用会话编号 tmux attach -t 0 # 使用会话名称 tmux attach -t &lt;session-name&gt; 1.4 杀死会话 tmux kill-session命令用于杀死某个会话
# 使用会话编号 tmux kill-session -t 0 # 使用会话名称 tmux kill-session -t &lt;session-name&gt; 1.5 切换会话 tmux switch命令用于切换会话
# 使用会话编号 tmux switch -t 0 # 使用会话名称 tmux switch -t &lt;session-name&gt; 1.6 重命名会话 tmux rename-session命令用于重命名会话。
tmux rename-session -t 0 &lt;new-name&gt; 1.7 会话快捷键 $ Ctrl+b d：分离当前会话。 $ Ctrl+b s：列出所有会话。 $ Ctrl+b $：重命名当前会话。 2. 窗口管理 2.1 新建窗口 tmux new-window # 新建一个指定名称的窗口 tmux new-window -n &lt;window-name&gt; 2.2 切换窗口 # 切换到指定编号的窗口 tmux select-window -t &lt;window-number&gt; # 切换到指定名称的窗口 tmux select-window -t &lt;window-name&gt; 2.3 重命名窗口 tmux rename-window &lt;new-name&gt; 2.4 窗口快捷键 Ctrl+b c：创建一个新窗口，状态栏会显示多个窗口的信息。 Ctrl+b p：切换到上一个窗口（按照状态栏上的顺序）。 Ctrl+b n：切换到下一个窗口。 Ctrl+b ：切换到指定编号的窗口，其中的是状态栏上的窗口编号。 Ctrl+b w：从列表中选择窗口。 Ctrl+b ,：窗口重命名。 Ctrl+b %：划分左右两个窗格。 Ctrl+b &#34;：划分上下两个窗格。 Ctrl+b ：光标切换到其他窗格。是指向要切换到的窗格的方向键，比如切换到下方窗格，就按方向键↓。 Ctrl+b ;：光标切换到上一个窗格。 Ctrl+b o：光标切换到下一个窗格。 Ctrl+b {：当前窗格左移。 Ctrl+b }：当前窗格右移。 Ctrl+b Ctrl+o：当前窗格上移。 Ctrl+b Alt+o：当前窗格下移。 Ctrl+b x：关闭当前窗格。 Ctrl+b !：将当前窗格拆分为一个独立窗口。 Ctrl+b z：当前窗格全屏显示，再使用一次会变回原来大小。 Ctrl+b Ctrl+：按箭头方向调整窗格大小。 Ctrl+b q：显示窗格编号。 更改prefix前缀快捷键 修改系统级的/etc/tmux.conf或用户级的~/.tmux.conf，没有的话新建
向文件写入一下内容
set -g prefix C-x unbind C-b bind C-x send-prefix ]]></content></entry><entry><title>X-UI，支持多协议多用户的Xray面板</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/x-ui%E6%94%AF%E6%8C%81%E5%A4%9A%E5%8D%8F%E8%AE%AE%E5%A4%9A%E7%94%A8%E6%88%B7%E7%9A%84-xray-%E9%9D%A2%E6%9D%BF/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>XUI</tag></tags><content type="html"><![CDATA[X-ui，支持多协议多用户的 Xray 面板！ 1.0 安装x-ui x-ui地址： https://github.com/vaxilu/x-ui acme脚本地址： https://github.com/acmesh-official/acme.sh 1.0.1更新及安装组件 apt update -y # Debian/Ubuntu 命令 apt install -y curl #Debian/Ubuntu 命令 apt install -y socat #Debian/Ubuntu 命令 yum update -y #CentOS 命令 yum install -y curl #CentOS 命令 yum install -y socat #CentOS 命令 # 关闭防火墙 systemctl disable firewalld.service systemctl stop firewalld.service 1.0.2 安装 Acme 脚本 curl https://get.acme.sh | sh 1.0.3 80 端口空闲的证书申请方式 自行更换代码中的域名、邮箱为你解析的域名及邮箱
~/.acme.sh/acme.sh --set-default-ca --server letsencrypt /zerossl ~/.acme.sh/acme.sh --register-account -m xxxx@xxxx.com ~/.acme.sh/acme.sh --issue -d mydomain.com --standalone 1.0.4 安装证书到指定文件夹（选做） 自行更换代码中的域名为你解析的域名
~/.acme.sh/acme.sh --installcert -d mydomain.com --key-file /root/private.key --fullchain-file /root/cert.crt 1.0.5 安装 &amp; 升级 X-ui 面板 安装及升级的一键代码
bash &lt;(curl -Ls https://raw.githubusercontent.com/vaxilu/x-ui/master/install.sh) 2.0 节点配置及功能讲解 2.0.1 更改面板端口，根路径，用户名和密码 2.0.2 更改xray版本到最新(选做) 2.0.3 创建节点 vmess协议
vless 协议
Trojan 协议
2.0.4 nginx配置 配置此项之前先搭建https静态网站(伪装)
filebrowser (目前推荐安装此服务) 反代别人的网站 安装nginx dnf install nginx -y 安装filebrowser curl -fsSL https://raw.githubusercontent.com/filebrowser/get/master/get.sh | bash #创建配置数据库 filebrowser -d /etc/filebrowser/filebrowser.db config init #设置监听端口 filebrowser -d /etc/filebrowser/filebrowser.db config set --port 5210 #设置语言环境 filebrowser -d /etc/filebrowser/filebrowser.db config set --locale zh-cn #添加一个用户 filebrowser -d /etc/filebrowser/filebrowser.db users add admin password --perm.admin #设置网盘根目录 mkdir -p /data/fs filebrowser -d /etc/filebrowser/filebrowser.db config set --root /data/fs vim /lib/systemd/system/filebrowser.service -----------------------------filebrowser.service------------ [Unit] Description=File Browser After=network.target [Service] Type=simple ExecStart=/usr/local/bin/filebrowser -d /etc/filebrowser/filebrowser.db Restart=on-abnormal RestartSec=5s KillMode=mixed [Install] WantedBy=multi-user.target ----------------------------------------------------------- systemctl daemon-reload systemctl start filebrowser systemctl status filebrowser systemctl enable filebrowser 用户名：admin 密码：password 修改nginx配置 # 先删除nginx默认的80端口配置 vim /etc/nginx/nginx.conf 确保http中有红框中的内容 # 再添加新的配置 vim /etc/nginx/conf.d/vps.conf server{ ssl on; listen 443; server_name fs.gossip.tk; ssl_certificate /root/.acme.sh/fs.gossip.tk/fs.gossip.tk.cer; ssl_certificate_key /root/.acme.sh/fs.gossip.tk/fs.gossip.tk.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; # 反向代理filebrowser网站 location / { proxy_pass http://127.0.0.1:5210; # 设置文件上传大小 client_max_body_size 100M; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # x-ui面板 location ^~ /cocoly { proxy_pass http://127.0.0.1:10105/cocoly; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # ws协议 location /gofic { proxy_redirect off; proxy_pass http://127.0.0.1:31694; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &#34;upgrade&#34;; proxy_set_header Host $http_host; proxy_read_timeout 300s; # Show realip in v2ray access.log proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # 可以把ws协议统一管理 # include /etc/x-ui/location/*.conf; } 可自行更改x-ui的根路径和端口（下面的内容应填在https配置的地方）
location ^~ 面板url根路径 { proxy_pass http://127.0.0.1:面板监听端口/面板url根路径; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location 节点路径 { proxy_redirect off; proxy_pass http://127.0.0.1:节点端口; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &#34;upgrade&#34;; proxy_set_header Host $http_host; proxy_read_timeout 300s; # Show realip in v2ray access.log proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } ok之后可以到cloudflare开启小云朵代理 将SSL的模式改为完全，不然访问网站时可能会报** **此页面不能正确地重定向 错误 我的配置 vim /etc/nginx/conf.d/vps.conf
动态伪装网站配置（搭建了filebrowser）
server{ ssl on; listen 443; server_name fs.gossip.tk; ssl_certificate /root/.acme.sh/fs.gossip.tk/fs.gossip.tk.cer; ssl_certificate_key /root/.acme.sh/fs.gossip.tk/fs.gossip.tk.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; # 反向代理filebrowser网站 location / { proxy_pass http://127.0.0.1:5210; # 设置文件上传大小 client_max_body_size 100M; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # x-ui面板 location ^~ /cocoly { proxy_pass http://127.0.0.1:10105/cocoly; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # ws协议 location /gofic { proxy_redirect off; proxy_pass http://127.0.0.1:31694; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &#34;upgrade&#34;; proxy_set_header Host $http_host; proxy_read_timeout 300s; # Show realip in v2ray access.log proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # 可以把ws协议统一管理 # include /etc/x-ui/location/*.conf; } # 停止80端口的使用，证书的申请需要占用80端口 #server { # listen 80; # server_name pan.gossip.tk; # rewrite ^(.*)$ https://$host$1 permanent; #} 配置完成后重启nginx # 检查nginx 配置的语法错误 nginx -t systemctl restart nginx nginx -t 测试配置文件 nginx -s reload 修改配置后重载生效 nginx -s reopen 重新打开日志文件 nginx -s stop 快速停止 nginx -s quit 如果语法检查通过，重启报错的话，应该是端口被占用了
复制节点信息到代理软件中 注意勾选底层传输为tls（虽然节点并没有开启tls，但nginx已经转发到了443端口），并填写伪装域名
开启cloudflare代理(选做) 优选IP 软件下载地址
Github： https://github.com/XIU2/CloudflareSpeedTest 蓝奏云： https://pan.lanzouo.com/b0742hkxe 将优选出来的IP填入到之前的域名地址中，注意填写伪装域名
成功之后可对节点进行测速，对比之前的0.4M/s快了很多
]]></content></entry><entry><title>编译安装Nginx</title><url>/posts/nginx/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85nginx/</url><categories><category>Nginx</category></categories><tags><tag>Nginx</tag></tags><content type="html"><![CDATA[编译安装Nginx 1. 卸载原有的Nginx dnf remove nginx nginx-common 2. 安装编译依赖 2.1 安装编译工具 dnf install make automake gcc gcc-c++ kernel-devel 2.2 安装编译时需要的依赖 dnf install -y pcre pcre-devel pcre2 pcre2-devel zlib zlib-devel openssl openssl-devel libxslt-devel 2.3 拉取需要编译的模块 git clone https://github.com/arut/nginx-dav-ext-module 3. 下载并解压nginx wget http://nginx.org/download/nginx-1.23.3.tar.gz &amp;&amp; tar -zvxf nginx-1.23.3.tar.gz ##　4. 编译nginx
4.1 创建nginx用户 注意： 后面并没有使用nginx用户启动，需要自行配置
#创建nginx用户与用户组 useradd -s /sbin/nologin nginx 4.2 做编译前的配置 ./configure \ --prefix=/usr \ --sbin-path=/usr/sbin/nginx \ --conf-path=/etc/nginx/nginx.conf \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --pid-path=/var/run/nginx/nginx.pid \ --lock-path=/var/lock/nginx.lock \ --user=nginx \ --group=nginx \ --with-http_gzip_static_module \ --with-http_ssl_module \ --with-http_stub_status_module \ --with-http_flv_module \ --with-http_dav_module --add-module=../nginx-dav-ext-module configure参数解释:
--prefix=/usr/ # 指向安装目录 --sbin-path=/usr/sbin/nginx \ # 指向（执行）程序文件（nginx） --conf-path=/etc/nginx/nginx.conf # 指定配置文件 --http-log-path=/var/log/nginx/access.log # 指定访问日志 --error-log-path=/var/log/nginx/error.log # 指定错误日志 --lock-path=/var/lock/nginx.lock # 指定lock文件 --pid-path=/var/run/nginx/nginx.pid # 指定pid文件 --user=nginx \ # 指定用户 --group=nginx \ # 指定用户组 --http-client-body-temp-path=/var/lib/nginx/body # 设定http客户端请求临时文件路径 --http-fastcgi-temp-path=/var/lib/nginx/fastcgi # 设定http fastcgi临时文件路径 --http-proxy-temp-path=/var/lib/nginx/proxy # 设定http代理临时文件路径 --http-scgi-temp-path=/var/lib/nginx/scgi # 设定http scgi临时文件路径 --http-uwsgi-temp-path=/var/lib/nginx/uwsgi # 设定http uwsgi临时文件路径 --with-pcre # 启用pcre库 --with-debug # 启用debug日志 --with-pcre-jit # 编译PCRE包含“just-in-time compilation” --with-ipv6 # 启用ipv6支持 --with-http_ssl_module # 启用ssl支持 --with-http_stub_status_module # 获取nginx自上次启动以来的状态 --with-http_realip_module # 允许从请求标头更改客户端的IP地址值，默认为关 --with-http_auth_request_module # 实现基于一个子请求的结果的客户端授权。如果该子请求返回的2xx响应代码，所述接入是允许的。如果它返回401或403中，访问被拒绝与相应的错误代码。由子请求返回的任何其他响应代码被认为是一个错误。 --with-http_addition_module # 作为一个输出过滤器，支持不完全缓冲，分部分响应请求 --with-http_dav_module # 增加PUT,DELETE,MKCOL：创建集合,COPY和MOVE方法 默认关闭，需编译开启 --with-http_geoip_module # 使用预编译的MaxMind数据库解析客户端IP地址，得到变量值 --with-http_gunzip_module # 它为不支持“gzip”编码方法的客户端解压具有“Content-Encoding: gzip”头的响应。 --with-http_gzip_static_module # 在线实时压缩输出数据流 --with-http_image_filter_module # 传输JPEG/GIF/PNG 图片的一个过滤器）（默认为不启用。gd库要用到） --with-http_spdy_module # SPDY可以缩短网页的加载时间 --with-http_sub_module # 允许用一些其他文本替换nginx响应中的一些文本 --with-http_xslt_module # 过滤转换XML请求 --with-mail # 启用POP3/IMAP4/SMTP代理模块支持 --with-mail_ssl_module # 启用ngx_mail_ssl_module支持启用外部模块支持 4.3 编译并安装 make &amp;&amp; make install ##　5．为 nginx 创建 systemd 单元
vim /etc/systemd/system/nginx.service [Unit] Description=nginx Documentation=https://nginx.org/en/docs/ After=network-online.target remote-fs.target nss-lookup.target Wants=network-online.target [Service] Type=forking PIDFile=/var/run/nginx/nginx.pid ExecStartPre=/usr/sbin/nginx -t -c /etc/nginx/nginx.conf ExecStart=/usr/sbin/nginx -c /etc/nginx/nginx.conf ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s TERM $MAINPID [Install] WantedBy=multi-user.target 之后使用 systemd 即可控制 nginx 服务的启动，停止等
systemctl daemon-reload systemctl start nginx systemctl status nginx # 使用ss查看端口 [root@localhost]# ss -lnt State Recv-Q Send-Q Local Address:Port Peer Address:Port Process LISTEN 0 511 0.0.0.0:80 0.0.0.0:* LISTEN 0 128 0.0.0.0:22 0.0.0.0:* LISTEN 0 128 [::]:22 [::]:* ]]></content></entry><entry><title>搭建私有云盘</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E4%BA%91%E7%9B%98/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>cloudreve</tag></tags><content type="html">
下载并安装cloudreve GitHub仓库地址： https://github.com/cloudreve/Cloudreve/releases 下载arm版本 上传并解压 # 解压程序包 tar -zxvf cloudreve_VERSION_OS_ARCH.tar.gz # 赋予执行权限 chmod +x ./cloudreve # 启动 Cloudreve ./cloudreve 这个时候控制台会显示管理员的用户名和密码，访问树莓派的5212端口（先放行5212端口）就可以来到网站
添加守护进程，让其开机自启 # 编辑配置文件 sudo vim /usr/lib/systemd/system/cloudreve.service 将下文 PATH_TO_CLOUDREVE 更换为程序所在目录：
[Unit] Description=Cloudreve Documentation=https://docs.cloudreve.org After=network.target After=mysqld.service Wants=network.target [Service] WorkingDirectory=/PATH_TO_CLOUDREVE ExecStart=/PATH_TO_CLOUDREVE/cloudreve Restart=on-abnormal RestartSec=5s KillMode=mixed StandardOutput=null StandardError=syslog [Install] WantedBy=multi-user.target ======================法二======================== [Unit] Description=Cloudreve Documentation=https://docs.cloudreve.org After=network.target Wants=network.target [Service] WorkingDirectory=/opt ExecStart=/opt/cloudreve Restart=on-abnormal RestartSec=5s KillMode=mixed StandardOutput=null StandardError=syslog [Install] WantedBy=multi-user.target # 更新配置 sudo systemctl daemon-reload # 启动服务 sudo systemctl start cloudreve # 设置开机启动 sudo systemctl enable cloudreve 管理命令：
# 启动服务 sudo systemctl start cloudreve # 停止服务 sudo systemctl stop cloudreve # 重启服务 sudo systemctl restart cloudreve # 查看状态 sudo systemctl status cloudreve 安装Aria2让cloudreve支持离线下载 BT下载服务搭建 cloudreve配置aria2 来到cloudreve首页，点击管理面板 RPC Secret处填写自己设定的密码
RPC 服务器地址填写本地aria2监听的端口
填写一下临时下载目录保存就行了
批量删除前缀 j=&amp;#34;&amp;#34;;for i in `ls` ;do echo $i;j=${i#*_};mv $i $j;echo $j ;done</content></entry><entry><title>使用Kali爆破WIFI密码</title><url>/posts/linux%E6%93%8D%E4%BD%9C/%E4%BD%BF%E7%94%A8kali%E7%88%86%E7%A0%B4wifi%E5%AF%86%E7%A0%81/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html">使用kali爆破WiFi密码 首先准备一个免驱的kali无线网卡 过程 插上无线网卡，让虚拟机的kali连接上无线网卡 打开终端，使用ifconfig查看网卡信息 可以看到wlan0就是无线网卡
注意： 以下命令都在root模式下执行
为无线网卡开启监听模式 airmon-ng start wlan0 若遇到提示，则运行提示里的命令即可
再次使用ifconfig命令查看是否被监听
若后面出现mon则说明已经被监听
扫描附近的WiFi airodump-ng wlan0mon BSSID 表示MAC地址 PWR 表示信号 -------排名越靠前的信号越好 CH 表示信号道 ESSID 表示WiFi名称 大概稳定之后可以使用Ctrl + C结束扫描
抓包 airodump-ng --bssid 02:4B:F3:00:7E:D7 -c 6 --write /home/kali/demo wlan0mon --bssid 表示目标WiFi的MAC地址 -c 表示目标WiFi所处的信号道 --wirte 表示抓到的包所在的文件地址（/home/kali/ 为文件目录） 若红框中并没有内容则说明还没抓到数据包，这时需要有人连接上WiFi或者让连接的设备下线，让设备再次自动连接WiFi，这时就可以抓取到握手包
我们选择后者的操作，重新打开新的终端，使用命令
sudo aireplay-ng -0 3 -a 02:4B:F3:00:7E:D7 wlan0mon -0 表示发送攻击的数据包个数 -a 表示目标WiFi的MAC地址 这个时候可以发现上一个终端所标的红框处已经有了内容，说明抓包成功
来到保存握手包的目录，可以发现握手包已经放在了此目录下
使用密码字典进行爆破 密码字典可以使用网上找的，也可以使用kali自带的
来到密码字典所在的目录，执行下面命令
aircrack-ng -w FastPwds.txt /home/kali/demo-01.cap -w 表示密码字典 /home/kali/demo-01.cap 则是握手包 啪的一下，很快啊，就爆破完了(前提密码很简单)，红框中的内容就是密码
注意：本方法只是用来学习和交流的</content></entry><entry><title>使用Nginx快速搭建文件索引服务</title><url>/posts/nginx/%E4%BD%BF%E7%94%A8nginx%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E6%96%87%E4%BB%B6%E7%B4%A2%E5%BC%95%E6%9C%8D%E5%8A%A1/</url><categories><category>Nginx</category></categories><tags><tag>Nginx</tag></tags><content type="html">使用宝塔面板 在宝塔面板找到Nginx，点击设置，打开配置修改
在http的花括号中添加以下内容
server { listen 80; # 监听80端口 server_name localhost; # 自己PC的ip或者服务器的域名 charset utf-8; # 避免中文乱码 root /opt/data; # 存放文件的目录 location / { autoindex on; # 索引 autoindex_exact_size on; # 显示文件大小 autoindex_localtime on; # 显示文件时间 } } 修改完成后，点击最上面的服务，选择重载配置
打开主机ip的80端口就能看到文件索引了
不使用宝塔面板 1.安装nginx
sudo apt-get install nginx 2.创建conf文件
sudo vim /etc/nginx/conf.d/file_server.conf 3.修改conf文件如下：
server { listen 80; # 监听80端口 server_name localhost; # 自己PC的ip或者服务器的域名 charset utf-8; # 避免中文乱码 root /opt/data; # 存放文件的目录 location / { autoindex on; # 索引 autoindex_exact_size on; # 显示文件大小 autoindex_localtime on; # 显示文件时间 } } 3.使配置生效
sudo rm /etc/nginx/sites-enabled/default sudo service nginx reload 4.重启命令
sudo /etc/init.d/nginx start|stop|reload| sudo service nginx start|stop|reload| 5.访问 浏览器里直接输入 主机IP:80</content></entry><entry><title>Containerd安装</title><url>/posts/docker/containerd%E5%AE%89%E8%A3%85/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[官方下载地址：https://github.com/containerd/containerd/releases
wget https://github.com/containerd/containerd/releases/download/v1.6.8/cri-containerd-cni-1.6.8-linux-amd64.tar.gz mkdir cri-containerd-cni &amp;&amp; tar -zxvf cri-containerd-cni-1.6.8-linux-amd64.tar.gz -C cri-containerd-cni 复制配置文件
cp cri-containerd-cni/etc/crictl.yaml /etc/ cp cri-containerd-cni/etc/systemd/system/containerd.service /etc/systemd/system/ # 复制 containerd 和相关依赖 cp cri-containerd-cni/usr/local/bin/. /usr/local/bin/ -a # 复制runc文件 cp cri-containerd-cni/usr/local/sbin/. /usr/local/sbin/ -a 生成和配置启动文件 # 1. 创建文件夹 mkdir -p /etc/containerd # 2. 生成配置文件 containerd config default &gt; /etc/containerd/config.toml vim /etc/containerd/config.toml disabled_plugins = [] imports = [] oom_score = 0 plugin_dir = &#34;&#34; required_plugins = [] root = &#34;/var/lib/containerd&#34; state = &#34;/run/containerd&#34; version = 2 [cgroup] path = &#34;&#34; [debug] address = &#34;&#34; format = &#34;&#34; gid = 0 level = &#34;&#34; uid = 0 [grpc] address = &#34;/run/containerd/containerd.sock&#34; gid = 0 max_recv_message_size = 16777216 max_send_message_size = 16777216 tcp_address = &#34;&#34; tcp_tls_cert = &#34;&#34; tcp_tls_key = &#34;&#34; uid = 0 [metrics] address = &#34;&#34; grpc_histogram = false [plugins] [plugins.&#34;io.containerd.gc.v1.scheduler&#34;] deletion_threshold = 0 mutation_threshold = 100 pause_threshold = 0.02 schedule_delay = &#34;0s&#34; startup_delay = &#34;100ms&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;] disable_apparmor = false disable_cgroup = false disable_hugetlb_controller = true disable_proc_mount = false disable_tcp_service = true enable_selinux = false enable_tls_streaming = false ignore_image_defined_volumes = false max_concurrent_downloads = 3 max_container_log_line_size = 16384 netns_mounts_under_state_dir = false restrict_oom_score_adj = false # sandbox_image = &#34;k8s.gcr.io/pause:3.5&#34; # 1. 修改基础镜像地址 sandbox_image = &#34;registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5&#34; selinux_category_range = 1024 stats_collect_period = 10 stream_idle_timeout = &#34;4h0m0s&#34; stream_server_address = &#34;127.0.0.1&#34; stream_server_port = &#34;0&#34; systemd_cgroup = false tolerate_missing_hugetlb_controller = true unset_seccomp_profile = &#34;&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.cni] bin_dir = &#34;/opt/cni/bin&#34; conf_dir = &#34;/etc/cni/net.d&#34; conf_template = &#34;&#34; max_conf_num = 1 [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd] default_runtime_name = &#34;runc&#34; disable_snapshot_annotations = true discard_unpacked_layers = false no_pivot = false snapshotter = &#34;overlayfs&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.default_runtime] base_runtime_spec = &#34;&#34; container_annotations = [] pod_annotations = [] privileged_without_host_devices = false runtime_engine = &#34;&#34; runtime_root = &#34;&#34; runtime_type = &#34;&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.default_runtime.options] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc] base_runtime_spec = &#34;&#34; container_annotations = [] pod_annotations = [] privileged_without_host_devices = false runtime_engine = &#34;&#34; runtime_root = &#34;&#34; runtime_type = &#34;io.containerd.runc.v2&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc.options] BinaryName = &#34;&#34; CriuImagePath = &#34;&#34; CriuPath = &#34;&#34; CriuWorkPath = &#34;&#34; IoGid = 0 IoUid = 0 NoNewKeyring = false NoPivotRoot = false Root = &#34;&#34; ShimCgroup = &#34;&#34; SystemdCgroup = false [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.untrusted_workload_runtime] base_runtime_spec = &#34;&#34; container_annotations = [] pod_annotations = [] privileged_without_host_devices = false runtime_engine = &#34;&#34; runtime_root = &#34;&#34; runtime_type = &#34;&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.untrusted_workload_runtime.options] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.image_decryption] key_model = &#34;node&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry] config_path = &#34;&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.auths] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.configs] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.headers] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.mirrors] # 2. 设置仓库地址 [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.mirrors.&#34;docker.io&#34;] endpoint = [&#34;https://usydjf4t.mirror.aliyuncs.com&#34;] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.mirrors.&#34;k8s.gcr.io&#34;] endpoint = [&#34;https://registry.cn-hangzhou.aliyuncs.com/google_containers&#34;] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.x509_key_pair_streaming] tls_cert_file = &#34;&#34; tls_key_file = &#34;&#34; [plugins.&#34;io.containerd.internal.v1.opt&#34;] path = &#34;/opt/containerd&#34; [plugins.&#34;io.containerd.internal.v1.restart&#34;] interval = &#34;10s&#34; [plugins.&#34;io.containerd.metadata.v1.bolt&#34;] content_sharing_policy = &#34;shared&#34; [plugins.&#34;io.containerd.monitor.v1.cgroups&#34;] no_prometheus = false [plugins.&#34;io.containerd.runtime.v1.linux&#34;] no_shim = false runtime = &#34;runc&#34; runtime_root = &#34;&#34; shim = &#34;containerd-shim&#34; shim_debug = false [plugins.&#34;io.containerd.runtime.v2.task&#34;] platforms = [&#34;linux/amd64&#34;] [plugins.&#34;io.containerd.service.v1.diff-service&#34;] default = [&#34;walking&#34;] [plugins.&#34;io.containerd.snapshotter.v1.aufs&#34;] root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.btrfs&#34;] root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.devmapper&#34;] async_remove = false base_image_size = &#34;&#34; pool_name = &#34;&#34; root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.native&#34;] root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.overlayfs&#34;] root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.zfs&#34;] root_path = &#34;&#34; [proxy_plugins] [stream_processors] [stream_processors.&#34;io.containerd.ocicrypt.decoder.v1.tar&#34;] accepts = [&#34;application/vnd.oci.image.layer.v1.tar+encrypted&#34;] args = [&#34;--decryption-keys-path&#34;, &#34;/etc/containerd/ocicrypt/keys&#34;] env = [&#34;OCICRYPT_KEYPROVIDER_CONFIG=/etc/containerd/ocicrypt/ocicrypt_keyprovider.conf&#34;] path = &#34;ctd-decoder&#34; returns = &#34;application/vnd.oci.image.layer.v1.tar&#34; [stream_processors.&#34;io.containerd.ocicrypt.decoder.v1.tar.gzip&#34;] accepts = [&#34;application/vnd.oci.image.layer.v1.tar+gzip+encrypted&#34;] args = [&#34;--decryption-keys-path&#34;, &#34;/etc/containerd/ocicrypt/keys&#34;] env = [&#34;OCICRYPT_KEYPROVIDER_CONFIG=/etc/containerd/ocicrypt/ocicrypt_keyprovider.conf&#34;] path = &#34;ctd-decoder&#34; returns = &#34;application/vnd.oci.image.layer.v1.tar+gzip&#34; [timeouts] &#34;io.containerd.timeout.shim.cleanup&#34; = &#34;5s&#34; &#34;io.containerd.timeout.shim.load&#34; = &#34;5s&#34; &#34;io.containerd.timeout.shim.shutdown&#34; = &#34;3s&#34; &#34;io.containerd.timeout.task.state&#34; = &#34;2s&#34; [ttrpc] address = &#34;&#34; gid = 0 uid = 0 启动 systemctl daemon-reload systemctl enable containerd --now systemctl status containerd ]]></content></entry><entry><title>Docker换源</title><url>/posts/docker/%E6%8D%A2%E6%BA%90/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[Podman换源 网易 hub-mirror.c.163.com USTC docker.mirrors.ustc.edu.cn vim /etc/containers/registries.conf ################################################ unqualified-search-registries = [&#34;docker.io&#34;] [[registry]] prefix = &#34;docker.io&#34; location = &#34;l6p4ic76.mirror.aliyuncs.com&#34; ################################################# Docker换源 vim /etc/docker/daemon.json { &#34;registry-mirrors&#34;: [&#34;https://l6p4ic76.mirror.aliyuncs.com&#34;], &#34;log-driver&#34;:&#34;json-file&#34;, &#34;log-opts&#34;: {&#34;max-size&#34;:&#34;500m&#34;, &#34;max-file&#34;:&#34;3&#34;} } systemctl restart docker &gt; 南京大学 https://docker.nju.edu.cn/ &gt; 网易 http://hub-mirror.c.163.com &gt; 腾讯云 docker hub mirror https://mirror.ccs.tencentyun.com &gt; docker中国 https://registry.docker-cn.com &gt; 我的 daocloud http://f1361db2.m.daocloud.io &gt; 我的华为云 https://326fcbdbb5c7487aa2d8180833e71119.mirror.swr.myhuaweicloud.com ) 我的阿里云 https://l6p4ic76.mirror.aliyuncs.com 查看镜像源 docker info podman info ]]></content></entry><entry><title>K8S集群部署</title><url>/posts/docker/k8s%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[官网地址：https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/
1. 搭建单Master集群 创建一个 Master 节点 kubeadm init 将 Node节点加入到当前集群中 kubeadm join &lt;Master节点的IP和端口&gt; 环境准备 工作节点 主机名 IP地址 系统版本 master k8s-master 192.168.211.201 almalinux8.6 node1 k8s-node1 192.168.211.202 almalinux8.6 node2 k8s-node2 192.168.211.203 almalinux8.6 注意： 从 2 - 5 的内容在在master和node节点主机在都要执行
2. 安装前准备 2.1 修改和添加主机名 # 修改主机名 # 在master节点执行 hostnamectl set-hostname k8s-master # 在node节点执行 hostnamectl set-hostname k8s-node1 hostnamectl set-hostname k8s-node2 # 添加主机名 cat &gt;&gt; /etc/hosts &lt;&lt; EOF 192.168.211.201 k8s-master 192.168.211.202 k8s-node1 192.168.211.203 k8s-node2 EOF 2.2 关闭防火墙 systemctl stop firewalld systemctl disable firewalld 2.3 关闭 selinux sed -i &#39;s/SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux setenforce 0 2.4 关闭swap分区 先临时关闭，再永久关闭，这样就不用重启 # 临时关闭 swapoff -a # 永久关闭 sed -ri &#39;s/.*swap.*/#&amp;/&#39; /etc/fstab # 重启生效 # 查看效果 free -m # 重新启动swap分区 swapon -a 2.5 网桥过滤 cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-arptables = 1 net.ipv4.ip_forward=1 net.ipv4.ip_forward_use_pmtu = 0 EOF # 生效命令 sysctl --system 2.6 时间同步 # 安装软件 yum -y install ntpdate # 向阿里云服务器同步时间 ntpdate time1.aliyun.com # 删除本地时间并设置时区为上海 rm -rf /etc/localtime ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # 查看时间 date -R || date 3. 所有节点安装Docker 1.卸载旧版本 yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-engine 2.安装需要的依赖包	yum install -y yum-utils 3.设置阿里云docker镜像 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo &amp;&amp; yum makecache 4.安装docker yum -y install docker-ce docker-ce-cli containerd.io 5.启动Docker systemctl start docker &amp;&amp; systemctl enable docker &amp;&amp; systemctl status docker 6.查看docker版本信息 docker info 4. 所有节点配置阿里云Docker、kubernetes镜像 1. 配置阿里云docker镜像加速 mkdir -p /etc/docker cat &gt; /etc/docker/daemon.json &lt;&lt; EOF { &#34;registry-mirrors&#34;: [&#34;https://l6p4ic76.mirror.aliyuncs.com&#34;], &#34;log-driver&#34;:&#34;json-file&#34;, &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;], &#34;log-opts&#34;: {&#34;max-size&#34;:&#34;500m&#34;, &#34;max-file&#34;:&#34;3&#34;} } EOF systemctl restart docker 2. 配置阿里云Kubernetes 镜像 cat &gt;&gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 5. 所有节点安装kubelet kubeadm kubectl yum install -y --nogpgcheck kubelet-1.22.15 kubeadm-1.22.15 kubectl-1.22.15 # 指定K8S版本安装，不指定版本默认安装最新版。 # yum install -y --nogpgcheck kubelet kubeadm kubectl systemctl enable kubelet &amp;&amp; systemctl start kubelet 6. 部署Kubernetes Master节点 这里指定阿里云镜像仓库地址，默认的镜像地址无法加载访问。
kubeadm init \ --apiserver-advertise-address=192.168.211.201 \ --image-repository registry.aliyuncs.com/google_containers \ --kubernetes-version v1.22.15 \ --service-cidr=10.96.0.0/12 \ --pod-network-cidr=10.244.0.0/16 若出现错误
[root@almalinux ~]# kubeadm init \ &gt; --apiserver-advertise-address=192.168.211.201 \ &gt; --image-repository registry.aliyuncs.com/google_containers \ &gt; --kubernetes-version v1.25.3 \ &gt; --service-cidr=10.96.0.0/12 \ &gt; --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.25.3 [preflight] Running pre-flight checks [WARNING FileExisting-tc]: tc not found in system path error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR CRI]: container runtime is not running: output: E1029 14:48:00.390255 29768 remote_runtime.go:948] &#34;Status from runtime service failed&#34; err=&#34;rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.RuntimeService&#34; time=&#34;2022-10-29T14:48:00+08:00&#34; level=fatal msg=&#34;getting status of runtime: rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.RuntimeService&#34; , error: exit status 1 [preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...` To see the stack trace of this error execute with --v=5 or higher 解决办法
rm -rf /etc/containerd/config.toml systemctl restart containerd # 最后使用 kubeadm reset 若出现错误
[root@k8s-master ~]# kubeadm init \ &gt; --apiserver-advertise-address=192.168.211.201 \ &gt; --image-repository registry.aliyuncs.com/google_containers \ &gt; --kubernetes-version v1.25.3 \ &gt; --service-cidr=10.96.0.0/12 \ &gt; --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.25.3 [preflight] Running pre-flight checks [WARNING FileExisting-tc]: tc not found in system path [WARNING Hostname]: hostname &#34;k8s-master&#34; could not be reached [WARNING Hostname]: hostname &#34;k8s-master&#34;: lookup k8s-master on 223.5.5.5:53: no such host error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist [preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...` To see the stack trace of this error execute with --v=5 or higher 解决方法
modprobe br_netfilter echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables 注意： 如果要使用 kubectl get nodes 命令需要做以下配置
- master节点，root用户，执行以下命令 echo &#34;export KUBECONFIG=/etc/kubernetes/admin.conf&#34; &gt;&gt; ~/.bash_profile source ~/.bash_profile - master节点，非root用户，执行以下命令 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config - node节点需要从 master 节点拷贝 admin.con 文件到 node 节点上 scp root@master:/etc/kubernetes/admin.conf /etc/kubernetes/ - root 和 非root 用户的命令同master 7. 部署网络插件 # 以下网络插件任选一个 # CNI网络插件 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml # Flannel网络插件 kubectl apply -f https://kuboard.cn/install-script/flannel/flannel-v0.14.0.yaml # 查看 kubectl get pods -n kube-system 若发现有Pending的删除即可，会自动重新部署
[root@k8s-master ~]# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-7f6cbbb7b8-6gxf6 0/1 Pending 0 23m coredns-7f6cbbb7b8-nnjsk 0/1 Pending 0 23m etcd-k8s-master 1/1 Running 1 23m kube-apiserver-k8s-master 1/1 Running 1 23m kube-controller-manager-k8s-master 1/1 Running 1 23m kube-proxy-6d4d6 1/1 Running 0 18m kube-proxy-m4vx9 1/1 Running 0 23m kube-scheduler-k8s-master 1/1 Running 1 23m [root@k8s-master ~]# kubectl delete pods coredns-7f6cbbb7b8-6gxf6 coredns-7f6cbbb7b8-nnjsk -n kube-system pod &#34;coredns-7f6cbbb7b8-6gxf6&#34; deleted pod &#34;coredns-7f6cbbb7b8-nnjsk&#34; deleted [root@k8s-master ~]# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-7f6cbbb7b8-4df47 1/1 Running 0 11s coredns-7f6cbbb7b8-wxzcl 1/1 Running 0 11s etcd-k8s-master 1/1 Running 1 24m kube-apiserver-k8s-master 1/1 Running 1 24m kube-controller-manager-k8s-master 1/1 Running 1 24m kube-proxy-6d4d6 1/1 Running 0 19m kube-proxy-m4vx9 1/1 Running 0 24m kube-scheduler-k8s-master 8. 部署node节点 # 只在 master 节点执行 kubeadm token create --print-join-command # 在node节点中执行打印出的结果 kubeadm join 192.168.211.201:6443 --token hfyeoe.ie453hoen4eku70w --discovery-token-ca-cert-hash sha256:3716cd7f3c8a52b78b1ab495e7fbd3c6f7dabd899a0237c203c05bce11ac9be6 # 在 master 节点中查看 [root@k8s-master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master Ready control-plane,master 59m v1.22.3 k8s-node1 Ready &lt;none&gt; 54m v1.22.3 k8s-node2 Ready &lt;none&gt; 3m53s v1.22.3 注意： 若新加入的node节点出现NotReady等待一会即可
9. 添加图形化管理（选做） # 在 master 节点执行 kubectl apply -f https://addons.kuboard.cn/kuboard/kuboard-v3-swr.yaml 执行指令 watch kubectl get pods -n kuboard，等待 kuboard 名称空间中所有的 Pod 就绪
root@k8s-master ~]# kubectl get pods -n kuboard NAME READY STATUS RESTARTS AGE kuboard-agent-2-85d76b44dd-jvpm2 1/1 Running 0 9s kuboard-agent-67864c5f66-4w9z2 1/1 Running 0 9s kuboard-etcd-htppb 1/1 Running 0 36s kuboard-v3-765f7bcbfd-lpwct 0/1 Running 0 36s 访问 Kuboard 在浏览器中打开链接 http://your-node-ip-address:30080
输入初始用户名和密码，并登录
用户名： admin 密码： Kuboard123 卸载 kubectl delete -f https://addons.kuboard.cn/kuboard/kuboard-v3-swr.yaml rm -rf /usr/share/kuboard ]]></content></entry><entry><title>安装Docker</title><url>/posts/docker/%E5%AE%89%E8%A3%85docker/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html">1. 命令行安装 1.1 卸载旧版本 yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine 1.2 安装 执行以下命令安装依赖包：
yum install -y yum-utils 鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。 执行下面的命令添加 yum 软件源：
yum-config-manager \ --add-repo \ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 官方源 # yum-config-manager \ # --add-repo \ # https://download.docker.com/linux/centos/docker-ce.repo 更新 yum 软件源缓存，并安装 docker-ce
yum makecache yum install docker-ce docker-ce-cli containerd.io docker-scan-plugin docker-compose-plugin docker-ce-rootless-extras 1.3 防火墙额外设置 由于 CentOS8 防火墙使用了 nftables，但 Docker 尚未支持 nftables， 我们可以使用如下设置使用 iptables：
更改 vim /etc/firewalld/firewalld.conf
# FirewallBackend=nftables FirewallBackend=iptables 或者执行如下命令：
firewall-cmd --permanent --zone=trusted --add-interface=docker0 firewall-cmd --reload 2. 使用脚本自动安装 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 3. 启动Docker systemctl enable docker systemctl start docker</content></entry><entry><title>使用Docker安装常用环境</title><url>/posts/docker/%E4%BD%BF%E7%94%A8docker%E5%AE%89%E8%A3%85%E5%B8%B8%E7%94%A8%E7%8E%AF%E5%A2%83/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[安装Docker $ curl -fsSL get.docker.com -o get-docker.sh $ sudo sh get-docker.sh --mirror Aliyun 卸载
dnf remove -y -q docker-ce docker-ce-cli containerd.io docker-scan-plugin docker-compose-plugin docker-ce-rootless-extras rm -rf 启动 Docker $ sudo systemctl enable docker $ sudo systemctl start docker 建立 docker 用户组 默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。
建立 docker 组：
$ sudo groupadd docker 将当前用户加入 docker 组：
$ sudo usermod -aG docker $USER 注销用户或者重启系统 更换镜像源 vim /etc/docker/daemon.json {&#34;registry-mirrors&#34;: [&#34;http://hub-mirror.c.163.com&#34;]} systemctl restart docker 2) 腾讯云 docker hub mirror https://mirror.ccs.tencentyun.com 3) 华为云 https://05f073ad3c0010ea0f4bc00b7105ec20.mirror.swr.myhuaweicloud.com 4) docker中国 https://registry.docker-cn.com 5) 网易 http://hub-mirror.c.163.com 6) daocloud http://f1361db2.m.daocloud.io 安装Docker图形化界面 #下载 Docker 图形化界面 portainer sudo docker pull portainer/portainer #创建 portainer 容器 sudo docker volume create portainer_data #运行 portainer sudo docker run -d \ -p 9000:9000 \ --name portainer \ --restart always \ -v /var/run/docker.sock:/var/run/docker.sock \ -v portainer_data:/data \ portainer/portainer 安装MySql //拉取MySQL镜像 docker pull mysql //启动MySQL，注意更改密码，用户名为root，密码czyadmin docker run -d \ --name mysql \ --restart=always \ -p 3306:3306 \ -e MYSQL_ROOT_PASSWORD=czyadmin \ mysql 安装Redis //拉取Redis镜像 docker pull redis //启动Redis，注意更改密码，用户名为root，密码czyadmin docker run -d \ --name redis \ --restart=always \ -p 6379:6379 \ redis \ --requirepass &#34;czyadmin&#34; 安装Nginx 拉取镜像
docker pull nginx 创建本地配置文件
mkdir -p /etc/nginx/conf.d &amp;&amp; vim /etc/nginx/nginx.conf user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#39;$remote_addr - $remote_user [$time_local] &#34;$request&#34; &#39; &#39;$status $body_bytes_sent &#34;$http_referer&#34; &#39; &#39;&#34;$http_user_agent&#34; &#34;$http_x_forwarded_for&#34;&#39;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 启动服务
//启动nginx，映射本地配置文件 docker run -d \ --name nginx \ --restart=always \ -p 80:80 \ -v /etc/nginx/nginx.conf:/etc/nginx/nginx.conf \ -v /etc/nginx/conf.d:/etc/nginx/conf.d \ nginx vim /etc/nginx/conf.d/demo.conf server { listen 80; listen [::]:80; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; } } docker exec nginx bash -c &#39;nginx -s reload&#39; 安装RabbitMQ docker pull rabbitmq:management 默认用户名和密码：guest/guest
docker run -dit \ --name rabbitmq \ --restart=always \ -p 5672:5672 \ -p 15672:15672 \ rabbitmq:management 端口 作用 15672 管理界面UI的使用端口 15671 管理监听端口 5672,5671 AMQP 0-9-1 without and with TLSclient端通信口 4369 (epmd)epmd代表Erlang端口映射守护进程，erlang发现口 25672 ( Erlang distribution) server间内部通信口 安装Postgresql docker pull postgres docker run -d \ --name postgres \ --restart=always \ -p 5432:5432 \ -e POSTGRES_PASSWORD=czyadmin \ postgres 用户名：postgres	密码：czyadmin
]]></content></entry><entry><title>树莓派使用Docker安装openwrt作为旁路由(网关服务器)</title><url>/posts/docker/%E6%A0%91%E8%8E%93%E6%B4%BE%E4%BD%BF%E7%94%A8docker%E5%AE%89%E8%A3%85openwrt%E4%BD%9C%E4%B8%BA%E6%97%81%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3%E6%9C%8D%E5%8A%A1%E5%99%A8/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag><tag>树莓派</tag></tags><content type="html"><![CDATA[
推荐使用 树莓派爱好基地的arm64无桌面增强版镜像
仓库地址： https://github.com/openfans-community-offical/Debian-Pi-Aarch64/blob/master/README_zh.md 仓库中有详细的说明文档和下载地址
开始安装openwrt容器 树莓派爱好基地的arm64无桌面增强版自带docker，可以直接使用
1. 打开网卡混杂模式 sudo ip link set eth0 promisc on 2. 创建macvlan虚拟网络，同一网段下的主机才能访问容器 下面的网段(subnet)和网关(gateway)选项请结合实际自行更改
docker network create -d macvlan --subnet=192.168.0.0/24 --gateway=192.168.0.1 -o parent=eth0 macnet 此时，我们使用 docker network ls命令可以看到网络macnet已建立成功：
pi@raspbian:~$ docker network ls NETWORK ID NAME DRIVER SCOPE 7b8e38d3dd3c bridge bridge local f96e6360c248 host host local 7c7a5a51b268 macnet macvlan local c8c6782b8e1e none null local 3. 拉取openwrt镜像 docker pull registry.cn-shanghai.aliyuncs.com/suling/openwrt:rpi4 镜像拉取完成后，我们可以执行docker images命令查看现存镜像：
docker images REPOSITORY TAG IMAGE ID CREATED SIZE registry.cn-shanghai.aliyuncs.com/suling/openwrt rpi4 c3ba4d17a20e 32 hours ago 455MB 4. 创建并启动容器 docker run --restart always --name openwrt -d --network macnet --privileged --ip 192.168.0.200 registry.cn-shanghai.aliyuncs.com/suling/openwrt:rpi4 /sbin/init 其中：
--restart always参数表示容器退出时始终重启，使服务尽量保持始终可用；
--name openwrt参数定义了容器的名称；
-d参数定义使容器运行在 Daemon 模式(后台运行)；
--network macnet参数定义将容器加入 maxnet网络；
--privileged参数定义容器运行在特权模式下；
--ip 192.168.0.200指定容器的ip
registry.cn-shanghai.aliyuncs.com/suling/openwrt:latest为 Docker 镜像名，因容器托管在阿里云 Docker 镜像仓库内，所以在镜像名中含有阿里云仓库信息；
/sbin/init定义容器启动后执行的命令。
启动容器后，我们可以使用 docker ps -a命令查看当前运行的容器：
docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 5cd19f4cd735 registry.cn-shanghai.aliyuncs.com/suling/openwrt:rpi4 &#34;/sbin/init&#34; 20 hours ago Up 7 hours openwrt 5. 进入容器修改ip,网关和dns docker exec -it openwrt ash 执行此命令后我们便进入 OpenWrt 的命令行界面，首先，我们需要编辑 OpenWrt 的网络配置文件：
vim /etc/config/network 我们需要更改 Lan 口设置：
config interface &#39;lan&#39; option ifname &#39;eth0&#39; option proto &#39;static&#39; option netmask &#39;255.255.255.0&#39; option ip6assign &#39;60&#39; option ipaddr &#39;192.168.0.200&#39; option gateway &#39;192.168.0.1&#39; option dns &#39;192.168.0.1&#39; 6. 保存后重启网络 /etc/init.d/network restart 按下Ctrl + D可以退出openwrt的终端
7. 进入luci 控制面板 在浏览器中输入第 5 步option ipaddr项目中的 IP 进入 Luci 控制面板，若option ipaddr的参数为 192.168.0.200，则可以在浏览器输入 http://192.168.0.200进入控制面板。
用户名：root
密码：password
8. 配置防火墙 在网络-防火墙-自定义规则添加以下命令后重启防火墙
iptables -t nat -I POSTROUTING -o eth0 -j MASQUERADE 9. 关闭dhcp服务 在网络-接口处删除多于的网络，只保留LAN口，点击LAN口的修改
来到最下面的基本设置，勾上忽略此接口，然后保存应用即可
10. 将网关指向openwrt 来到路由器的后台管理，将路由器的网关指向openwrt的ip地址即可
参考： https://mlapp.cn/376.html ]]></content></entry><entry><title>初次安装Git的配置</title><url>/posts/git/%E5%88%9D%E6%AC%A1%E5%AE%89%E8%A3%85git%E7%9A%84%E9%85%8D%E7%BD%AE/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[初次运行 Git 前的配置 Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：
/etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果在执行 git config 时带上 --system 选项，那么它就会读写该文件中的配置变量。 （由于它是系统配置文件，因此你需要管理员或超级用户权限来修改它。） ~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 你可以传递 --global 选项让 Git 读写此文件，这会对你系统上 所有 的仓库生效。 当前使用仓库的 Git 目录中的 config 文件（即 .git/config）：针对该仓库。 你可以传递 --local 选项让 Git 强制读写此文件，虽然默认情况下用的就是它。。 （当然，你需要进入某个 Git 仓库中才能让该选项生效。） 每一个级别会覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。
在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\Users\$USER ）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。 如果你在 Windows 上使用 Git 2.x 以后的版本，那么还有一个系统级的配置文件，Windows XP 上在 C:\Documents and Settings\All Users\Application Data\Git\config ，Windows Vista 及更新的版本在 C:\ProgramData\Git\config 。此文件只能以管理员权限通过 git config -f &lt;file&gt; 来修改。
你可以通过以下命令查看所有的配置以及它们所在的文件：
$ git config --list --show-origin 用户信息 安装完 Git 之后，要做的第一件事就是设置你的用户名和邮件地址。 这一点很重要，因为每一个 Git 提交都会使用这些信息，它们会写入到你的每一次提交中，不可更改：
$ git config --global user.name &#34;John Doe&#34; $ git config --global user.email johndoe@example.com 再次强调，如果使用了 --global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。 当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 --global 选项的命令来配置。
检查配置信息 如果想要检查你的配置，可以使用 git config --list 命令来列出所有 Git 当时能找到的配置。
$ git config --list user.name=John Doe user.email=johndoe@example.com color.status=auto color.branch=auto color.interactive=auto color.diff=auto ... 你可能会看到重复的变量名，因为 Git 会从不同的文件中读取同一个配置（例如：/etc/gitconfig 与 ~/.gitconfig）。 这种情况下，Git 会使用它找到的每一个变量的最后一个配置。
你可以通过输入 git config &lt;key&gt;： 来检查 Git 的某一项配置
$ git config user.name John Doe 生成 SSH 公钥 许多 Git 服务器都使用 SSH 公钥进行认证。 为了向 Git 服务器提供 SSH 公钥，如果某系统用户尚未拥有密钥，必须事先为其生成一份。 这个过程在所有操作系统上都是相似的。 首先，你需要确认自己是否已经拥有密钥。 默认情况下，用户的 SSH 密钥存储在其 ~/.ssh 目录下。 进入该目录并列出其中内容，你便可以快速确认自己是否已拥有密钥：
$ cd ~/.ssh $ ls authorized_keys2 id_dsa known_hosts config id_dsa.pub 我们需要寻找一对以 id_dsa 或 id_rsa 命名的文件，其中一个带有 .pub 扩展名。 .pub 文件是你的公钥，另一个则是与之对应的私钥。 如果找不到这样的文件（或者根本没有 .ssh 目录），你可以通过运行 ssh-keygen 程序来创建它们。 在 Linux/macOS 系统中，ssh-keygen 随 SSH 软件包提供；在 Windows 上，该程序包含于 MSysGit 软件包中。
$ ssh-keygen -o Generating public/private rsa key pair. Enter file in which to save the key (/home/schacon/.ssh/id_rsa): Created directory &#39;/home/schacon/.ssh&#39;. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/schacon/.ssh/id_rsa. Your public key has been saved in /home/schacon/.ssh/id_rsa.pub. The key fingerprint is: d0:82:24:8e:d7:f1:bb:9b:33:53:96:93:49:da:9b:e3 schacon@mylaptop.local 首先 ssh-keygen 会确认密钥的存储位置（默认是 .ssh/id_rsa），然后它会要求你输入两次密钥口令。 如果你不想在使用密钥时输入口令，将其留空即可。 然而，如果你使用了密码，那么请确保添加了 -o 选项，它会以比默认格式更能抗暴力破解的格式保存私钥。 你也可以用 ssh-agent 工具来避免每次都要输入密码。
现在，进行了上述操作的用户需要将各自的公钥发送给任意一个 Git 服务器管理员 （假设服务器正在使用基于公钥的 SSH 验证设置）。 他们所要做的就是复制各自的 .pub 文件内容，并将其通过邮件发送。 公钥看起来是这样的：
$ cat ~/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSU GPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3 Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XA t3FaoJoAsncM1Q9x5+3V0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/En mZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbx NrRFi9wrf+M7Q== schacon@mylaptop.local 将公钥上传到指定服务器 # 上传公钥到服务器 $ ssh-copy-id user@host # 文件会自动上传为服务器特定文件 ～/.ssh/authorized_keys 要了解更多关于Git的知识请访问官方文档
官方文档入口 ]]></content></entry></search>