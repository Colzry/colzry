<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>BT下载服务搭建</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/bt%E4%B8%8B%E8%BD%BD%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag></tags><content type="html"><![CDATA[github项目地址： https://github.com/P3TERX/aria2.sh 0. 新加入Docker安装 文档地址： https://p3terx.com/archives/docker-aria2-pro.html 0.1 安装aria2 自行替换RPC_SECRET后启动
docker run -d \ --name aria2-pro \ --restart always \ --log-opt max-size=1m \ --network host \ -e PUID=$UID \ -e PGID=$GID \ -e RPC_SECRET=czyadmin \ -e RPC_PORT=6800 \ -e LISTEN_PORT=6888 \ -v $PWD/aria2-config:/config \ -v $PWD/aria2-downloads:/downloads \ p3terx/aria2-pro 0.2 安装WEBUI docker run -d \ --name ariang \ --restart always \ --log-opt max-size=1m \ -p 6880:6880 \ p3terx/ariang 0.3 安装filebrowser 默认用户名和密码：admin
docker run -d \ --name filebrowser \ --restart always \ -v $PWD/aria2-downloads:/srv \ -v $PWD/filebrowser/filebrowser.db:/database/filebrowser.db \ -v $PWD/filebrowser/settings.json:/config/settings.json \ -e PUID=$(id -u) \ -e PGID=$(id -g) \ -p 8080:80 \ filebrowser/filebrowser 普通安装 1.0 安装并配置aria2 wget https://picture-czy.oss-cn-beijing.aliyuncs.com/shareFile/aria2.sh -O /root/aria2.sh &amp;&amp; bash /root/aria2.sh 2.0 设置tracker自动更新 wget https://picture-czy.oss-cn-beijing.aliyuncs.com/shareFile/tracker.sh -O /root/tracker.sh &amp;&amp; bash /root/tracker.sh crontab -e # 每周日凌晨5点 0 5 * * 0 /bin/bash /root/tracker.sh 2&gt;&amp;1 3.0 安装AriaNg wget https://picture-czy.oss-cn-beijing.aliyuncs.com/shareFile/AriaNg-1.2.3-AllInOne.zip -O /root/AriaNg.zip apt install nginx -y unzip /root/AriaNg.zip -d /var/www/AriaNg vim /etc/nginx/sites-enabled/AriaNg server { listen 80; #监听端口 server_name 127.0.0.1; #主机ip index index.html index.htm; location / { root /var/www/AriaNg; #站点目录 } } # 检查语法错误 nginx -t # 重启服务 systemctl restart nginx.service 填入RPC密钥 4.0 安装filebrowser wget https://picture-czy.oss-cn-beijing.aliyuncs.com/shareFile/linux-amd64-filebrowser.tar.gz tar -zxvf linux-amd64-filebrowser.tar.gz -C /usr/local/bin/ #先创建一个目录用来存放数据库和配置文件 mkdir /etc/filebrowser/ source ~/.bashrc ############# 国外新方法 ################## curl -fsSL https://raw.githubusercontent.com/filebrowser/get/master/get.sh | bash #创建配置数据库 filebrowser -d /etc/filebrowser/filebrowser.db config init #设置监听地址 filebrowser -d /etc/filebrowser/filebrowser.db config set --address 0.0.0.0 #设置监听端口 filebrowser -d /etc/filebrowser/filebrowser.db config set --port 8080 #设置语言环境 filebrowser -d /etc/filebrowser/filebrowser.db config set --locale zh-cn #设置日志位置 filebrowser -d /etc/filebrowser/filebrowser.db config set --log /var/log/filebrowser.log #添加一个用户 filebrowser -d /etc/filebrowser/filebrowser.db users add admin password --perm.admin #设置网盘根目录 filebrowser -d /etc/filebrowser/filebrowser.db config set --root /mnt/hhd01/aria2 # 启动 filebrowser -d /etc/filebrowser/filebrowser.db Username: admin Password: password 后台挂起 nohup filebrowser -d /etc/filebrowser/filebrowser.db &amp; 或者设置守护进程
vim /lib/systemd/system/filebrowser.service [Unit] Description=File Browser After=network.target [Service] Type=simple ExecStart=/usr/local/bin/filebrowser -d /etc/filebrowser/filebrowser.db Restart=on-abnormal RestartSec=5s KillMode=mixed [Install] WantedBy=multi-user.target systemctl daemon-reload systemctl start filebrowser.service systemctl status filebrowser.service systemctl enable filebrowser.service ]]></content></entry><entry><title>byobu的使用</title><url>/posts/linux%E6%93%8D%E4%BD%9C/byobu%E7%9A%84%E4%BD%BF%E7%94%A8/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html">1.1 安装 sudo apt-get install byobu 命令安装byobu
1.2 登录启动 byobu-enable 表示Byobu窗口管理器将在每次文本登录时自动启动
byobu-disable 表示Byobu窗口管理器将不再在登录时自动启动
1.3 色彩提示 byobu-enable-prompt 启动Byobu的彩色提示
byobu-disable-prompt 禁用Byobu的彩色提示
2.Byobu 使用 更多相关操作可以按 F9 选项查看帮助指南 2.1 使用会话 一个会话仅仅是byobu的运行实例。会话由一组窗口组成，这些窗口基本上是shell会话，默认开启byobu只开0这一个窗口
(1) 创建窗口 F2 创建新的窗口
(2) 切换窗口 F3 回到先前窗口
F4 跳到下一个窗口
(3) 重命名窗口 F8 重新命名一个窗口
(4) 窗口操作 F5 重新加载文件
F6 释放该次对话
F7 进入 复制/回滚模式
F9 配置菜单
Ctrl + D关闭当前窗口
2.2 使用窗格 Byobu提供了将窗口分成多个窗格的功能，包括水平和垂直分割。这些允许您在同一窗口中进行多任务，而不是跨多个窗口。
(1) 创建窗格 SHIFT + F2 创建一个水平窗格
CTRL + F2 创造一个垂直窗格
(2) 切换窗格 以下三个快捷键都可以让窗格切换:
SHIFT + LEFT/RIGHT/UP/DOWN
SHIFT + F3/F4
CTRL + F3/F4
(3) 设置窗格 SHIFT + ALT + LEFT/RIGHT/UP/DOWN 调整当前窗格的大小
SHIFT + F11 切换窗格以暂时填充整个窗口
ALT + F11 永久地将窗格拆分为自己的新窗口
2.3 配置通知栏 ①.按F9进入Byobu配置菜单。
②.导航到 切换状态通知选项，然后按 ENTER
③.选择要启用或禁用的状态通知。(启用状态通知后，它们将显示在底部状态栏中，与窗口指示器一起显示。)
④.选择要启用的状态通知后，选择 应用，按 F5 才能刷新状态栏
有很多不同的通知可供选择，一些常用的通知是：
date 显示当前系统日期。
disk 显示当前磁盘空间使用情况。
hostname 显示当前系统主机名。
ip_address 显示当前系统的IP地址。
load_average 显示当前系统负载平均值。
memory 显示当前的内存使用情况。
network 显示当前的网络使用情况，发送和接收。
reboot_required 显示需要重新启动系统时的指示灯。
release 显示当前的分发版本（例如14.04）。
time 显示当前系统时间。
updates_available 在有可用更新时显示指示符。
uptime 显示当前系统正常运行时间。
whoami 显示当前登录的用户。</content></entry><entry><title>Centos8 KVM 虚拟化</title><url>/posts/kvm%E8%99%9A%E6%8B%9F%E5%8C%96/centos8-kvm-%E8%99%9A%E6%8B%9F%E5%8C%96/</url><categories><category>KVM</category></categories><tags><tag>KVM</tag><tag>Linux</tag></tags><content type="html"><![CDATA[1. 安装Centos8 1.1 下载 Centos8 镜像 下载地址： http://isoredirect.centos.org/centos/8/isos/x86_64/ 1.2 安装Centos8 1.2.1 回车
1.2.2 选择中文
1.2.3 从右到左依次点击配置，先选择安装目的地
1.2.4 配置网络
这时要等待镜像源的选择，不要认为卡了
1.2.5 来到软件选择，选择安装虚拟化主机
1.2.6 设置root密码
1.2.7 点击开始安装，并等待15分钟左右
2. 在 Centos8 上安装KVM 2.1 先检查硬件是否支持虚拟化 grep -e &#39;vmx&#39; /proc/cpuinfo #Intel CPU grep -e &#39;svm&#39; /proc/cpuinfo #AMD CPU 出现标有红色字样的字，则代表支持
2.2 确认KVM模块是否已加载到内核中 lsmod | grep kvm 2.3 安装cockpit Web控制台 cockpit是预先安装的，并在新安装的CentOS 8和RHEL 8系统上启用。 如果您没有安装它，使用下面的dnf命令进行安装。其中cockpit-machines扩展是用来管理基于Libvirt的虚拟机的
使用阿里云镜像，速度更快
$ mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup $ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo $ yum makecache $ dnf install cockpit cockpit-machines 启动cockpit socket服务
$ systemctl start cockpit.socket $ systemctl enable cockpit.socket $ systemctl status cockpit.socket 配置防火墙
$ firewall-cmd --add-service=cockpit --permanent $ firewall-cmd --reload 2.4 打开控制台 使用浏览器打开 https://服务器IP:9090/
用户名和密码和系统的一样
2.5 添加网桥 2.5.1 点击左侧控制面板中 -网络-
2.5.2 点击 -添加网桥- 选择第一个网卡后点击应用
2.6 添加虚拟机 2.6.1 点击左侧控制面板中的 -虚拟机-
2.6.2 点击 -创建虚拟机-
win7镜像我已经上传到/opt/目录下，也可以选择下载一个OS，但需要时间等待
2.6.3 点击创建好的虚拟机，编辑详细信息
这里我编辑了CPU的数量，自行发挥，之后点击安装
2.7 开启win7远程桌面 点击选择用户可以查看和添加远程连接的用户
]]></content></entry><entry><title>Cloudflare WARP解锁NetFlix</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/cloudflare-warp%E8%A7%A3%E9%94%81netflix/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag></tags><content type="html"><![CDATA[1. 检测是否解锁 #项目地址：https://github.com/sjlleo/netflix-verify #下载检测解锁程序 wget -O nf https://github.com/sjlleo/netflix-verify/releases/download/v3.1.0/nf_linux_amd64 &amp;&amp; chmod +x nf #执行 ./nf #通过代理执行 ./nf -proxy socks5://127.0.0.1:40000 2. WARP安装 github地址： https://github.com/P3TERX/warp.sh 使用文档地址： https://p3terx.com/archives/cloudflare-warp-configuration-script.html 使用以下命令一把梭后将自动安装 WARP 官方客户端并开启 SOCKS5 代理端口 (127.0.0.1:40000)：
# 自动配置 WARP 官方客户端 SOCKS5 代理 bash &lt;(curl -fsSL git.io/warp.sh) s5 执行以下命令显示功能菜单和贴心的状态显示：
# Cloudflare WARP 一键配置脚本 功能菜单 bash &lt;(curl -fsSL git.io/warp.sh) menu 3. 通过WARP代理再次检测是否解锁 ./nf -proxy socks5://127.0.0.1:40000 #查询代理后的IP地址： curl ifconfig.me --proxy socks5://127.0.0.1:40000 4. 配置Xray分流 替换掉文本域中的内容后，重启面板 { &#34;api&#34;: { &#34;services&#34;: [ &#34;HandlerService&#34;, &#34;LoggerService&#34;, &#34;StatsService&#34; ], &#34;tag&#34;: &#34;api&#34; }, &#34;inbounds&#34;: [ { &#34;listen&#34;: &#34;127.0.0.1&#34;, &#34;port&#34;: 62789, &#34;protocol&#34;: &#34;dokodemo-door&#34;, &#34;settings&#34;: { &#34;address&#34;: &#34;127.0.0.1&#34; }, &#34;tag&#34;: &#34;api&#34; } ], &#34;outbounds&#34;: [ { &#34;protocol&#34;: &#34;freedom&#34;, &#34;settings&#34;: {} }, { &#34;tag&#34;: &#34;netflix_proxy&#34;, &#34;protocol&#34;: &#34;socks&#34;, &#34;settings&#34;: { &#34;servers&#34;: [ { &#34;address&#34;: &#34;127.0.0.1&#34;, &#34;port&#34;: 40000 } ] } }, { &#34;protocol&#34;: &#34;blackhole&#34;, &#34;settings&#34;: {}, &#34;tag&#34;: &#34;blocked&#34; } ], &#34;policy&#34;: { &#34;system&#34;: { &#34;statsInboundDownlink&#34;: true, &#34;statsInboundUplink&#34;: true } }, &#34;routing&#34;: { &#34;rules&#34;: [ { &#34;type&#34;: &#34;field&#34;, &#34;outboundTag&#34;: &#34;netflix_proxy&#34;, &#34;domain&#34;: [ &#34;geosite:netflix&#34;, &#34;geosite:disney&#34;, &#34;geosite:category-porn&#34; ] }, { &#34;inboundTag&#34;: [ &#34;api&#34; ], &#34;outboundTag&#34;: &#34;api&#34;, &#34;type&#34;: &#34;field&#34; }, { &#34;ip&#34;: [ &#34;geoip:private&#34; ], &#34;outboundTag&#34;: &#34;blocked&#34;, &#34;type&#34;: &#34;field&#34; }, { &#34;outboundTag&#34;: &#34;blocked&#34;, &#34;protocol&#34;: [ &#34;bittorrent&#34; ], &#34;type&#34;: &#34;field&#34; } ] }, &#34;stats&#34;: {} } 重启面板后不通过代理再次检测
./nf 原来的xray配置
{ &#34;api&#34;: { &#34;services&#34;: [ &#34;HandlerService&#34;, &#34;LoggerService&#34;, &#34;StatsService&#34; ], &#34;tag&#34;: &#34;api&#34; }, &#34;inbounds&#34;: [ { &#34;listen&#34;: &#34;127.0.0.1&#34;, &#34;port&#34;: 62789, &#34;protocol&#34;: &#34;dokodemo-door&#34;, &#34;settings&#34;: { &#34;address&#34;: &#34;127.0.0.1&#34; }, &#34;tag&#34;: &#34;api&#34; } ], &#34;outbounds&#34;: [ { &#34;protocol&#34;: &#34;freedom&#34;, &#34;settings&#34;: {} }, { &#34;protocol&#34;: &#34;blackhole&#34;, &#34;settings&#34;: {}, &#34;tag&#34;: &#34;blocked&#34; } ], &#34;policy&#34;: { &#34;system&#34;: { &#34;statsInboundDownlink&#34;: true, &#34;statsInboundUplink&#34;: true } }, &#34;routing&#34;: { &#34;rules&#34;: [ { &#34;inboundTag&#34;: [ &#34;api&#34; ], &#34;outboundTag&#34;: &#34;api&#34;, &#34;type&#34;: &#34;field&#34; }, { &#34;ip&#34;: [ &#34;geoip:private&#34; ], &#34;outboundTag&#34;: &#34;blocked&#34;, &#34;type&#34;: &#34;field&#34; }, { &#34;outboundTag&#34;: &#34;blocked&#34;, &#34;protocol&#34;: [ &#34;bittorrent&#34; ], &#34;type&#34;: &#34;field&#34; } ] }, &#34;stats&#34;: {} } ]]></content></entry><entry><title>Debian Locale问题</title><url>/posts/linux%E6%93%8D%E4%BD%9C/debian-locale%E9%97%AE%E9%A2%98/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>疑难杂症</tag></tags><content type="html">Debian locale问题 问题 root@debian:~# locale -a locale: Cannot set LC_CTYPE to default locale: No such file or directory locale: Cannot set LC_MESSAGES to default locale: No such file or directory locale: Cannot set LC_COLLATE to default locale: No such file or directory C C.UTF-8 POSIX zh_CN.utf8 -bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8) 解决办法 sudo localedef -i en_US -f UTF-8 en_US.UTF-8</content></entry><entry><title>Debian编译网卡驱动(I219-V)</title><url>/posts/linux%E6%93%8D%E4%BD%9C/debian%E7%BC%96%E8%AF%91%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8i219-v/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>疑难杂症</tag></tags><content type="html">换源 bash &amp;lt;(curl -sSL https://gitee.com/SuperManito/LinuxMirrors/raw/main/ChangeMirrors.sh) 1. 下载网卡驱动 下载e1000e网卡驱动，下载地址 https://downloadcenter.intel.com/zh-cn/download/15817?_ga=1.159975677.114505945.1484457019 2. 配置编译环境 # 查看内核版本 uname -r # 去华农镜像下载对应的linux-headers curl -O https://mirrors.scau.edu.cn/proxmox/debian/dists/bullseye/pve-no-subscription/binary-amd64/pve-headers-5.15.30-2-pve_5.15.30-3_amd64.deb # 安装linux-headers dpkg -i pve-headers-5.15.30-2-pve_5.15.30-3_amd64.deb # 安装编译工具链 sudo apt install build-essential build-essential 包含了以下编译环境
$ apt-cache depends build-essential build-essential |Depends: libc6-dev Depends: &amp;lt;libc-dev&amp;gt; libc6-dev Depends: gcc Depends: g++ Depends: make make-guile Depends: dpkg-de RedHat 安装 yum install make automake gcc gcc-c++ kernel-devel 3. 开始编译 cd e1000e-3.8.5/src make install 若编译报错
common.mk:82: *** Kernel header files not in any of the expected locations. common.mk:83: *** Install the appropriate kernel development package, e.g. common.mk:84: *** kernel-devel, for building kernel modules and try again. Stop. 安装内核源码
sudo apt-get install linux-headers-$(uname -r) 若上面的安装失败，安装通用内核替代
sudo apt-get install linux-headers-generic 创建软连接
ln -s /usr/src/linux-headers-5.4.0-65-generic /usr/src/linux</content></entry><entry><title>entity、bo、vo、po、dto、pojo如何理解和区分</title><url>/posts/java/entitybovopodtopojo%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%92%8C%E5%8C%BA%E5%88%86/</url><categories><category>Java</category></categories><tags><tag>Java</tag></tags><content type="html">Entity 最常用实体类，基本和数据表一一对应，一个实体一张表。
Bo(business object) 代表业务对象的意思，Bo就是把业务逻辑封装为一个对象（注意是逻辑，业务逻辑），这个对象可以包括一个或多个其它的对象。通过调用Dao方法，结合Po或Vo进行业务操作。
形象描述为一个对象的形为和动作，当然也有涉及到基它对象的一些形为和动作。比如处理一个人的业务逻辑，该人会睡觉，吃饭，工作，上班等等行为，还有可能和别人发关系的行为，处理这样的业务逻辑时，我们就可以针对BO去处理。
再比如投保人是一个Po，被保险人是一个Po，险种信息也是一个Po等等，他们组合起来就是一张保单的Bo。
Vo(value object) 代表值对象的意思，通常用于业务层之间的数据传递，由new创建，由GC回收。
主要体现在视图的对象，对于一个WEB页面将整个页面的属性封装成一个对象，然后用一个VO对象在控制层与视图层进行传输交换。
Po(persistant object) 代表持久层对象的意思，对应数据库中表的字段，数据库表中的记录在java对象中的显示状态，最形象的理解就是一个PO就是数据库中的一条记录。
好处是可以把一条记录作为一个对象处理，可以方便的转为其它对象。Vo和Po，都是属性加上属性的get和set方法；表面看没什么不同，但代表的含义是完全不同的。
Dto(data transfer object) 代表数据传输对象的意思
是一种设计模式之间传输数据的软件应用系统，数据传输目标往往是数据访问对象从数据库中检索数据
数据传输对象与数据交互对象或数据访问对象之间的差异是一个以不具任何行为除了存储和检索的数据（访问和存取器）
简而言之，就是接口之间传递的数据封装
表里面有十几个字段：id，name，gender（M/F)，age……
页面需要展示三个字段：name，gender(男/女)，age
DTO由此产生，一是能提高数据传输的速度(减少了传输字段)，二能隐藏后端表结构
Pojo(plian ordinary java object) 代表简单无规则java对象
纯的传统意义的java对象，最基本的Java Bean只有属性加上属性的get和set方法
可以额转化为PO、DTO、VO；比如POJO在传输过程中就是DTO
Dao(data access object) 代表数据访问对象的意思，是sun的一个标准j2ee设计模式的接口之一，负责持久层的操作 。这个基本都了解，Dao和上面几个O区别最大，基本没有互相转化的可能性和必要，主要用来封装对数据的访问，注意，是对数据的访问，不是对数据库的访问。
Controller 代表控制层，主要是Action/Servlet等构成（Spring MVC则是通过@Controller标签使用）此层业务层与视图层打交道的中间层，负责传输VO对象和调用BO层的业务方法，负责视图层请求的数据处理后响应给视图层。
View 代表视图层的意思，主要是指由JSP、HTML等文件形成的显示层。
所以实际项目中，一般都是这样应用的：
控制层(controller-action)，业务层/服务层( bo-manager-service)，实体层(po-entity)，dao(dao)，视图对象(Vo-)，视图层(view-jsp/html)</content></entry><entry><title>FRP内网穿透</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/frpc%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>FRP</tag></tags><content type="html">1. 下载Frp wget https://gitpy.colzry.tk/github.com/fatedier/frp/releases/download/v0.48.0/frp_0.48.0_linux_amd64.tar.gz wget https://github.com/fatedier/frp/releases/download/v0.48.0/frp_0.48.0_linux_amd64.tar.gz 2. 服务端安装 2.1 解压文件 tar -zxvf frp_0.48.0_linux_amd64.tar.gz cd frp_0.48.0_linux_amd64/ cp frps /usr/local/bin/ 2.2 编写配置文件 mkdir /etc/frps vim /etc/frps/frps.ini [common] bind_port = 7000 token = czyadmin 2.3 启动 sudo vim /lib/systemd/system/frps.service [Unit] Description=Frp Server Service After=network.target [Service] Type=simple User=nobody Restart=on-failure RestartSec=5s ExecStart=/usr/local/bin/frps -c /etc/frps/frps.ini ExecReload=/usr/local/bin/frps reload -c /etc/frps/frps.ini LimitNOFILE=1048576 [Install] WantedBy=multi-user.target sudo systemctl daemon-reload sudo systemctl start frps.service sudo systemctl enable --now frps.service 3. 客户端安装 3.1 解压文件 tar -zxvf frp_0.44.0_linux_amd64.tar.gz cd frp_0.44.0_linux_amd64/ cp frpc /usr/local/bin/ frpc.ini 配置文件详解
[common] #远程frp服务器地址，可ip可域名 server_addr = frp02.wefinger.club #远程frp服务器通信端口 server_port = 7000 #特权密钥 token = 12345678 #http穿透 [demo-http] #穿透类型 type = http #本地监听ip local_ip = 127.0.0.1 #本地监听端口，欲穿透转发端口。 local_port = 8080 #自定义穿透域名，该域名需要解析至frp服务器。 custom_domains = testhttp.frp02.wefinger.club #https穿透 [demo-https] type = https local_ip = 127.0.0.1 local_port = 8088 custom_domains = testhttps.frp02.wefinger.club #tcp穿透，例如ssh、ftp服务 [demo-tcp] type = tcp #欲穿透地址，本地必须可访问。 local_ip = 127.0.0.1 #可批量绑定，使用`,`分隔，或者使用`-`定义端口段。 local_port = 22 #绑定远程端口，可批量绑定，使用`,`分隔，或者使用`-`定义端口段。 remote_port = 20022 #udp穿透,例如转发dns服务 [demo-udp] type = udp local_ip = 8.8.8.8 local_port = 53 remote_port = 20053 3.2 启动 配置文件根据各网站的粘贴过来就行
3.2.1 直接启动 启动
./frpc -c ./frpc.ini &amp;amp; 3.2.2 后台启动 配置后台自动启动
sudo vim /lib/systemd/system/frpc.service [Unit] Description=Frp Client Service After=network.target [Service] Type=simple User=nobody Restart=on-failure RestartSec=5s ExecStart=/usr/local/bin/frpc -c /etc/frpc/frpc.ini ExecReload=/usr/local/bin/frpc reload -c /etc/frpc/frpc.ini LimitNOFILE=1048576 [Install] WantedBy=multi-user.target sudo systemctl daemon-reload sudo systemctl start frpc.service sudo systemctl enable frpc.service 3.3 配置多个隧道 创建配置文件目录
mkdir -p /etc/frpc 打开配置文件的目录，编写对应的配置文件
cd /etc/frpc vim 102SSH.ini 配置示例如下
[common] server_addr = cn-gydx-bgp-1.openfrp.top server_port = 8120 tls_enable = true tcp_mux = true protocol = tcp user = 8022c3fe7ba2d9d8c953f899b86da17a tls_enable = true token = mnE3A8hIWapwShje dns_server = 114.114.114.114 [102UH] privilege_mode = true type = tcp local_ip = 192.168.5.102 local_port = 1022 remote_port = 60856 use_encryption = false use_compression = false 配置System服务
vim /lib/systemd/system/frpc@.service [Unit] Description=Frp Client Service After=network.target [Service] Type=simple User=nobody Restart=on-failure RestartSec=5s ExecStart=/usr/local/bin/frpc -c /etc/frpc/%i.ini ExecReload=/usr/local/bin/frpc reload -c /etc/frpc/%i.ini LimitNOFILE=1048576 [Install] WantedBy=multi-user.target 根据配置文件名称来启动服务
systemctl daemon-reload systemctl start frpc@102SSH systemctl status frpc@102SSH systemctl enable frpc@102SSH 如果您忘记了之前开启过哪些隧道，使用下面的命令可以列出当前运行中的隧道
systemctl list-units frpc@* 如果您忘记了之前设置过的自启隧道，可以使用下面的命令列出
systemctl list-units --all frpc@*</content></entry><entry><title>GitHub代理加速</title><url>/posts/git/github%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[项目地址： https://github.com/hunshcn/gh-proxy 使用cloudflare免费的代理加速 网址： https://workers.cloudflare.com 先登录或注册 将下面的放入左侧的方框中(不需要任何的改动)
&#39;use strict&#39; /** * static files (404.html, sw.js, conf.js) */ const ASSET_URL = &#39;https://hunshcn.github.io/gh-proxy/&#39; // 前缀，如果自定义路由为example.com/gh/*，将PREFIX改为 &#39;/gh/&#39;，注意，少一个杠都会错！ const PREFIX = &#39;/&#39; // 分支文件使用jsDelivr镜像的开关，0为关闭，默认关闭 const Config = { jsdelivr: 0 } const whiteList = [] // 白名单，路径里面有包含字符的才会通过，e.g. [&#39;/username/&#39;] /** @type {RequestInit} */ const PREFLIGHT_INIT = { status: 204, headers: new Headers({ &#39;access-control-allow-origin&#39;: &#39;*&#39;, &#39;access-control-allow-methods&#39;: &#39;GET,POST,PUT,PATCH,TRACE,DELETE,HEAD,OPTIONS&#39;, &#39;access-control-max-age&#39;: &#39;1728000&#39;, }), } const exp1 = /^(?:https?:\/\/)?github\.com\/.+?\/.+?\/(?:releases|archive)\/.*$/i const exp2 = /^(?:https?:\/\/)?github\.com\/.+?\/.+?\/(?:blob|raw)\/.*$/i const exp3 = /^(?:https?:\/\/)?github\.com\/.+?\/.+?\/(?:info|git-).*$/i const exp4 = /^(?:https?:\/\/)?raw\.(?:githubusercontent|github)\.com\/.+?\/.+?\/.+?\/.+$/i const exp5 = /^(?:https?:\/\/)?gist\.(?:githubusercontent|github)\.com\/.+?\/.+?\/.+$/i const exp6 = /^(?:https?:\/\/)?github\.com\/.+?\/.+?\/tags.*$/i /** * @param {any} body * @param {number} status * @param {Object&lt;string, string&gt;} headers */ function makeRes(body, status = 200, headers = {}) { headers[&#39;access-control-allow-origin&#39;] = &#39;*&#39; return new Response(body, {status, headers}) } /** * @param {string} urlStr */ function newUrl(urlStr) { try { return new URL(urlStr) } catch (err) { return null } } addEventListener(&#39;fetch&#39;, e =&gt; { const ret = fetchHandler(e) .catch(err =&gt; makeRes(&#39;cfworker error:\n&#39; + err.stack, 502)) e.respondWith(ret) }) function checkUrl(u) { for (let i of [exp1, exp2, exp3, exp4, exp5, exp6]) { if (u.search(i) === 0) { return true } } return false } /** * @param {FetchEvent} e */ async function fetchHandler(e) { const req = e.request const urlStr = req.url const urlObj = new URL(urlStr) let path = urlObj.searchParams.get(&#39;q&#39;) if (path) { return Response.redirect(&#39;https://&#39; + urlObj.host + PREFIX + path, 301) } // cfworker 会把路径中的 `//` 合并成 `/` path = urlObj.href.substr(urlObj.origin.length + PREFIX.length).replace(/^https?:\/+/, &#39;https://&#39;) if (path.search(exp1) === 0 || path.search(exp5) === 0 || path.search(exp6) === 0 || path.search(exp3) === 0 || path.search(exp4) === 0) { return httpHandler(req, path) } else if (path.search(exp2) === 0) { if (Config.jsdelivr) { const newUrl = path.replace(&#39;/blob/&#39;, &#39;@&#39;).replace(/^(?:https?:\/\/)?github\.com/, &#39;https://cdn.jsdelivr.net/gh&#39;) return Response.redirect(newUrl, 302) } else { path = path.replace(&#39;/blob/&#39;, &#39;/raw/&#39;) return httpHandler(req, path) } } else if (path.search(exp4) === 0) { const newUrl = path.replace(/(?&lt;=com\/.+?\/.+?)\/(.+?\/)/, &#39;@$1&#39;).replace(/^(?:https?:\/\/)?raw\.(?:githubusercontent|github)\.com/, &#39;https://cdn.jsdelivr.net/gh&#39;) return Response.redirect(newUrl, 302) } else { return fetch(ASSET_URL + path) } } /** * @param {Request} req * @param {string} pathname */ function httpHandler(req, pathname) { const reqHdrRaw = req.headers // preflight if (req.method === &#39;OPTIONS&#39; &amp;&amp; reqHdrRaw.has(&#39;access-control-request-headers&#39;) ) { return new Response(null, PREFLIGHT_INIT) } const reqHdrNew = new Headers(reqHdrRaw) let urlStr = pathname let flag = !Boolean(whiteList.length) for (let i of whiteList) { if (urlStr.includes(i)) { flag = true break } } if (!flag) { return new Response(&#34;blocked&#34;, {status: 403}) } if (urlStr.startsWith(&#39;github&#39;)) { urlStr = &#39;https://&#39; + urlStr } const urlObj = newUrl(urlStr) /** @type {RequestInit} */ const reqInit = { method: req.method, headers: reqHdrNew, redirect: &#39;manual&#39;, body: req.body } return proxy(urlObj, reqInit) } /** * * @param {URL} urlObj * @param {RequestInit} reqInit */ async function proxy(urlObj, reqInit) { const res = await fetch(urlObj.href, reqInit) const resHdrOld = res.headers const resHdrNew = new Headers(resHdrOld) const status = res.status if (resHdrNew.has(&#39;location&#39;)) { let _location = resHdrNew.get(&#39;location&#39;) if (checkUrl(_location)) resHdrNew.set(&#39;location&#39;, PREFIX + _location) else { reqInit.redirect = &#39;follow&#39; return proxy(newUrl(_location), reqInit) } } resHdrNew.set(&#39;access-control-expose-headers&#39;, &#39;*&#39;) resHdrNew.set(&#39;access-control-allow-origin&#39;, &#39;*&#39;) resHdrNew.delete(&#39;content-security-policy&#39;) resHdrNew.delete(&#39;content-security-policy-report-only&#39;) resHdrNew.delete(&#39;clear-site-data&#39;) return new Response(res.body, { status, headers: resHdrNew, }) } 点击保存并部署后可以点击发送测试是否成功 目前国内无法访问 *.workers.dev，需要cloudflare托管的域名反代进行CNAME解析 之后点击Worker路由-&gt; 添加路由 按照下图的形式编写进行保存即可 之后就能通过自定义的域名进行访问
终端使用方法 例如下载 Releases 文件
# 原来的使用方法 wget https://github.com/fatedier/frp/releases/download/v0.44.0/frp_0.44.0_linux_amd64.tar.gz # 代理使用方法 wget https://gitpy.colzry.tk/https://github.com/fatedier/frp/releases/download/v0.44.0/frp_0.44.0_linux_amd64.tar.gz clone也是如此
]]></content></entry><entry><title>Git的基本使用</title><url>/posts/git/git%E5%9F%BA%E6%9C%AC%E7%9A%84%E4%BD%BF%E7%94%A8/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[1. 设置签名 git config --global user.name tom #设置用户名tom git config --global user.email xxx@qq.com #设置用户邮箱 2. 创建本地仓库 $ git init 3. 版本提交 3.1 状态查看 git status #查看工作区、暂存区状态 3.2 添加 git add fileName #指定文件 git add . #所有 说明：将工作区的文件添加到暂存区 3.3 提交 git commit -m &#39;commit message&#39; 说明：将暂存区内容提交到本地库 3.4 查看历史记录 git log git reflog #常用 git log --greph #图形显示,更直观 git log --pretty=oneline #漂亮一行显示 git log --oneline #简洁显示 说明：HEAD@{移动到当前版本需要多少步} 4. 分支操作 4.1 创建分支 git branch 分支名 4.2 查看分支 git branch git branch -v 4.3 切换分支 git checkout 分支名 git checkout -b 分支名 #创建分支并直接切换到该分支 4.4 重命名分支 在当前分支
git branch -m new_branch_name 不在当前分支
git branch -m old_name new_name 4.5 合并分支 **相当于把修改了的文件拉过来**
git rebase &lt;branch&gt; 将指定的分支合并到当前分支 git merge --no-ff xxx 注意：合并分支的时候要明确谁谁合并 我在a分支里面修改了。要合并到master，就先切换到master，然后合并b 4.6 删除分支 git branch -d 分支名 5. 使用远程仓库 5.1 创建远程库地址别名 git remote -v #查看远程地址别名 git remote add 别名 远程地址 git remote set-url 别名 远程地址 例子：git remote add origin https://xx 5.2 推送 **开发修改完把本地库的文件推送到远程仓库**** ****前提是提交到了本地库才可以推送**
git push 别名 分支名 git push -u 别名 分支名 #-u指定默认主机 git push -f # 强制推送 例子：git push origin master 5.3 克隆 **完整的把远程库克隆到本地**** **克隆下来后不要在主分支里面做开发** ****clone进行一次，从无到有的过程，更新用pull**
git clone 远程地址 例子：git clone https://xx 5.4 拉取 **本地存在clone下来的文件 就用pull更新**
pull = fetch + merge git fetch 别名 分支名 git merge 别名 分支名 git pull 别名 分支名 5.5 解决冲突 注意：解决冲突后的提交是不能带文件名的 如果不是基于远程库最新版做的修改不能推送，必须先pull下来安装冲突办法解决
# 查看所有分支 git reflog # 回退到上一个版本 git rest --hard HEAD^ # 回退到上上个版本 git rest --hard HEAD^^ # 回退到commit id为ba7914b的版本 git rest --hard ba7914b git pull origin/master # 合并之后修改冲突 git diff origin/master ]]></content></entry><entry><title>Git设置代理</title><url>/posts/git/git%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[# 以下使用http代理 git config --global http.proxy http://127.0.0.1:10809 git config --global https.proxy https://127.0.0.1:10809 # 以下使用socks5代理 git config --global http.proxy socks5://127.0.0.1:10808 git config --global https.proxy socks5://127.0.0.1:10808 # 取消代理 git config --global --unset http.proxy git config --global --unset https.proxy git config --global url.&#34;https://gitpy.colzry.tk/&#34;.insteadOf https:// git config --global --remove-section url.&#34;https://gitpy.colzry.tk/&#34; ]]></content></entry><entry><title>go mod的使用</title><url>/posts/golang/go-mod/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[常用命令
# 初始化模块 cd &lt;mod_name&gt; go mod init &lt;mod_name&gt; # 删除没用的依赖，下载位拉取的依赖 go mod tidy go mod使用 | 全网最详细 ]]></content></entry><entry><title>go workspace快速使用</title><url>/posts/golang/go-workspace/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html">常用命令
# 初始化工作区 go work init [dirnames] # 添加模块 go work use [dirnames] 官方博文：Go 1.18工作区模式最佳实践 Go 1.18 workspace 使用初体验_Seekload的博客-CSDN博客</content></entry><entry><title>Gogs服务搭建</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/gogs%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>Gogs</tag></tags><content type="html">Gogs服务搭建 1. 安装 wget https://github.com/gogs/gogs/releases/download/v0.13.0/gogs_0.13.0_linux_amd64.tar.gz # 网络不好可以使用下面的 wget https://picture-czy.oss-cn-beijing.aliyuncs.com/shareFile/gogs_0.13.0_linux_amd64.tar.gz tar -zxvf gogs_0.13.0_linux_amd64.tar.gz -C /usr/local # 修改目录拥有者，如无用户先添加 U:G chown -R gogs:gogs gogs/ 无用户的先添加用户，并为用户赋予gogs目录的权限
#创建用户组 groupadd gogs #创建用户家目录 mkdir -p /home/gogs #创建用户 useradd -g gogs -d /home/gogs -s /bin/bash gogs #用户家目录赋权755 4-&amp;gt;r 2-&amp;gt;w 1-&amp;gt;x chmod -R 755 /home/gogs #修改gogs目录拥有者 chown -R gogs:gogs /usr/local/gogs/ 2. 添加守护进程 在安装目录的scripts/systemd下有官方的脚本可以参考 以下的内容经过修改，若启动不成功可以尝试更改custom/conf/目录下的配置文件
vim /lib/systemd/system/gogs.service [Unit] Description=Gogs After=syslog.target After=network.target [Service] Type=simple User=gogs Group=gogs WorkingDirectory=/usr/local/gogs ExecStart=/usr/local/gogs/gogs web Restart=always Environment=USER=gogs HOME=/home/gogs [Install] WantedBy=multi-user.target systemctl daemon-reload systemctl start gogs.service systemctl status gogs.service systemctl enable gogs.service --now</content></entry><entry><title>Golang1.18泛型新特性</title><url>/posts/golang/1.18-%E6%B3%9B%E5%9E%8B%E6%96%B0%E7%89%B9%E6%80%A7/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"> Go 1.18 泛型全面讲解：一篇讲清泛型的全部</content></entry><entry><title>Go语言快速上手</title><url>/posts/golang/go%E8%AF%AD%E8%A8%80%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[在Linux上安装GoLang wget https://golang.google.cn/dl/go1.19.1.linux-amd64.tar.gz rm -rf /usr/local/go &amp;&amp; tar -C /usr/local -xzf go1.19.1.linux-amd64.tar.gz echo &#39;export PATH=$PATH:/usr/local/go/bin&#39; &gt;&gt; $HOME/.profile source $HOME/.profile go version go env -w GO111MODULE=on go env -w GOPROXY=https://goproxy.cn,direct 在Windows上安装GoLang 官网地址 国内镜像地址 下载.msi文件安装后，配置环境变量
将安装的Go\bin 目录添加到 Path 环境变量中
将工作目录也添加到环境变量中
确认之后检查是否成功
配置开发环境 配置「七牛云」的代理服务
$ go env -w GO111MODULE=on $ go env -w GOPROXY=https://goproxy.cn,direct 配置工作路径
go env -w GOPATH=C:\WorkDir\Go # 这是我的工作路径，填自己的 打开vscode安装GO语言的插件
之后工作目录下新建一个src目录，在该目录下创建xxx.go文件，根据vscode的提示安装所有的包
变量的声明 // 法一 var num int = 100 var str string = &#34;123&#34; // 法二 知道变量的值后可以不用声明属性 var num = 100 var str = &#34;123&#34; // 法三 此方法只能用在局部变量中 num := 100 str := &#34;123&#34; // 多行声明 var num, str = 100, &#34;123&#34; var ( num = 100 str = &#34;123&#34; ) num, str := 100, &#34;123&#34; 常量的定义 // 常量只读，不允许修改 const num int = 100 // const 用来定义枚举类型 const ( // 可以在 const() 中添加关键字 iota(也只能在const 中使用), iota 会自增，第一行默认为 1 January = iota // iota = 0 February // iota = 1 March // iota = 2 April // iota = 3 May // ... ... June July ) 函数的返回值 package main import &#34;fmt&#34; // 1个匿名返回值 func demo1(a int) int { b := a * 2 return b } // 2个匿名返回值 func demo2(a int, b int) (int, int) { return a * 2, b * 3 } // 不匿名的返回 func demo3(a int, b int) (r1 int, r2 int) { r1 = a * 2 r2 = b * 3 return } func demo4(a int, b int) (r1, r2 int){ } func main() { ret1 := demo1(10) fmt.Printf(&#34;ret1 = %d\n&#34;, ret1) ret2, ret3 := demo2(10, 20) fmt.Printf(&#34;ret2 = %d, ret3 = %d\n&#34;, ret2, ret3) ret4, ret5 := demo3(100, 200) fmt.Printf(&#34;ret4 = %d, ret5 = %d\n&#34;, ret4, ret5) } init() 函数和import // 程序会先执行最里面的包的init()方法 **注意：**函数名开头大写表示函数是public, 小写表示函数是private
import ( _ &#34;$GOPATH/xxx/xxx&#34; // 匿名导包，不调用也会执行init() name &#34;$GOPATH/xxx/xxx&#34; // 起别名 . &#34;$GOPATH/xxx/xxx&#34; // 导入到当前程序中，可直接使用包内的方法 ) defer 语句的调用顺序 defer在函数的生命周期结束后调用(在return之后)，遵循先进后出原则
package main import &#34;fmt&#34; func fun1() { fmt.Println(&#34;this is fun1 called&#34;) } func fun2() int { fmt.Println(&#34;this is fun2 called&#34;) return fun3() } func fun3() int { fmt.Println(&#34;this is fun3 called&#34;) return 0 } func main() { defer fun1() defer fun2() } /* 结果 this is fun2 called this is fun3 called this is fun1 called */ 静态数组和动态数值 // 静态数组，上来就声明长度或者内容,有着固定长度 arr1 := [4]int{1,2,3,4} arr2 := [10]int{1,2,3,4} // 前四有值，后面的全为0 var arr3 [5]int // 定义五个为0的数组 // 动态数组没有固定的长度，也叫 切片 (其本质为指针) slice := []int{1,2,3} // 默认值 1 2 3 长度为3 len=3 , cap = 3 slice1 := make([]int, len, cap) // len &lt;= cap slice2 := make([]int, 3) // len = 3, cap = 3 // 切片的追加 slice1 = append(slice1, 1) // 向slice1追加一个值为1的元素 // 若向一个容量已满的切片追加，则会新建一个之前两倍容量的切片， // 之后将旧的切片赋值给新的切片，在新的切片上进行追加 // 切片的截取 slice4 := []int{1,2,3,4,5,6} // 若修改num，则slice4也会改变 浅拷贝 num := slice4[0:3] // 左闭右开 [:2] [1:] // 深拷贝 num2 := make([]int, 3) copy(num2, slice4) map的使用 和切片一样，是动态的，要分配空间
|-&gt;值 mymap := make(map[int]string, 10) // map[key]value / cap = 10 |-&gt; 键 mymap[0] = &#34;Jun&#34; mymap[1] = &#34;xxx&#34; ... ... mymap1 := make(map[int]string) // 可以不加容量 mymap := map[string]string{ &#34;one&#34;: &#34;Jun&#34;, &#34;tow&#34;: &#34;Fer&#34;, &#34;key&#34;: &#34;vlaue&#34; } // 删除 delete(mymap, &#34;key&#34;) // 遍历 for key, value := range mymap { fmt.Println(&#34;key = &#34;, key) fmt.Println(&#34;value = &#34;, value) } **注意：**map 和 切片 传参时传的是指针，因此改变值时，原来的也会改变
结构体 // 大写表示public 小写表示private type book struct{ name string autoh string price int } type Student struct { Name string Gender string Age int8 } 结构体之间的嵌套可以看作继承 type Personal struct { Name string Age int Gender string } // Student 继承 Personal type Student struct { Personal Classroom string } // 与结构体绑定方法 // 父类的方法 func (p Personal) Run() { fmt.Println(p.Name + &#34;在奔跑~~~~~~~~&#34;) } // 子类的方法 func (t Student) HaveClass() { fmt.Println(t.Name + &#34;在&#34; + t.Classroom + &#34;上课&#34;) } func main() { var s = Student{ Personal: Personal{ &#34;Colzry&#34;, 21, &#34;男&#34;, }, Classroom: &#34;16班&#34;, } fmt.Printf(&#34;%#v\n&#34;, s) // 调用父类的方法 s.Run() // 调用自己的方法 s.HaveClass() } 接口 使用接口来规范结构体的方法 package main import &#34;fmt&#34; //定义一个接口 type Operate interface { start() stop() } type Phone struct { Name string } // 让结构体实现接口 func (p Phone) start() { fmt.Println(p.Name + &#34;开机&#34;) } func (p Phone) stop() { fmt.Println(p.Name + &#34;关机&#34;) } func main() { // 实例化接口 var redmi Operate = Phone{Name: &#34;RedMi k40&#34;} // 调用实现的方法 redmi.start() redmi.stop() } 使用空接口来做泛型 var a interface{} a = 20 fmt.Printf(&#34;a的值: %v, a的类型: %T\n&#34;, a, a) a = &#34;Colzry&#34; fmt.Printf(&#34;a的值: %v, a的类型: %T\n&#34;, a, a) a = true fmt.Printf(&#34;a的值: %v, a的类型: %T\n&#34;, a, a) a = []int{1, 2, 3} fmt.Printf(&#34;a的值: %v, a的类型: %T\n&#34;, a, a) b := make(map[interface{}]interface{}) b[4] = true b[&#34;str&#34;] = 25 fmt.Println(b) c := []interface{}{1, 2, &#34;3&#34;, true} fmt.Println(c) ######## 打印 ########## a的值: 20, a的类型: int a的值: Colzry, a的类型: string a的值: true, a的类型: bool a的值: [1 2 3], a的类型: []int map[4:true str:25] [1 2 3 true] 常用在函数的参数和返回值处
func getObj(value interface{}) interface{} { return value } 类型断言 package main import &#34;fmt&#34; // 类型断言 func TypePrint(value interface{}) { // 两种判断类型的方法(if switch)，但是switch只能使用 x.(type) if _, ok := value.(string); ok { fmt.Println(&#34;它居然是个字符串&#34;) } else { fmt.Println(&#34;可惜它不是字符串&#34;) } switch value.(type) { case int: fmt.Println(&#34;int类型&#34;) case string: fmt.Println(&#34;string类型&#34;) case bool: fmt.Println(&#34;bool类型&#34;) case []int: fmt.Println(&#34;[]int类型&#34;) default: fmt.Println(&#34;不在列表范围内&#34;) } } func main() { a := 20 TypePrint(a) b := &#34;Colzry&#34; TypePrint(b) } 打印
可惜它不是字符串 int类型 它居然是个字符串 string类型 协程 使用关键字go可以将一个方法(函数)作为协程来使用
func main() { go test() for i := 0; i &lt; 10; i++ { fmt.Println(&#34;main ---------------&#34;, i) time.Sleep(time.Millisecond * 500) } } func test() { for i := 0; i &lt; 10; i++ { fmt.Println(&#34;test ---------------&#34;, i) time.Sleep(time.Millisecond * 1000) } } 这样main函数和test函数就能同时运行，但会出现一个问题，main函数会因为先结束而导致test函数没运行完就结束了，这时需要使用异步
import ( &#34;fmt&#34; &#34;sync&#34; &#34;time&#34; ) var wg sync.WaitGroup func main() { wg.Add(1) // 添加一个协程 go test() // 启动一个协程 for i := 0; i &lt; 10; i++ { fmt.Println(&#34;main ---------------&#34;, i) time.Sleep(time.Millisecond * 500) } wg.Wait() // 等待所有协程执行完 } func test() { for i := 0; i &lt; 10; i++ { fmt.Println(&#34;test ---------------&#34;, i) time.Sleep(time.Millisecond * 1000) } wg.Done() // 完成一个协程 } Add, Wait, Done 需要一起出现 管道 使用关键字chan定义一个管道(注意：管道也是地址引用型)
var ch chan int // 类型为 int 型 ch = make(chan int, 10) // 给管道ch分配10个空间 ch &lt;- 10 // 将10写入管道ch中 value := &lt;- ch // 取出管道中的第一个值，也可匿名取出 &lt;- ch close(ch) // 关闭管道 管道中的值遵循先进先出，一旦没有导致取不出或者满了导致放不了都会报错，错误如下
fatal error: all goroutines are asleep - deadlock! 使用for range 遍历管道时要先关闭管道
func main() { ch := make(chan int, 10) for i := 0; i &lt; 10; i++ { ch &lt;- i } close(ch) for v := range ch{ fmt.Println(v) } } 单向管道
chan&lt;- // 只写 &lt;-chan // 只读 ch1 = make(chan&lt;- int, 10) // 只写的int管道 ch2 = make(&lt;-chan int, 10) // 只读的int管道 // 形参表示 func fn1(ch chan&lt;- int){} func fn2(ch &lt;-chan int){} 管道和线程的使用 package main import ( &#34;fmt&#34; &#34;sync&#34; &#34;time&#34; ) var wg sync.WaitGroup func fn1(ch chan int){ for i := 1; i &lt;= 10; i++ { ch &lt;- i fmt.Println(&#34;写入&#34;, i, &#34;成功&#34;) time.Sleep(time.Millisecond * 100) } close(ch) wg.Done() } func fn2(ch chan int) { for v := range ch{ fmt.Println(&#34;读取&#34;, v, &#34;成功&#34;) time.Sleep(time.Millisecond * 10) } wg.Done() } func main() { ch := make(chan int, 10) wg.Add(2) go fn1(ch) go fn2(ch) wg.Wait() } package main import ( &#34;fmt&#34; &#34;sync&#34; ) var wg sync.WaitGroup func putNum(numChan chan int) { for i := 2; i &lt;= 1200000; i++ { numChan &lt;- i } close(numChan) wg.Done() } func getPrime(numChan chan int, primeChan chan int, exitChan chan bool) { for num := range numChan { flag := true for i := 2; i &lt; num; i++ { if num % i == 0 { flag = false break } } if flag { primeChan &lt;- num } } // 存放素数管道完成数 +1 exitChan &lt;- true wg.Done() } func printPrime(primeChan chan int) { for v := range primeChan{ fmt.Println(v) } wg.Done() } func main() { numChan := make(chan int, 1000) // 存放数字的管道 primeChan := make(chan int, 1000) // 存放素数的管道 exitChan := make(chan bool, 16) // 存放素数管道完成数 count := 20 // 判断素数的协程数 wg.Add(1) go putNum(numChan) for i := 0; i &lt; count; i++ { wg.Add(1) go getPrime(numChan, primeChan, exitChan) } wg.Add(1) go printPrime(primeChan) wg.Add(1) go func() { for i := 0; i &lt; count; i++ { &lt;- exitChan // 存放素数管道完成数 -1 } // 判断存放素数管道完成数都运行完后关闭管道 close(primeChan) wg.Done() }() wg.Wait() fmt.Println(&#34;执行结束......&#34;) } 多路复用 多路复用使用select关键字，通常搭配for使用，让case中的代码随机的执行，也叫并发
package main import &#34;fmt&#34; func main() { intChan := make(chan int, 10) strChan := make(chan string, 10) for i := 0; i &lt; 10; i++ { intChan &lt;- i strChan &lt;- &#34;hello&#34; + fmt.Sprint(i) } for { select { case v := &lt;- intChan: fmt.Println(&#34;intChan 读取的数据&#34;, v) case v := &lt;-strChan: fmt.Println(&#34;strChan 读取的数据&#34;, v) default: fmt.Println(&#34;结束&#34;) return } } } goroutine异常处理 使用defer + recover进行异常捕获
defer func(){ if err := recover(); err != nil { fmt.Println(&#34;发生错误&#34;, err) } }() package main import ( &#34;fmt&#34; &#34;time&#34; ) func fn1() { defer func(){ if err := recover(); err != nil { fmt.Println(&#34;发生错误&#34;, err) } }() var name map[int]string name[0] = &#34;test&#34; } func fn2() { for i := 0; i &lt; 10; i++ { fmt.Println(&#34;hell0&#34;, i) } } func main() { go fn1() go fn2() time.Sleep(time.Second * 5) } ]]></content></entry><entry><title>iperf3的使用</title><url>/posts/linux%E6%93%8D%E4%BD%9C/iperf3%E7%9A%84%E4%BD%BF%E7%94%A8/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html">1. 安装 1.1 linux # Debian sudo apt install iperf3 -y # Centos sudo yum install iperf3 -y 1.2 windows 官网下载地址 2. 使用 2.1 详细命令参数 -p, --port #，Server 端监听、Client 端连接的端口号； -f, --format [kmgKMG]，报告中所用的数据单位，Kbits, Mbits, KBytes, Mbytes； -i, --interval #，每次报告的间隔，单位为秒； -F, --file name，测试所用文件的文件名。如果使用在 Client 端，发送该文件用作测试；如果使用在 Server 端，则是将数据写入该文件，而不是丢弃； -A, --affinity n/n,m，设置 CPU 亲和力； -B, --bind ，绑定指定的网卡接口； -V, --verbose，运行时输出更多细节； -J, --json，运行时以 JSON 格式输出结果； --logfile f，输出到文件； -d, --debug，以 debug 模式输出结果； -v, --version，显示版本信息并退出； -h, --help，显示帮助信息并退出。 Server 端参数： -s, --server，以 Server 模式运行； -D, --daemon，在后台以守护进程运行； -I, --pidfile file，指定 pid 文件； -1, --one-off，只接受 1 次来自 Client 端的测试，然后退出。 Client 端参数 -c, --client ，以 Client 模式运行，并指定 Server 端的地址； -u, --udp，以 UDP 协议进行测试； -b, --bandwidth #[KMG][/#]，限制测试带宽。UDP 默认为 1Mbit/秒，TCP 默认无限制； -t, --time #，以时间为测试结束条件进行测试，默认为 10 秒； -n, --bytes #[KMG]，以数据传输大小为测试结束条件进行测试； -k, --blockcount #[KMG]，以传输数据包数量为测试结束条件进行测试； -l, --len #[KMG]，读写缓冲区的长度，TCP 默认为 128K，UDP 默认为 8K； --cport ，指定 Client 端运行所使用的 TCP 或 UDP 端口，默认为临时端口； -P, --parallel #，测试数据流并发数量； -R, --reverse，反向模式运行（Server 端发送，Client 端接收）； -w, --window #[KMG]，设置套接字缓冲区大小，TCP 模式下为窗口大小； -C, --congestion ，设置 TCP 拥塞控制算法（仅支持 Linux 和 FreeBSD ）； -M, --set-mss #，设置 TCP/SCTP 最大分段长度（MSS，MTU 减 40 字节）； -N, --no-delay，设置 TCP/SCTP no delay，屏蔽 Nagle 算法； -4, --version4，仅使用 IPv4； -6, --version6，仅使用 IPv6； -S, --tos N，设置 IP 服务类型（TOS，Type Of Service）； -L, --flowlabel N，设置 IPv6 流标签（仅支持 Linux）； -Z, --zerocopy，使用 “zero copy”（零拷贝）方法发送数据； -O, --omit N，忽略前 n 秒的测试； -T, --title str，设置每行测试结果的前缀； --get-server-output，从 Server 端获取测试结果； --udp-counters-64bit，在 UDP 测试包中使用 64 位计数器（防止计数器溢出）。 2.2 简单使用例子 # 示例1 正向测试 # Server iperf3 -s # Client iperf3 -c Server_IP地址 # 示例2 反向测试 iperf3 -s # Client iperf3 -c Server_IP地址 -R # 示例3 # Server iperf3 -s # Client iperf3 -c Server_IP地址 -b 1000M -t 60 -d -c 为客户端运行并要指定服务端的IP地址 -b 表示使用的测试带宽 -t 表示以时间为测试结束条件进行测试，默认为 10 秒 -d 打印出更详细的debug调试信息</content></entry><entry><title>Java多线程同步锁</title><url>/posts/java/java-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E9%94%81/</url><categories><category>Java</category></categories><tags><tag>Java</tag></tags><content type="html"><![CDATA[ 同步监视器必须为唯一的对象
例如：this, *.class
若使用*.class时，报以下错误
则原因为： 线程操作的wait()、notify()、notifyAll()方法只能在同步控制方法或同步控制块内调用。如果在非同步控制方法或控制块里调用，程序能通过编译，但运行的时候，将得到 java.lang.IllegalMonitorStateException 异常，并伴随着一些含糊信息，比如 current thread is not owner(当前线程不是拥有者)。其实异常的含义是 调用wait()、notify()、notifyAll()的任务在调用这些方法前必须 ‘拥有’（获取）对象的锁。
解决方法： 在wait()、notify()、notifyAll()方法调用是加上调用的对象，例如：*.class.wait();
具体实现 使用两个线程间隔递增的打印0到100
使用*.class同步监视器 public class demo implements Runnable{ public static int number = 0; @Override public void run() { while (true) { synchronized (demo.class) { demo.class.notify(); if (number &lt;= 100) { try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + &#34; : &#34; + number++); try { demo.class.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } else { System.exit(0); } } } } public static void main(String[] args) { demo demo = new demo(); Thread thread1 = new Thread(demo); Thread thread2 = new Thread(demo); thread1.setName(&#34;线程1&#34;); thread2.setName(&#34;线程2&#34;); thread1.start(); thread2.start(); } } 使用this同步监视器 public class demo implements Runnable{ public static int number = 0; @Override public void run() { while (true) { synchronized (this) { this.notify(); if (number &lt;= 100) { try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + &#34; : &#34; + number++); try { this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } else { System.exit(0); } } } } public static void main(String[] args) { demo demo = new demo(); Thread thread1 = new Thread(demo); Thread thread2 = new Thread(demo); thread1.setName(&#34;线程1&#34;); thread2.setName(&#34;线程2&#34;); thread1.start(); thread2.start(); } } ]]></content></entry><entry><title>LambdaQueryWrapper使用</title><url>/posts/java/lambdaquerywrapper%E4%BD%BF%E7%94%A8/</url><categories><category>Java</category></categories><tags><tag>Java</tag></tags><content type="html"><![CDATA[// eq用法 LambdaQueryWrapper&lt;News&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;(); queryWrapper.eq(News::getNid, nid); News news = newsService.getOne(queryWrapper); // select用法 LambdaQueryWrapper&lt;User&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;(); queryWrapper.eq(User::getUid, uid).select(User::getUid, User::getUsername, User::getIsVip); User user = userService.getOne(queryWrapper); // and用法 Page&lt;User&gt; userPage = new Page&lt;&gt;(pageParam.getPage(), pageParam.getPageSize()); LambdaQueryWrapper&lt;User&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;(); queryWrapper.eq(User::getType, 1).and(u -&gt; u.eq(User::getStatus, 0)); Page&lt;User&gt; page = userService.page(userPage, queryWrapper); ]]></content></entry><entry><title>Linux JDK一键安装脚本</title><url>/posts/java/linux-jdk-%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/</url><categories><category>Java</category></categories><tags><tag>Java</tag><tag>JDK</tag></tags><content type="html"><![CDATA[bash &lt;(curl -Ssl https://picture-czy.oss-cn-beijing.aliyuncs.com/shareFile/jdk-install.sh) 下载不了的话，运行下面脚本
#!/bin/bash set -e java_dist=&#34;/root/jdk-8u202-linux-x64.tar.gz&#34; default_java_dir=&#34;/usr/local&#34; java_dir=&#34;$default_java_dir&#34; SUDO_USER=root function usage() { echo &#34;&#34; echo &#34;这个脚本会自动下载jdk 1.8. &#34; echo &#34;Usage: &#34; echo &#34;install-java.sh -f &lt;java_dist&gt; [-p &lt;java_dir&gt;]&#34; echo &#34;&#34; echo &#34;-f: The jdk tar.gz file. 默认安装的是/root/jdk-8u202-linux-x64.tar.gz&#34; echo &#34;-p: java默认安装在/usr/local目录中，你可以通过-p命令切换目录&#34; echo &#34;-h: 显示帮助.&#34; echo &#34;&#34; } function confirm() { # call with a prompt string or use a default read -r -p &#34;${1:-Are you sure?} [y/N] &#34; response case $response in [yY][eE][sS] | [yY]) true ;; *) false ;; esac } # Make sure the script is running as root. if [ &#34;$UID&#34; -ne &#34;0&#34; ]; then echo &#34;You must be root to run $0. Try following&#34; echo &#34;sudo $0&#34; exit 9 fi while getopts &#34;f:p:h&#34; opts; do case $opts in f) java_dist=${OPTARG} ;; p) java_dir=${OPTARG} ;; h) usage exit 0 ;; \?) usage exit 1 ;; esac done if ! [ -x &#34;$(command -v axel)&#34; ]; then wget https://mirrors.huaweicloud.com/java/jdk/8u202-b08/jdk-8u202-linux-x64.tar.gz -O /root/jdk-8u202-linux-x64.tar.gz else axel -n 10 -a https://mirrors.huaweicloud.com/java/jdk/8u202-b08/jdk-8u202-linux-x64.tar.gz -o /root/jdk-8u202-linux-x64.tar.gz fi if [[ ! -f $java_dist ]]; then echo &#34;Please specify the Java distribution file.&#34; echo &#34;Use -h for help.&#34; exit 1 fi # Validate Java Distribution java_dist_filename=$(basename $java_dist) if [[ ${java_dist_filename: -7} != &#34;.tar.gz&#34; ]]; then echo &#34;Java distribution must be a valid tar.gz file.&#34; exit 1 fi # Create the default directory if user has not specified any other path if [[ $java_dir == $default_java_dir ]]; then mkdir -p $java_dir fi #Validate java directory if [[ ! -d $java_dir ]]; then echo &#34;Please specify a valid Java installation directory.&#34; exit 1 fi echo &#34;Installing: $java_dist_filename&#34; # Check Java executable java_exec=&#34;$(tar -tzf $java_dist | grep ^[^/]*/bin/java$ || echo &#34;&#34;)&#34; if [[ -z $java_exec ]]; then echo &#34;Could not find \&#34;java\&#34; executable in the distribution. Please specify a valid Java distribution.&#34; exit 1 fi # JDK Directory with version jdk_dir=&#34;$(echo $java_exec | cut -f1 -d&#34;/&#34;)&#34; extracted_dirname=$java_dir&#34;/&#34;$jdk_dir # Extract Java Distribution if [[ ! -d $extracted_dirname ]]; then echo &#34;Extracting $java_dist to $java_dir&#34; tar -xof $java_dist -C $java_dir echo &#34;JDK is extracted to $extracted_dirname&#34; else echo &#34;WARN: JDK was not extracted to $java_dir. There is an existing directory with the name \&#34;$jdk_dir\&#34;.&#34; if ! (confirm &#34;Do you want to continue?&#34;); then exit 1 fi fi if [[ ! -f &#34;${extracted_dirname}/bin/java&#34; ]]; then echo &#34;ERROR: The path $extracted_dirname is not a valid Java installation.&#34; exit 1 fi # Oracle JDK: 7 to 8 java_78_dir_regex=&#34;^jdk1\.([0-9]*).*$&#34; # Oracle JDK / OpenJDK / AdoptOpenJDK: 9 and upwards java_9up_dir_regex=&#34;^jdk-([0-9]*).*$&#34; # JDK Major Version jdk_major_version=&#34;&#34; if [[ $jdk_dir =~ $java_78_dir_regex ]]; then jdk_major_version=$(echo $jdk_dir | sed -nE &#34;s/$java_78_dir_regex/\1/p&#34;) else jdk_major_version=$(echo $jdk_dir | sed -nE &#34;s/$java_9up_dir_regex/\1/p&#34;) fi # Install Demos if [[ $jdk_dir =~ $java_78_dir_regex ]]; then # Demos are only available for Java 7 and 8 demos_dist=$(dirname $java_dist)&#34;/&#34;$(echo $java_dist_filename | sed &#39;s/\.tar\.gz/-demos\0/&#39;) fi if [[ -f $demos_dist &amp;&amp; ! -d $extracted_dirname/demo ]]; then # No demo directory if (confirm &#34;Extract demos?&#34;); then echo &#34;Extracting $demos_dist to $java_dir&#34; tar -xf $demos_dist -C $java_dir fi fi # Install Unlimited JCE Policy (only for Oracle JDK 7 &amp; 8) # Java 9 and above: default JCE policy files already allow for \&#34;unlimited\&#34; cryptographic strengths. unlimited_jce_policy_dist=&#34;&#34; if [[ $jdk_dir =~ ^jdk1\.7.* ]]; then unlimited_jce_policy_dist=&#34;$(dirname $java_dist)/UnlimitedJCEPolicyJDK7.zip&#34; elif [[ $jdk_dir =~ ^jdk1\.8.* ]]; then unlimited_jce_policy_dist=&#34;$(dirname $java_dist)/jce_policy-8.zip&#34; fi if [[ -f $unlimited_jce_policy_dist ]]; then #Check whether unzip command exsits if ! command -v unzip &gt;/dev/null 2&gt;&amp;1; then echo &#34;Please install unzip (apt -y install unzip).&#34; exit 1 fi if (confirm &#34;Install Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files?&#34;); then echo &#34;Extracting policy jars in $unlimited_jce_policy_dist to $extracted_dirname/jre/lib/security&#34; unzip -j -o $unlimited_jce_policy_dist *.jar -d $extracted_dirname/jre/lib/security fi fi # Run update-alternatives commands if (confirm &#34;Run update-alternatives commands?&#34;); then echo &#34;Running update-alternatives...&#34; cmd=&#34;update-alternatives --install /usr/bin/java java $extracted_dirname/bin/java 10000&#34; declare -a commands=($(ls -1 ${extracted_dirname}/bin | grep -v ^java$)) for command in &#34;${commands[@]}&#34;; do command_path=$extracted_dirname/bin/$command if [[ -x $command_path ]]; then cmd=&#34;$cmd --slave /usr/bin/$command $command $command_path&#34; fi done lib_path=$extracted_dirname/jre/lib/amd64/libnpjp2.so if [[ -d &#34;/usr/lib/mozilla/plugins/&#34; ]] &amp;&amp; [[ -f $lib_path ]]; then cmd=&#34;$cmd --slave /usr/lib/mozilla/plugins/libjavaplugin.so mozilla-javaplugin.so $lib_path&#34; fi echo $cmd # Execute command $cmd update-alternatives --set java $extracted_dirname/bin/java fi # Create system preferences directory java_system_prefs_dir=&#34;/etc/.java/.systemPrefs&#34; if [[ ! -d $java_system_prefs_dir ]]; then if (confirm &#34;Create Java System Prefs Directory ($java_system_prefs_dir) and change ownership to $SUDO_USER:$SUDO_USER?&#34;); then echo &#34;Creating $java_system_prefs_dir&#34; mkdir -p $java_system_prefs_dir chown -R $SUDO_USER:$SUDO_USER $java_system_prefs_dir fi fi USER_HOME=&#34;$(getent passwd $SUDO_USER | cut -d: -f6)&#34; if [[ -d &#34;$USER_HOME&#34; ]] &amp;&amp; (confirm &#34;Do you want to set JAVA_HOME environment variable in $USER_HOME/.bashrc?&#34;); then if grep -q &#34;export JAVA_HOME=.*&#34; $USER_HOME/.bashrc; then sed -i &#34;s|export JAVA_HOME=.*|export JAVA_HOME=$extracted_dirname|&#34; $USER_HOME/.bashrc else echo &#34;export JAVA_HOME=$extracted_dirname&#34; &gt;&gt;$USER_HOME/.bashrc fi fi applications_dir=&#34;$USER_HOME/.local/share/applications&#34; create_jmc_shortcut() { shortcut_file=&#34;$applications_dir/jmc_$jdk_major_version.desktop&#34; cat &lt;&lt;_EOF_ &gt;$shortcut_file [Desktop Entry] Name=Java $jdk_major_version: JMC Comment=Oracle Java Mission Control for Java $jdk_major_version Type=Application Exec=$extracted_dirname/bin/jmc Icon=$extracted_dirname/lib/missioncontrol/icon.xpm Terminal=false _EOF_ chmod +x $shortcut_file } if [[ -d $applications_dir ]] &amp;&amp; [[ -f $extracted_dirname/bin/jmc ]]; then if (confirm &#34;Do you want to create a desktop shortcut to JMC?&#34;); then create_jmc_shortcut fi fi 添加执行权限并运行
chmod +x install-java.sh &amp;&amp; ./install-java.sh ]]></content></entry><entry><title>Linux usr文件概述</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux-usr%E6%96%87%E4%BB%B6%E6%A6%82%E8%BF%B0/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">/bin 存放所有用户皆可用的系统程序，系统启动或者系统修复时可用（在没有挂载 /usr 目录时就可以使用） /sbin 存放超级用户才能使用的系统程序 /usr/bin 存放所有用户都可用的应用程序 /usr/sbin 存放超级用户才能使用的应用程序 /usr/local/bin 存放所有用户都可用的与本地机器无关的程序 /usr/local/sbin 存放超级用户才能使用的与本地机器无关的程序</content></entry><entry><title>Linux安装最新的Node(LTS)</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux-%E5%AE%89%E8%A3%85%E6%9C%80%E6%96%B0%E7%9A%84nodelts/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>Node</tag></tags><content type="html"># 先更新软件源 $ sudo apt-get upadte # 安装npm $ sudo apt install npm # 使用npm全局安装n模块 $ sudo npm install n -g # 安装最新长期支持版node $ sudo n lts # 检查是否安装成功 $ node -v</content></entry><entry><title>Linux查看温度</title><url>/posts/linux%E6%93%8D%E4%BD%9C/%E6%9F%A5%E7%9C%8B%E6%B8%A9%E5%BA%A6/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">方法一 pi@RaspberryPi:~ $ /opt/vc/bin/vcgencmd measure_temp temp=51.5&amp;#39;C 方法二 pi@RaspberryPi:~ $ cat /sys/class/thermal/thermal_zone0/temp 50464 此处的数值除以1000，单位是℃。</content></entry><entry><title>Linux常用命令</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[
系统信息 arch #显示机器的处理器架构(1) uname -m #显示机器的处理器架构(2) uname -r #显示正在使用的内核版本 dmidecode -q #显示硬件系统部件 - (SMBIOS / DMI) hdparm -i /dev/hda #罗列一个磁盘的架构特性 hdparm -tT /dev/sda #在磁盘上执行测试性读取操作 cat /proc/cpuinfo #显示CPU info的信息 cat /proc/interrupts #显示中断 cat /proc/meminfo #校验内存使用 cat /proc/swaps #显示哪些swap被使用 cat /proc/version #显示内核的版本 cat /proc/net/dev #显示网络适配器及统计 cat /proc/mounts #显示已加载的文件系统 lspci -tv #罗列PCI设备 lsusb -tv #显示USB设备 date 显示系统日期 cal 2007 #显示2007年的日历表 date 041217002007.00 #设置日期和时间 - 月日时分年.秒 clock -w #将时间修改保存到 BIOS 关机 (系统的关机、重启以及登出 ) shutdown -h now #关闭系统(1) init 0 #关闭系统(2) telinit 0 #关闭系统(3) shutdown -h hours:minutes &amp; #按预定时间关闭系统 shutdown -c #取消按预定时间关闭系统 shutdown -r now #重启(1) reboot #重启(2) logout #注销 文件和目录 cd /home #进入 &#39;/ home&#39; 目录&#39; cd .. #返回上一级目录 cd ../.. #返回上两级目录 cd #进入个人的主目录 cd ~user1 #进入个人的主目录 cd - #返回上次所在的目录 pwd #显示工作路径 ls #查看目录中的文件 ls -F #查看目录中的文件 ls -l #显示文件和目录的详细资料 ls -a #显示隐藏文件 ls *[0-9]* #显示包含数字的文件名和目录名 tree #显示文件和目录由根目录开始的树形结构(1) lstree #显示文件和目录由根目录开始的树形结构(2) mkdir dir1 #创建一个叫做 &#39;dir1&#39; 的目录&#39; mkdir dir1 dir2 #同时创建两个目录 mkdir -p /tmp/dir1/dir2 #创建一个目录树 rm -f file1 #删除一个叫做 &#39;file1&#39; 的文件&#39; rmdir dir1 #删除一个叫做 &#39;dir1&#39; 的目录&#39; rm -rf dir1 #删除一个叫做 &#39;dir1&#39; 的目录并同时删除其内容 rm -rf dir1 dir2 #同时删除两个目录及它们的内容 mv dir1 new_dir #重命名/移动 一个目录 cp file1 file2 #复制一个文件 cp dir/* . #复制一个目录下的所有文件到当前工作目录 cp -a /tmp/dir1 . #复制一个目录到当前工作目录 cp -a dir1 dir2 #复制一个目录 ln -s file1 lnk1 #创建一个指向文件或目录的软链接 ln file1 lnk1 #创建一个指向文件或目录的物理链接 touch -t 0712250000 file1 #修改一个文件或目录的时间戳 - (YYMMDDhhmm) file file1 outputs the mime type of the file as text iconv -l #列出已知的编码 iconv -f fromEncoding -t toEncoding inputFile &gt; outputFile creates a new from the given input file by assuming it is encoded in fromEncoding and converting it to toEncoding. find . -maxdepth 1 -name *.jpg -print -exec convert &#34;{}&#34; -resize 80x60 &#34;thumbs/{}&#34; \; batch resize files in the current directory and send them to a thumbnails directory (requires convert from Imagemagick) 文件搜索 find / -name file1 #从 &#39;/&#39; 开始进入根文件系统搜索文件和目录 find / -user user1 #搜索属于用户 &#39;user1&#39; 的文件和目录 find /home/user1 -name \*.bin #在目录 &#39;/ home/user1&#39; 中搜索带有&#39;.bin&#39; 结尾的文件 find /usr/bin -type f -atime +100 #搜索在过去100天内未被使用过的执行文件 find /usr/bin -type f -mtime -10 #搜索在10天内被创建或者修改过的文件 find / -name \*.rpm -exec chmod 755 &#39;{}&#39; \; #搜索以 &#39;.rpm&#39; 结尾的文件并定义其权限 find / -xdev -name \*.rpm #搜索以 &#39;.rpm&#39; 结尾的文件，忽略光驱、捷盘等可移动设备 locate \*.ps #寻找以 &#39;.ps&#39; 结尾的文件 - 先运行 &#39;updatedb&#39; 命令 whereis halt #显示一个二进制文件、源码或man的位置 which halt #显示一个二进制文件或可执行文件的完整路径 挂载一个文件系统 mount /dev/hda2 /mnt/hda2 #挂载一个叫做hda2的盘 - 确定目录 &#39;/ mnt/hda2&#39; 已经存在 umount /dev/hda2 #卸载一个叫做hda2的盘 - 先从挂载点 &#39;/ mnt/hda2&#39; 退出 fuser -km /mnt/hda2 #当设备繁忙时强制卸载 umount -n /mnt/hda2 #运行卸载操作而不写入 /etc/mtab 文件- 当文件为只读或当磁盘写满时非常有用 mount /dev/fd0 /mnt/floppy #挂载一个软盘 mount /dev/cdrom /mnt/cdrom #挂载一个cdrom或dvdrom mount /dev/hdc /mnt/cdrecorder #挂载一个cdrw或dvdrom mount /dev/hdb /mnt/cdrecorder #挂载一个cdrw或dvdrom mount -o loop file.iso /mnt/cdrom #挂载一个文件或ISO镜像文件 mount -t vfat /dev/hda5 /mnt/hda5 #挂载一个Windows FAT32文件系统 mount /dev/sda1 /mnt/usbdisk #挂载一个usb 捷盘或闪存设备 mount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share #挂载一个windows网络共享 磁盘空间 df -h #显示已经挂载的分区列表 ls -lSr |more #以尺寸大小排列文件和目录 du -sh dir1 #估算目录 &#39;dir1&#39; 已经使用的磁盘空间&#39; du -sk * | sort -rn #以容量大小为依据依次显示文件和目录的大小 rpm -q -a --qf &#39;%10{SIZE}t%{NAME}n&#39; | sort -k1,1n #以大小为依据依次显示已安装的rpm包所使用的空间 (fedora, redhat类系统) dpkg-query -W -f=&#39;${Installed-Size;10}t${Package}n&#39; | sort -k1,1n #以大小为依据显示已安装的deb包所使用的空间 (ubuntu, debian类系统) 用户和群组 groupadd group_name #创建一个新用户组 groupdel group_name #删除一个用户组 groupmod -n new_group_name old_group_name #重命名一个用户组 useradd -c &#34;Name Surname &#34; -g admin -d /home/user1 -s /bin/bash user1 #创建一个属于 &#34;admin&#34; 用户组的用户 useradd user1 #创建一个新用户 userdel -r user1 #删除一个用户 ( &#39;-r&#39; 排除主目录) usermod -c &#34;User FTP&#34; -g system -d /ftp/user1 -s /bin/nologin user1 #修改用户属性 passwd #修改口令 passwd user1 #修改一个用户的口令 (只允许root执行) chage -E 2005-12-31 user1 #设置用户口令的失效期限 pwck #检查 &#39;/etc/passwd&#39; 的文件格式和语法修正以及存在的用户 grpck #检查 &#39;/etc/passwd&#39; 的文件格式和语法修正以及存在的群组 newgrp group_name #登陆进一个新的群组以改变新创建文件的预设群组 文件的权限 使用 &#34;+&#34; 设置权限，使用 &#34;-&#34; 用于取消 ls -lh #显示权限 ls /tmp | pr -T5 -W$COLUMNS #将终端划分成5栏显示 chmod ugo+rwx directory1 #设置目录的所有人(u)、群组(g)以及其他人(o)以读（r ）、写(w)和执行(x)的权限 chmod go-rwx directory1 #删除群组(g)与其他人(o)对目录的读写执行权限 chown user1 file1 #改变一个文件的所有人属性 chown -R user1 directory1 #改变一个目录的所有人属性并同时改变改目录下所有文件的属性 chgrp group1 file1 #改变文件的群组 chown user1:group1 file1 #改变一个文件的所有人和群组属性 find / -perm -u+s #罗列一个系统中所有使用了SUID控制的文件 chmod u+s /bin/file1 #设置一个二进制文件的 SUID 位 - 运行该文件的用户也被赋予和所有者同样的权限 chmod u-s /bin/file1 #禁用一个二进制文件的 SUID位 chmod g+s /home/public #设置一个目录的SGID 位 - 类似SUID ，不过这是针对目录的 chmod g-s /home/public #禁用一个目录的 SGID 位 chmod o+t /home/public #设置一个文件的 STIKY 位 - 只允许合法所有人删除文件 chmod o-t /home/public #禁用一个目录的 STIKY 位 文件的特殊属性 - 使用 &#34;+&#34; 设置权限，使用 &#34;-&#34; 用于取消 chattr +a file1 #只允许以追加方式读写文件 chattr +c file1 #允许这个文件能被内核自动压缩/解压 chattr +d file1 #在进行文件系统备份时，dump程序将忽略这个文件 chattr +i file1 #设置成不可变的文件，不能被删除、修改、重命名或者链接 chattr +s file1 #允许一个文件被安全地删除 chattr +S file1 #一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘 chattr +u file1 #若文件被删除，系统会允许你在以后恢复这个被删除的文件 lsattr #显示特殊的属性 打包和压缩文件 bunzip2 file1.bz2 #解压一个叫做 &#39;file1.bz2&#39;的文件 bzip2 file1 #压缩一个叫做 &#39;file1&#39; 的文件 gunzip file1.gz #解压一个叫做 &#39;file1.gz&#39;的文件 gzip file1 #压缩一个叫做 &#39;file1&#39;的文件 gzip -9 file1 #最大程度压缩 rar a file1.rar test_file #创建一个叫做 &#39;file1.rar&#39; 的包 rar a file1.rar file1 file2 dir1 #同时压缩 &#39;file1&#39;, &#39;file2&#39; 以及目录 &#39;dir1&#39; rar x file1.rar #解压rar包 unrar x file1.rar #解压rar包 tar -cvf archive.tar file1 #创建一个非压缩的 tarball tar -cvf archive.tar file1 file2 dir1 #创建一个包含了 &#39;file1&#39;, &#39;file2&#39; 以及 &#39;dir1&#39;的档案文件 tar -tf archive.tar #显示一个包中的内容 tar -xvf archive.tar #释放一个包 tar -xvf archive.tar -C /tmp #将压缩包释放到 /tmp目录下 tar -cvfj archive.tar.bz2 dir1 #创建一个bzip2格式的压缩包 tar -jxvf archive.tar.bz2 #解压一个bzip2格式的压缩包 tar -cvfz archive.tar.gz dir1 #创建一个gzip格式的压缩包 tar -zxvf archive.tar.gz #解压一个gzip格式的压缩包 zip file1.zip file1 #创建一个zip格式的压缩包 zip -r file1.zip file1 file2 dir1 #将几个文件和目录同时压缩成一个zip格式的压缩包 unzip file1.zip #解压一个zip格式压缩包 RPM 包 - （Fedora, Redhat及类似系统） rpm -ivh package.rpm #安装一个rpm包 rpm -ivh --nodeeps package.rpm #安装一个rpm包而忽略依赖关系警告 rpm -U package.rpm #更新一个rpm包但不改变其配置文件 rpm -F package.rpm #更新一个确定已经安装的rpm包 rpm -e package_name.rpm #删除一个rpm包 rpm -qa #显示系统中所有已经安装的rpm包 rpm -qa | grep httpd #显示所有名称中包含 &#34;httpd&#34; 字样的rpm包 rpm -qi package_name #获取一个已安装包的特殊信息 rpm -qg &#34;System Environment/Daemons&#34; #显示一个组件的rpm包 rpm -ql package_name #显示一个已经安装的rpm包提供的文件列表 rpm -qc package_name #显示一个已经安装的rpm包提供的配置文件列表 rpm -q package_name --whatrequires #显示与一个rpm包存在依赖关系的列表 rpm -q package_name --whatprovides #显示一个rpm包所占的体积 rpm -q package_name --scripts #显示在安装/删除期间所执行的脚本l rpm -q package_name --changelog #显示一个rpm包的修改历史 rpm -qf /etc/httpd/conf/httpd.conf #确认所给的文件由哪个rpm包所提供 rpm -qp package.rpm -l #显示由一个尚未安装的rpm包提供的文件列表 rpm --import /media/cdrom/RPM-GPG-KEY #导入公钥数字证书 rpm --checksig package.rpm #确认一个rpm包的完整性 rpm -qa gpg-pubkey #确认已安装的所有rpm包的完整性 rpm -V package_name #检查文件尺寸、 许可、类型、所有者、群组、MD5检查以及最后修改时间 rpm -Va #检查系统中所有已安装的rpm包- 小心使用 rpm -Vp package.rpm #确认一个rpm包还未安装 rpm2cpio package.rpm | cpio --extract --make-directories *bin* #从一个rpm包运行可执行文件 rpm -ivh /usr/src/redhat/RPMS/`arch`/package.rpm #从一个rpm源码安装一个构建好的包 rpmbuild --rebuild package_name.src.rpm #从一个rpm源码构建一个 rpm 包 YUM 软件包升级器 - （Fedora, RedHat及类似系统） yum install package_name #下载并安装一个rpm包 yum localinstall package_name.rpm #将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系 yum update package_name.rpm #更新当前系统中所有安装的rpm包 yum update package_name #更新一个rpm包 yum remove package_name #删除一个rpm包 yum list #列出当前系统中安装的所有包 yum search package_name #在rpm仓库中搜寻软件包 yum clean packages #清理rpm缓存删除下载的包 yum clean headers #删除所有头文件 yum clean all #删除所有缓存的包和头文件 DEB 包 (Debian, Ubuntu 以及类似系统) dpkg -i package.deb #安装/更新一个 deb 包 dpkg -r package_name #从系统删除一个 deb 包 dpkg -l #显示系统中所有已经安装的 deb 包 dpkg -l | grep httpd #显示所有名称中包含 &#34;httpd&#34; 字样的deb包 dpkg -s package_name #获得已经安装在系统中一个特殊包的信息 dpkg -L package_name #显示系统中已经安装的一个deb包所提供的文件列表 dpkg --contents package.deb #显示尚未安装的一个包所提供的文件列表 dpkg -S /bin/ping #确认所给的文件由哪个deb包提供 APT 软件工具 (Debian, Ubuntu 以及类似系统) apt-get install package_name #安装/更新一个 deb 包 apt-cdrom install package_name #从光盘安装/更新一个 deb 包 apt-get update #升级列表中的软件包 apt-get upgrade #升级所有已安装的软件 apt-get remove package_name #从系统删除一个deb包 apt-get check #确认依赖的软件仓库正确 apt-get clean #从下载的软件包中清理缓存 apt-cache search searched-package #返回包含所要搜索字符串的软件包名称 查看文件内容 cat file1 #从第一个字节开始正向查看文件的内容 tac file1 #从最后一行开始反向查看一个文件的内容 more file1 #查看一个长文件的内容 less file1 #类似于 &#39;more&#39; 命令，但是它允许在文件中和正向操作一样的反向操作 head -2 file1 #查看一个文件的前两行 tail -2 file1 #查看一个文件的最后两行 tail -f /var/log/messages #实时查看被添加到一个文件中的内容 文本处理 cat file1 file2 ... | command &lt;&gt; file1_in.txt_or_file1_out.txt general syntax for text manipulation using PIPE, STDIN and STDOUT cat file1 | command( sed, grep, awk, grep, etc...) &gt; result.txt #合并一个文件的详细说明文本，并将简介写入一个新文件中 cat file1 | command( sed, grep, awk, grep, etc...) &gt;&gt; result.txt #合并一个文件的详细说明文本，并将简介写入一个已有的文件中 grep Aug /var/log/messages #在文件 &#39;/var/log/messages&#39;中查找关键词&#34;Aug&#34; grep ^Aug /var/log/messages #在文件 &#39;/var/log/messages&#39;中查找以&#34;Aug&#34;开始的词汇 grep [0-9] /var/log/messages #选择 &#39;/var/log/messages&#39; 文件中所有包含数字的行 grep Aug -R /var/log/* #在目录 &#39;/var/log&#39; 及随后的目录中搜索字符串&#34;Aug&#34; sed &#39;s/stringa1/stringa2/g&#39; example.txt #将example.txt文件中的 &#34;string1&#34; 替换成 &#34;string2&#34; sed &#39;/^$/d&#39; example.txt #从example.txt文件中删除所有空白行 sed &#39;/ *#/d; /^$/d&#39; example.txt #从example.txt文件中删除所有注释和空白行 echo &#39;esempio&#39; | tr &#39;[:lower:]&#39; &#39;[:upper:]&#39; #合并上下单元格内容 sed -e &#39;1d&#39; result.txt #从文件example.txt 中排除第一行 sed -n &#39;/stringa1/p&#39; #查看只包含词汇 &#34;string1&#34;的行 sed -e &#39;s/ *$//&#39; example.txt #删除每一行最后的空白字符 sed -e &#39;s/stringa1//g&#39; example.txt #从文档中只删除词汇 &#34;string1&#34; 并保留剩余全部 sed -n &#39;1,5p;5q&#39; example.txt #查看从第一行到第5行内容 sed -n &#39;5p;5q&#39; example.txt #查看第5行 sed -e &#39;s/00*/0/g&#39; example.txt #用单个零替换多个零 cat -n file1 #标示文件的行数 cat example.txt | awk &#39;NR%2==1&#39; #删除example.txt文件中的所有偶数行 echo a b c | awk &#39;{print $1}&#39; #查看一行第一栏 echo a b c | awk &#39;{print $1,$3}&#39; #查看一行的第一和第三栏 paste file1 file2 #合并两个文件或两栏的内容 paste -d &#39;+&#39; file1 file2 #合并两个文件或两栏的内容，中间用&#34;+&#34;区分 sort file1 file2 #排序两个文件的内容 sort file1 file2 | uniq #取出两个文件的并集(重复的行只保留一份) sort file1 file2 | uniq -u #删除交集，留下其他的行 sort file1 file2 | uniq -d #取出两个文件的交集(只留下同时存在于两个文件中的文件) comm -1 file1 file2 #比较两个文件的内容只删除 &#39;file1&#39; 所包含的内容 comm -2 file1 file2 #比较两个文件的内容只删除 &#39;file2&#39; 所包含的内容 comm -3 file1 file2 #比较两个文件的内容只删除两个文件共有的部分 字符设置和文件格式转换 dos2unix filedos.txt fileunix.txt #将一个文本文件的格式从MSDOS转换成UNIX unix2dos fileunix.txt filedos.txt #将一个文本文件的格式从UNIX转换成MSDOS recode ..HTML &lt; page.txt &gt; page.html #将一个文本文件转换成html recode -l | more #显示所有允许的转换格式 文件系统分析 badblocks -v /dev/hda1 #检查磁盘hda1上的坏磁块 fsck /dev/hda1 #修复/检查hda1磁盘上linux文件系统的完整性 fsck.ext2 /dev/hda1 #修复/检查hda1磁盘上ext2文件系统的完整性 e2fsck /dev/hda1 #修复/检查hda1磁盘上ext2文件系统的完整性 e2fsck -j /dev/hda1 #修复/检查hda1磁盘上ext3文件系统的完整性 fsck.ext3 /dev/hda1 #修复/检查hda1磁盘上ext3文件系统的完整性 fsck.vfat /dev/hda1 #修复/检查hda1磁盘上fat文件系统的完整性 fsck.msdos /dev/hda1 #修复/检查hda1磁盘上dos文件系统的完整性 dosfsck /dev/hda1 #修复/检查hda1磁盘上dos文件系统的完整性 初始化一个文件系统 mkfs /dev/hda1 #在hda1分区创建一个文件系统 mke2fs /dev/hda1 #在hda1分区创建一个linux ext2的文件系统 mke2fs -j /dev/hda1 #在hda1分区创建一个linux ext3(日志型)的文件系统 mkfs -t vfat 32 -F /dev/hda1 #创建一个 FAT32 文件系统 fdformat -n /dev/fd0 #格式化一个软盘 mkswap /dev/hda3 #创建一个swap文件系统 SWAP文件系统 mkswap /dev/hda3 #创建一个swap文件系统 swapon /dev/hda3 #启用一个新的swap文件系统 swapon /dev/hda2 /dev/hdb3 #启用两个swap分区 备份 dump -0aj -f /tmp/home0.bak /home #制作一个 &#39;/home&#39; 目录的完整备份 dump -1aj -f /tmp/home0.bak /home #制作一个 &#39;/home&#39; 目录的交互式备份 restore -if /tmp/home0.bak #还原一个交互式备份 rsync -rogpav --delete /home /tmp #同步两边的目录 rsync -rogpav -e ssh --delete /home ip_address:/tmp #通过SSH通道rsync rsync -az -e ssh --delete ip_addr:/home/public /home/local #通过ssh和压缩将一个远程目录同步到本地目录 rsync -az -e ssh --delete /home/local ip_addr:/home/public #通过ssh和压缩将本地目录同步到远程目录 dd bs=1M if=/dev/hda | gzip | ssh user@ip_addr &#39;dd of=hda.gz&#39; #通过ssh在远程主机上执行一次备份本地磁盘的操作 dd if=/dev/sda of=/tmp/file1 #备份磁盘内容到一个文件 tar -Puf backup.tar /home/user 执行一次对 &#39;/home/user&#39; #目录的交互式备份操作 ( cd /tmp/local/ &amp;&amp; tar c . ) | ssh -C user@ip_addr &#39;cd /home/share/ &amp;&amp; tar x -p&#39; #通过ssh在远程目录中复制一个目录内容 ( tar c /home ) | ssh -C user@ip_addr &#39;cd /home/backup-home &amp;&amp; tar x -p&#39; #通过ssh在远程目录中复制一个本地目录 tar cf - . | (cd /tmp/backup ; tar xf - ) #本地将一个目录复制到另一个地方，保留原有权限及链接 find /home/user1 -name &#39;*.txt&#39; | xargs cp -av --target-directory=/home/backup/ --parents #从一个目录查找并复制所有以 &#39;.txt&#39; 结尾的文件到另一个目录 find /var/log -name &#39;*.log&#39; | tar cv --files-from=- | bzip2 &gt; log.tar.bz2 #查找所有以 &#39;.log&#39; 结尾的文件并做成一个bzip包 dd if=/dev/hda of=/dev/fd0 bs=512 count=1 #做一个将 MBR (Master Boot Record)内容复制到软盘的动作 dd if=/dev/fd0 of=/dev/hda bs=512 count=1 #从已经保存到软盘的备份中恢复MBR内容 光盘 cdrecord -v gracetime=2 dev=/dev/cdrom -eject blank=fast -force #清空一个可复写的光盘内容 mkisofs /dev/cdrom &gt; cd.iso #在磁盘上创建一个光盘的iso镜像文件 mkisofs /dev/cdrom | gzip &gt; cd_iso.gz #在磁盘上创建一个压缩了的光盘iso镜像文件 mkisofs -J -allow-leading-dots -R -V &#34;Label CD&#34; -iso-level 4 -o ./cd.iso data_cd #创建一个目录的iso镜像文件 cdrecord -v dev=/dev/cdrom cd.iso #刻录一个ISO镜像文件 gzip -dc cd_iso.gz | cdrecord dev=/dev/cdrom - #刻录一个压缩了的ISO镜像文件 mount -o loop cd.iso /mnt/iso #挂载一个ISO镜像文件 cd-paranoia -B #从一个CD光盘转录音轨到 wav 文件中 cd-paranoia -- &#34;-3&#34; #从一个CD光盘转录音轨到 wav 文件中（参数-3） cdrecord --scanbus #扫描总线以识别scsi通道 dd if=/dev/hdc | md5sum #校验一个设备的md5sum编码，例如一张 CD 网络 - （以太网和WIFI无线） ifconfig eth0 #显示一个以太网卡的配置 ifup eth0 #启用一个 &#39;eth0&#39; 网络设备 ifdown eth0 #禁用一个 &#39;eth0&#39; 网络设备 ifconfig eth0 192.168.1.1 netmask 255.255.255.0 #控制IP地址 ifconfig eth0 promisc #设置 &#39;eth0&#39; 成混杂模式以嗅探数据包 (sniffing) dhclient eth0 #以dhcp模式启用 &#39;eth0&#39; route -n #查看路由表 route add -net 0/0 gw IP_Gateway #配置默认网关 route add -net 192.168.0.0 netmask 255.255.0.0 gw 192.168.1.1 #配置静态路由到达网络&#39;192.168.0.0/16&#39; route del 0/0 gw IP_gateway #删除静态路由 hostname #查看机器名 host www.example.com #把一个主机名解析到一个网际地址或把一个网际地址解析到一个主机名。 nslookup www.example.com #用于查询DNS的记录，查看域名解析是否正常，在网络故障的时候用来诊断网络问题。 ip link show #查看网卡信息 mii-tool #用于查看、管理介质的网络接口的状态 ethtool #用于查询和设置网卡配置 netstat -tupl #用于显示TCP/UDP的状态信息 tcpdump tcp port 80 #显示所有http协议的流量 JPS工具 jps(Java Virtual Machine Process Status Tool)是JDK 1.5提供的一个显示当前所有java进程pid的命令，简单实用，非常适合在linux/unix平台上简单察看当前java进程的一些简单情况。
我想很多人都是用过unix系统里的ps命令，这个命令主要是用来显示当前系统的进程情况，有哪些进程，及其 id。jps 也是一样，它的作用是显示当前系统的java进程情况，及其id号。我们可以通过它来查看我们到底启动了几个java进程（因为每一个java程序都会独占一个java虚拟机实例），和他们的进程号（为下面几个程序做准备），并可通过opt来查看这些进程的详细启动参数。
**使用方法：**在当前命令行下打 jps(需要JAVA_HOME，没有的话，到改程序的目录下打) 。
jps存放在JAVA_HOME/bin/jps，使用时为了方便请将JAVA_HOME/bin/加入到Path. $&gt; jps 23991 Jps 23789 BossMain 23651 Resin 比较常用的参数： #-q 只显示pid，不显示class名称,jar文件名和传递给main 方法的参数 $&gt; jps -q 28680 23789 23651 #-m 输出传递给main 方法的参数，在嵌入式jvm上可能是null $&gt; jps -m 28715 Jps -m 23789 BossMain 23651 Resin -socketwait 32768 -stdout /data/aoxj/resin/log/stdout.log -stderr /data/aoxj/resin/log/stderr.log #-l 输出应用程序main class的完整package名 或者 应用程序的jar文件完整路径名 $&gt; jps -l 28729 sun.tools.jps.Jps 23789 com.asiainfo.aimc.bossbi.BossMain 23651 com.caucho.server.resin.Resin #-v 输出传递给JVM的参数 $&gt; jps -v 23789 BossMain 28802 Jps -Denv.class.path=/data/aoxj/bossbi/twsecurity/java/trustwork140.jar:/data/aoxj/bossbi/twsecurity/java/:/data/aoxj/bossbi/twsecurity/java/twcmcc.jar:/data/aoxj/jdk15/lib/rt.jar:/data/aoxj/jd k15/lib/tools.jar -Dapplication.home=/data/aoxj/jdk15 -Xms8m 23651 Resin -Xss1m -Dresin.home=/data/aoxj/resin -Dserver.root=/data/aoxj/resin -Djava.util.logging.manager=com.caucho.log.LogManagerImpl - Djavax.management.builder.initial=com.caucho.jmx.MBeanServerBuilderImpl jps 192.168.0.77 #列出远程服务器192.168.0.77机器所有的jvm实例，采用rmi协议，默认连接端口为1099（前提是远程服务器提供jstatd服务） #注：jps命令有个地方很不好，似乎只能显示当前用户的java进程，要显示其他用户的还是只能用unix/linux的ps命令 ]]></content></entry><entry><title>Linux创建守护进程</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux%E5%88%9B%E5%BB%BA%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">在 /etc/systemd/system/ 下新建并编辑 xxx.service 文件
这里以 code-server.service 为例
sudo vim /etc/systemd/system/code-server.service 写入下面的内容并根据自己创建的服务进行更改(带注释的为选填，看服务的需求开启)
[Unit] Description=code-server #描述要启动的进程 After=network.target [Service] Type=simple #WorkingDirectory=/root/workDir #启动进程的文件夹 #User=root #你想用什么用户启动该进程 #Group=root #你希望用什么用户组启动该进程 Restart=on-failure #进程错误时重启 RestartSec=10 ExecStart=/usr/bin/code-server#启动命，要用绝对路径，否则会报错 [Install] WantedBy=multi-user.target systemctl daemon-reload</content></entry><entry><title>Linux磁盘分区、格式化、挂载</title><url>/posts/linux%E6%93%8D%E4%BD%9C/%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%8C%82%E8%BD%BD/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html">一、插入U盘或者移动硬盘 1、若是一块新的移动硬盘，则需要对它进行分区和格式化 使用df -h可以查看当前系统中详细的存储设备挂载情况。
使用sudo fdisk -l可以查看磁盘分区情况
1.1进入fdisk操作模式，对磁盘进行分区 通过指令sudo fdisk /dev/sd*我们可以进入对应磁盘的fdisk操作模式，我们可以输入m来获取如下的帮助列表，并选择对应的功能进行后续操作。
Help: DOS (MBR) a toggle a bootable flag # 切换可引导的标识 b edit nested BSD disklabel # 编辑bsd磁盘标识 c toggle the dos compatibility flag # 切换dos兼容性标识 Generic d delete a partition # 删除磁盘分区 F list free unpartitioned space # 列出可用未分区空间 l list known partition types # 列出已知分区类型 n add a new partition # 添加一个新的分区 p print the partition table # 打印分区表 t change a partition type # 更改分区类型 v verify the partition table # 校验分区表 i print information about a partition # 打印有关分区的信息 Misc m print this menu # 打印help u change display/entry units # 改变 显示/接入 单元 x extra functionality (experts only) # 额外功能(仅限专家) Script I load disk layout from sfdisk script file # 从sfdisk脚本文件加载磁盘布局 O dump disk layout to sfdisk script file # 将磁盘布局转储到sfdisk脚本文件 Save &amp;amp; Exit w write table to disk and exit # 保存并退出 q quit without saving changes # 退出不保存 Create a new label g create a new empty GPT partition table # 创建一个新的gpt分区 G create a new empty SGI (IRIX) partition table o create a new empty DOS partition table s create a new empty Sun partition table 常用的就 n p w
1.2 对新分区进行格式化操作 有两种格式化方法：
sudo mkfs -t ext4 /dev/sda1 # 或者 sudo mkfs.ext4 /dev/sda1 # xfs文件系统 sudo mkfs -t xfs /dev/sdb1 sudo mkfs.xfs /dev/sdb1 1.3 磁盘挂载 sudo mount /dev/sda1 /data # 卸载命令 sudo umount /dev/sda1 最后通过df -h查看挂载情况
可以看到/dev/sda1已经挂载成功
1.4 设置磁盘的开机自动挂载 首先我们需要获取新的磁盘的UUID：
sudo blkid /dev/sda1 然后把UUID和相关信息按照格式写到/etc/fstab里面，主要增加UUID，挂载位置，FS格式这三点，之后保存即可。
sudo vim /etc/fstab</content></entry><entry><title>Linux磁盘清理</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux-%E7%A3%81%E7%9B%98%E6%B8%85%E7%90%86/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">1. 查看磁盘信息 df -lh 我们可以看见Filesystem下的挂载点 /dev/vda1 下的8.4G容量已经耗尽。接下来就是删除占用磁盘空间大，但又无用的文件。
2. 定位最大文件目录 cd / #寻找当前目录，哪个文件夹占用空间最大 du -h --max-depth=1 可以看到 /var 此路径占用较大磁盘空间，占用了6G。
重复上面的步骤，定位到最后的目录
可以看到 /log 此路径占用较大磁盘空间，占用了5.8G。
3. 定位最大文件 进入/log目录，查看里面的文件情况
可以看到里面有几个G的系统文件，查看之后再确认是否删除
4. 删除文件 rm -f messages*</content></entry><entry><title>Linux搭建Socks5代理</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/linux%E6%90%AD%E5%BB%BAsocks5%E4%BB%A3%E7%90%86/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>代理</tag></tags><content type="html"><![CDATA[ 说明： Socks5属于明文代理，可用于正常的跳板使用； 比如SSH转发加速国外VPS的连接速度，特别是一些延迟高或者丢包高的VPS； 使用Socks5转发后SSH就可以快速稳定的连接了，解决高丢包SSH断开的问题
项目地址： https://github.com/Lozy/danted 1. 安装 wget https://raw.githubusercontent.com/Lozy/danted/blob/master/install.sh # bash install.sh --port=端口 --user=用户名 --passwd=密码 bash install.sh --port=5566 --user=colzry --passwd=colzry_admin 下载不了的话可以直接写入下面的内容
#!/bin/bash # # Dante Socks5 Server AutoInstall # -- Owner: https://www.inet.no/dante # -- Provider: https://sockd.info # -- Author: Lozy # # Check if user is root if [ $(id -u) != &#34;0&#34; ]; then echo &#34;Error: You must be root to run this script, please use root to install&#34; exit 1 fi REQUEST_SERVER=&#34;https://raw.github.com/Lozy/danted/master&#34; SCRIPT_SERVER=&#34;https://public.sockd.info&#34; SYSTEM_RECOGNIZE=&#34;&#34; [ &#34;$1&#34; == &#34;--no-github&#34; ] &amp;&amp; REQUEST_SERVER=${SCRIPT_SERVER} if [ -s &#34;/etc/os-release&#34; ];then os_name=$(sed -n &#39;s/PRETTY_NAME=&#34;\(.*\)&#34;/\1/p&#39; /etc/os-release) if [ -n &#34;$(echo ${os_name} | grep -Ei &#39;Debian|Ubuntu&#39; )&#34; ];then printf &#34;Current OS: %s\n&#34; &#34;${os_name}&#34; SYSTEM_RECOGNIZE=&#34;debian&#34; elif [ -n &#34;$(echo ${os_name} | grep -Ei &#39;CentOS&#39;)&#34; ];then printf &#34;Current OS: %s\n&#34; &#34;${os_name}&#34; SYSTEM_RECOGNIZE=&#34;centos&#34; else printf &#34;Current OS: %s is not support.\n&#34; &#34;${os_name}&#34; fi elif [ -s &#34;/etc/issue&#34; ];then if [ -n &#34;$(grep -Ei &#39;CentOS&#39; /etc/issue)&#34; ];then printf &#34;Current OS: %s\n&#34; &#34;$(grep -Ei &#39;CentOS&#39; /etc/issue)&#34; SYSTEM_RECOGNIZE=&#34;centos&#34; else printf &#34;+++++++++++++++++++++++\n&#34; cat /etc/issue printf &#34;+++++++++++++++++++++++\n&#34; printf &#34;[Error] Current OS: is not available to support.\n&#34; fi else printf &#34;[Error] (/etc/os-release) OR (/etc/issue) not exist!\n&#34; printf &#34;[Error] Current OS: is not available to support.\n&#34; fi if [ -n &#34;$SYSTEM_RECOGNIZE&#34; ];then wget -qO- --no-check-certificate ${REQUEST_SERVER}/install_${SYSTEM_RECOGNIZE}.sh | \ bash -s -- $* else printf &#34;[Error] Installing terminated&#34; exit 1 fi exit 0 2. 服务端使用 卸载
bash install.sh --uninstall 增加用户
/etc/init.d/sockd adduser USERNAME PASSWORD command option description service sockd start /etc/init.d/sockd start start socks5 server daemon service sockd stop /etc/init.d/sockd stop stop socks5 server daemon service sockd restart /etc/init.d/sockd restart restart socks5 server daemon service sockd reload /etc/init.d/sockd reload reload socks5 server daemon service sockd status systemd process status service sockd state /etc/init.d/sockd state running state service sockd tail /etc/init.d/sockd tail sock log tail service sockd adduser /etc/init.d/sockd adduser add pam-auth user: service sockd adduser NAME PASSWORD service sockd deluser /etc/init.d/sockd deluser delete pam-auth user: service sockd deluser NAME 3. 客户端使用 proxychanins中使用（推荐）
vim /etc/proxychains.conf socks5 43.142.174.216 5566 colzry colzry_admin |-&gt;ip |-&gt;端口 |-&gt;用户名 |-&gt;密码 使用系统导出代理（不推荐）
export ALL_PROXY=socks5://colzry:colzry_admin@43.142.174.216:5566 # 取消代理 unset ALL_PROXY ]]></content></entry><entry><title>Linux搭建WebDav服务</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/linux%E6%90%AD%E5%BB%BAwebdav%E6%9C%8D%E5%8A%A1/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>WebDav</tag></tags><content type="html">WebDav Server WebDAV 是 GitHub 上开源的项目，基于 Go 语言实现，不仅跨平台，还支持 ARM 架构，可在㠌入式设备中部署 WebDAV 服务器。 项目地址： https://github.com/hacdias/webdav GitHub 下载对应的架构 WebDAV，解压后获得 webdav二进制文件
1. 解压 tar -zxvf linux-amd64-webdav.tar.gz mv webdav /usr/bin/ 2. 编写配置文件 vim /opt/webdav_config.yaml # Server related settings address: 0.0.0.0 port: 10105 # 如果无需验证填 false auth: true # 如果不需要 https 则填 false tls: false # https证书和密钥，如果 tls 为 false，cert 和 key 不需要 # cert: /data/www/cert/szhome.xf1024.com_nginx/cert.pem # key: /data/www/cert/szhome.xf1024.com_nginx/cert.key # 访问前缀，建议默认 prefix: / debug: false # 如果 auth 为 false 生效，文件共享的路径 scope: . modify: true rules: [] # 跨域设置 cors: enabled: true credentials: true allowed_headers: - Depth allowed_hosts: - http://localhost:10105 allowed_methods: - GET exposed_headers: - Content-Length - Content-Range # 用户信息，如果 auth 为 true 生效 users: - username: Colzry password: webdav_colzry scope: /mnt/hhd01/back/Video/ # 是否允许修改 modify: true - username: other_user password: xxxxx scope: /data/1/Video modify: true 使用命令
/usr/bin/webdav -c /opt/webdav_config.yaml 3. 添加守护进程 vim /usr/lib/systemd/system/webdav.service [Unit] Description=WebDAV server After=network.target [Service] Type=simple User=root ExecStart=/usr/bin/webdav -c /opt/webdav_config.yaml Restart=on-failure [Install] WantedBy=multi-user.target systemctl daemon-reload systemctl start webdav.service systemctl status webdav.service systemctl enable webdav.service 4. Linux 挂载 sudo apt install davfs2 sudo mount -t davfs http://192.168.5.254:10105/ /webdav 5. Nginx 开启 WebDAV 在Nginx中实现WebDAV需要安装 libnginx-mod-http-dav-ext 模块，以下是Nginx的配置：
server { listen 80; listen [::]:80; server_name dav.engr-z.com; location / { root /data/webdav; client_body_temp_path /var/temp; dav_methods PUT DELETE MKCOL COPY MOVE; dav_ext_methods PROPFIND OPTIONS; create_full_put_path on; client_max_body_size 10G; } } server { listen 443; listen [::]:443; server_name dav.engr-z.com; ssl on; ssl_certificate /data/www/cert/dav.engr-z.com_nginx/cert.pem; ssl_certificate_key /data/www/cert/dav.engr-z.com_nginx/cert.key; ssl_session_timeout 5m; ssl_protocols SSLv2 SSLv3 TLSv1; ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; ssl_prefer_server_ciphers on; location / { root /data/webdav; client_body_temp_path /var/temp; dav_methods PUT DELETE MKCOL COPY MOVE; dav_ext_methods PROPFIND OPTIONS; create_full_put_path on; client_max_body_size 10G; } }</content></entry><entry><title>Linux防火墙和Cockpit</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux%E9%98%B2%E7%81%AB%E5%A2%99%E5%92%8Ccockpit/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[1. firewall (RedHat系列) # 查看状态 firewall-cmd --state # 开启防火墙 systemctl start firewalld.service # 关闭并禁用防火墙 systemctl stop firewalld.service systemctl disable firewalld.service # 关闭SElinux 该为disable vim /etc/selinux/config # 开放端口 firewall-cmd --zone=public --add-port=8080/tcp --permanent firewall-cmd --reload # 关闭端口 firewall-cmd --zone=public --remove-port=8080/tcp --permanent firewall-cmd --reload # 查看以开放的端口 firewall-cmd --list-ports # 更新防火墙规则 firewall-cmd --reload 2. ufw (Ubuntu) # 查看状态 ufw status 3. Cockpit安装 dnf install cockpit cockpit-dashboard / cockpit-storaged cockpit-packagekit -y # 也可以安装其它的扩展包 dnf list cockpit* -------------------------- cockpit-bridge.x86_64 cockpit-composer.noarch cockpit-doc.noarch cockpit-machines.noarch cockpit-packagekit.noarch cockpit-pcp.x86_64 cockpit-podman.noarch cockpit-session-recording.noarch cockpit-storaged.noarch cockpit-system.noarch cockpit-ws.x86_64 -------------------------- # 启动cockpit并设为开启自启动 systemctl enable --now cockpit.socket / &amp;&amp; systemctl list-unit-files | grep cockpit / &amp;&amp; systemctl start cockpit # 有防火墙的话，记得开放 firewall-cmd --permanent --zone=public --add-service=cockpit firewall-cmd --reload 之后访问本机9090端口 ]]></content></entry><entry><title>Linux科学代理</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/linux-%E7%A7%91%E5%AD%A6%E4%BB%A3%E7%90%86/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>代理</tag></tags><content type="html"><![CDATA[官方文档： https://v2raya.org/docs/prologue/quick-start/ 安装v2ray内核，使用镜像脚本（不通过添加软件源安装）
# v2rayA 提供的镜像脚本 curl -Ls https://mirrors.v2raya.org/go.sh | sudo bash # 安装后可以关掉服务，因为 v2rayA 不依赖于该 systemd 服务 sudo systemctl disable v2ray --now 1. 安装 1.1 Fedora # 添加 copr 源 sudo dnf copr enable zhullyb/v2rayA # 安装 V2Ray 内核 sudo dnf install v2ray-core # 安装 v2rayA sudo dnf install v2raya # 启动 sudo systemctl start v2raya.service # 设置开机自启 sudo systemctl enable v2raya.service 1.2 Debian 请先通过顶上的方法安装v2ray内核
# 添加公钥 wget -qO - https://apt.v2raya.org/key/public-key.asc | sudo tee /etc/apt/trusted.gpg.d/v2raya.asc # 添加 V2RayA 软件源 echo &#34;deb https://apt.v2raya.org/ v2raya main&#34; | sudo tee /etc/apt/sources.list.d/v2raya.list sudo apt update # 安装 V2RayA sudo apt install v2raya # 启动 sudo systemctl start v2raya.service # 设置开机自启 sudo systemctl enable v2raya.service 切换 iptables 为 iptables-nft 对于 Debian11 用户来说，iptables 已被弃用。使用 nftables 作为 iptables 的后端以进行适配
update-alternatives --set iptables /usr/sbin/iptables-nft update-alternatives --set ip6tables /usr/sbin/ip6tables-nft update-alternatives --set arptables /usr/sbin/arptables-nft update-alternatives --set ebtables /usr/sbin/ebtables-nft 如果你想切换回 legacy 版本
update-alternatives --set iptables /usr/sbin/iptables-legacy update-alternatives --set ip6tables /usr/sbin/ip6tables-legacy update-alternatives --set arptables /usr/sbin/arptables-legacy update-alternatives --set ebtables /usr/sbin/ebtables-legacy 切换后重启即可
2. 使用 通过 2017 端口 如 http://localhost:2017 访问 UI 界面 记得调整防火墙
2.1 创建管理员账号 2.2 导入节点 vmess://ew0KICAidiI6ICIyIiwNCiAgInBzIjogIlZtZXNzIiwNCiAgImFkZCI6ICJwYW4uZ29zc2lwLnRrIiwNCiAgInBvcnQiOiAiNDQzIiwNCiAgImlkIjogIjcyNTQ0Nzk0LTRhYWUtNGVmNy1jMmRhLTUxOTRjN2RkOGI4NSIsDQogICJhaWQiOiAiMCIsDQogICJzY3kiOiAiYXV0byIsDQogICJuZXQiOiAid3MiLA0KICAidHlwZSI6ICJub25lIiwNCiAgImhvc3QiOiAicGFuLmdvc3NpcC50ayIsDQogICJwYXRoIjogIi9nb2ZpYyIsDQogICJ0bHMiOiAidGxzIiwNCiAgInNuaSI6ICIiLA0KICAiYWxwbiI6ICIiDQp9 2.3 启动 2.4 设置 2.5 开放代理端口 2.6 设置Linux代理 export ALL_PROXY=socks5://127.0.0.1:20170 # 取消代理 unset ALL_PROXY 2.7 使用proxychains设置代理（推荐） 安装
# Fedora sudo dnf install proxychains-ng # Debian sudo apt install proxychains-ng 配置
vim /etc/proxychains.conf socks5 127.0.0.1 20170 测试一下
[root@fedora ~]# proxychains curl cip.cc [proxychains] config file found: /etc/proxychains.conf [proxychains] preloading /usr/lib64/proxychains-ng/libproxychains4.so [proxychains] DLL init: proxychains-ng 4.16 [proxychains] Strict chain ... 127.0.0.1:20170 ... cip.cc:80 ... OK IP : 198.23.149.5 地址 : 美国 华盛顿州 西雅图 运营商 : colocrossing.com 数据二 : 美国 | 纽约州伊利县威廉斯维尔村ColoCrossing有限公司 数据三 : 美国华盛顿西雅图 URL : http://www.cip.cc/198.23.149.5 简化使用命令
echo &#34;alias pc=&#39;proxychains&#39;&#34; &gt;&gt; ~/.bashrc source ~/.bashrc [root@fedora ~]# pc curl cip.cc [proxychains] config file found: /etc/proxychains.conf [proxychains] preloading /usr/lib64/proxychains-ng/libproxychains4.so [proxychains] DLL init: proxychains-ng 4.16 [proxychains] Strict chain ... 192.168.211.99:20170 ... 122.51.162.249:80 ... OK IP : 198.23.149.5 地址 : 美国 华盛顿州 西雅图 运营商 : colocrossing.com 数据二 : 美国 | 纽约州伊利县威廉斯维尔村ColoCrossing有限公司 数据三 : 美国华盛顿西雅图 URL : http://www.cip.cc/198.23.149.5 2.8 设置局域网使用 3. 浏览器代理 SwitchyOmega 等浏览器插件可为浏览器提供代理服务。 ]]></content></entry><entry><title>Linux配置环境变量的建议</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux-%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%9A%84%E5%BB%BA%E8%AE%AE/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"> 若是普通用户，则在自己用户目录的.bashrc中配置，若使用了zsh，则在.zshrc中配置
若是root用户，则在/etc/profile.d/中新建一个my_env.sh文件
最后普通用户(source)刷新.bashrc或.zshrc文件，root用户刷新/etc/profile文件
其中$PAHT表示系统的环境变量，: 表示拼接在系统环境变量$PAHT之后
eg: root用户下的my_env.sh文件 #JAVA_HOME export JAVA_HOME=/opt/module/jdk1.8.0_212 export PATH=$PATH:$JAVA_HOME/bin #HADOOP_HOME export HADOOP_HOME=/opt/module/hadoop-3.1.3 export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin source /etc/profile 普通用户的.zshrc文件 export PATH=/home/colzry/.local/bin/:$PATH source .zshrc 最后 /etc/environment也可以更改，改完之后注销即可 或者执行下面语句
PATH=&amp;#34;$PATH&amp;#34;</content></entry><entry><title>Linux软件批量卸载</title><url>/posts/linux%E6%93%8D%E4%BD%9C/%E6%89%B9%E9%87%8F%E5%8D%B8%E8%BD%BD/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html">rpm -e `rpm -qa | grep python`</content></entry><entry><title>Linux设置静态IP</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux%E8%AE%BE%E7%BD%AE%E9%9D%99%E6%80%81ip/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>静态IP</tag></tags><content type="html"><![CDATA[Centos 编辑em1对应的配置文件，位于/etc/sysconfig/network-scripts/ifcfg-你的网卡名字 vim /etc/sysconfig/network-scripts/ifcfg-eth0 主要修改BOOTPROTO, IPADDR, NETMASK, GATEWAY也就是带注释的内容
# Generated by dracut initrd NAME=&#34;eth0&#34; HWADDR=&#34;52:54:00:e1:fa:43&#34; ONBOOT=yes NETBOOT=yes UUID=&#34;d30acbe4-f24c-40d2-be6a-f474d8b7d3f2&#34; IPV6INIT=yes BOOTPROTO=&#34;static&#34; # 使用静态IP，默认为dhcp IPADDR=&#34;192.168.0.100&#34; # 静态IP NETMASK=&#34;255.255.255.0&#34; # 子网掩码 GATEWAY=&#34;192.168.0.1&#34; # 网关 TYPE=Ethernet 保存后重启网络服务
service network restart Almalinux vim /etc/NetworkManager/system-connections/ens18.nmconnection nmcli c reload nmcli c down ens18 &amp;&amp; nmcli c up ens18 Debian 首选备份原始的网络配置文件，
sudo cp /etc/network/interfaces /etc/network/interfacesbak 编辑文件 /etc/network/interfaces，内容如下：
auto lo auto eth0 # 设置开机自动连接网络 iface lo inet loopback allow-hotplug eth0 iface eth0 inet static # static表示使用固定IP地址上网，dhcp表示使用动态ip address 192.168.9.100 # 设置静态ip地址 netmask 255.255.255.0 # 子网掩码 gateway 192.168.9.254 # 网关 保存后重启网络服务
service networking restart Ubuntu 更改/etc/netplan/*.yaml下的yaml文件
vim /etc/netplan/00-installer-config.yaml # This is the network config written by &#39;subiquity&#39; network: ethernets: enp1s0: dhcp4: no # 关闭dhcp addresses: [192.168.0.200/24] # 设置IP和掩码 gateway4: 192.168.0.1 # 网关 nameservers: # 设置DNS addresses: [192.168.0.1, 114.114.114.114] version: 2 保存后使用netplan命令应用最近的网络更改
netplan apply ]]></content></entry><entry><title>Linux输入输出重定向</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%87%8D%E5%AE%9A%E5%90%91/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[说明 0 标准输入 1 标准输出 2 标准错误 下面命令表示把输出结果重定向到file文件中，而错误重定向到标准输出，此时的标准输出为重定向到file文件中，所以错误也会输出到file文件中
command &gt; file 2&gt;&amp;1 解释 何2&gt;&amp;1要写在后面？
command &gt; file 2&gt;&amp;1
首先是command &gt; file将标准输出重定向到file中， 2&gt;&amp;1 是标准错误拷贝了标准输出的行为，也就是同样被重定向到file中，最终结果就是标准输出和错误都被重定向到file中。
command 2&gt;&amp;1 &gt;file
2&gt;&amp;1 标准错误拷贝了标准输出的行为，但此时标准输出还是在终端。&gt;file 后输出才被重定向到file，但标准错误仍然保持在终端。
用strace可以看到：
command &gt; file 2&gt;&amp;1 这个命令中实现重定向的关键系统调用序列是：
open(file) == 3
dup2(3,1)
dup2(1,2)
command 2&gt;&amp;1 &gt;file 这个命令中实现重定向的关键系统调用序列是：
dup2(1,2)
open(file) == 3
dup2(3,1)
为什么会有&amp;
当没有&amp;时，1会被认为是一个普通的文件，有&amp;表示重定向的目标不是一个文件，而是一个文件描述符。
为什么有&amp;1而没有&amp;2
2&gt;是一个整体，表示标准错误输出重定向，重定向至&amp;1，即标准输出，&amp;1是一个文件
常用命令 挂入后台命令
# 普通 断开终端就停止 command &gt;/dev/null 2&gt;&amp;1 &amp; # 高级 断开终端不停止 nohup command &gt;/dev/null 2&gt;&amp;1 &amp; # 或者 nohup command &gt;&amp; /dev/null &amp; 其他写法 command &gt; file 2&gt;&amp;1 等价写法 command &gt;&amp; file command &amp;&gt; file ]]></content></entry><entry><title>Linux文件恢复</title><url>/posts/linux%E6%93%8D%E4%BD%9C/%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html"> https://bbs.huaweicloud.com/blogs/345168 dd命令 https://blog.csdn.net/hezhanran/article/details/122662675 文件测速
hdparm -t /dev/sdxx</content></entry><entry><title>Linux文件拷贝</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux%E6%96%87%E4%BB%B6%E6%8B%B7%E8%B4%9D/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[scp 推送 scp -r 文件名 目标用户@主机名(host):目标目录 [colzry@hadoop102 ~]$ cd /opt/module/ [colzry@hadoop102 module]$ pwd /opt/module [colzry@hadoop102 module]$ ll 总用量 0 drwxr-xr-x. 9 colzry root 149 9月 12 2019 hadoop-3.1.3 drwxr-xr-x. 7 colzry root 245 4月 2 2019 jdk1.8.0_212 [colzry@hadoop102 module]$ scp -r jdk1.8.0_212/ colzry@hadoop103:/opt/module/ 拉取 scp -r 目标用户@主机名(host):目标目录 放置目录 [colzry@hadoop103 module]$ scp -r colzry@hadoop102:/opt/module/hadoop-3.1.3 ./ 中转 scp -r 目标用户@主机名(host):目标目录 目标用户@主机名(host):目标目录 [colzry@hadoop103 module]$ scp -r colzry@hadoop102:/opt/module/* colzry@hadoop104:/opt/module/ rsync(推荐使用) rsync -av 文件名 目标用户@主机名(host):目标目录 rsync -av 目标用户@主机名(host):目标目录 目标目录 rsync -av 目标用户@主机名(host):目标目录 目标用户@主机名(host):目标目录 集群分发脚本 #!/bin/bash #1. 判断参数个数 if [ $# -lt 1 ] then echo Not Enough Arguement! exit; fi #2. 遍历集群所有机器 for host in hadoop102 hadoop103 hadoop104 do echo ==================== $host ==================== #3. 遍历所有目录，挨个发送 for file in $@ do #4. 判断文件是否存在 if [ -e $file ] then #5. 获取父目录 pdir=$(cd -P $(dirname $file); pwd) #6. 获取当前文件的名称 fname=$(basename $file) ssh $host &#34;mkdir -p $pdir&#34; rsync -av $pdir/$fname $host:$pdir else echo $file does not exists! fi done done 使用方法 cd ~ mkdir bin vim xsync // 填入上面脚本内容 chmod 777 xsync xsync /etc/profile.d/my_env.sh 集群状态查看脚本 #!/bin/bash # 获取控制台指令 # 判断指令是否为空 if [ $# -lt 1 ] then echo &#34;command can not be null !&#34; exit fi # 获取当前登录用户 user=`whoami` source /etc/profile # 在从机执行指令,这里需要根据你具体的集群情况配置，host与具体主机名一致 for host in hadoop101 hadoop102 hadoop103 do echo ================ $host================= ssh $user@$host $@ done echo =========================================== 使用方法 cd ~ mkdir bin vim xcall // 填入上面脚本内容 chmod 777 xcall xcall jps ]]></content></entry><entry><title>Linux用户的管理</title><url>/posts/linux%E6%93%8D%E4%BD%9C/linux-%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag></tags><content type="html"><![CDATA[Linux 用户管理 一.用户管理命令 通过系统中的命令对用户进行相应的操作。在讲解命令之前，我们需要了解，在linux操作系统中，以下的几个概念：
UID：用户ID号，用户的唯一标识号，就相当于一个人的身份证号。 所属用户组：在linux操作系统中，一个用户必须有它的用户组，如果不给新用户指定用户组，那么该会默认创建一个与用户名相同的组。 GID：用户组的ID号。 家目录:与Windows系统相同，可理解为一个用户的用户文件夹，所有用户的家目录默认被创建在 /home 目录下。相当于Windows操作系统中的 C:/Users 目录。 1.1 创建用户 通过 useradd 命令来创建新的用户。
语法格式： useradd [参数] &lt;用户名&gt;
常用参数：
参数 作用 -u 指定用户UID -d 指定用户家目录位置 -c 添加用户说明/备注 -g 指定用户初始所属的用户组 -G 指定用户所属附加组 -s 指定用户登录的shell解释器 操作演示：
添加新用户 xiaobei
[root@localhost ~]# useradd xiaobei 添加新用户 test01 并且指定其家目录为 /test/test01
[root@localhost ~]# useradd -d /test/test01 test01 添加新用户 test01 并且指定ID为6666
[root@localhost ~]# useradd -u 6666 test01 添加新用户 test01 并且指定其所属组为root，并设置其登录shell为nologin
[root@localhost ~]# useradd -g root -s /sbin/nologin test01 1.2 设置密码 通过passwd命令来设置当前登录用户(自身)或者其他用户的密码。该命令如果不加用户名，即代表对当前登录的用户进行操作。不加参数，代表设置密码。这里我们需要知道，通常创建用户都是root来做的，所以设置密码也都是root用户身份来进行设置。如果是普通用户想设置root用户的密码，怎么办呢？不是不可以，只是该普通用户必须拥有sudo权限。本文我们只需要理解可以这么做就好。
语法格式： passwd [参数] [用户名]
常用参数：
参数 作用 -d 删除密码 -S 查询用户密码的状态 -l 锁定用户密码 -u 解锁用户密码 操作演示：
设置当前登录用户的密码：
[root@localhost ~]# passwd 设置用户xiaobei的密码
[root@localhost ~]# passwd xiaobei 清除用户 xiaobei 的密码
[root@localhost ~]# passwd -d xiaobei 1.3 查看当前登录用户 使用命令who 与 w 命令可以查询当前系统上已登录用户的相关信息。
语法格式： who [参数]
常用参数：
参数 作用 -a 打印全面信息 -b 打印系统最近引导时间 -H 带有列名打印信息 -u 打印已登录用户列表 操作演示： 输出当前已登录的用户信息(带列名打印)
[root@localhost ~]# who -H 名称 线路 时间 备注 root pts/0 2020-12-30 16:16 (192.168.3.8) 123 注释：线路列表中的 pts/0 ，pts代表远程终端登录，如果输出了 tty1，则tty代表本地终端登录。
语法格式： w [参数]
常用参数：
参数 作用 -h 不带列名输出 -s 使用短格式输出 操作演示： 输出当前已登录用户信息(带列名输出)
[root@localhost ~]# w USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 192.168.3.8 16:16 0.00s 0.46s 0.01s w 123 注释：LOGIN@ 代表登录时间，IDLE表示空闲时间，JCPU是与该终端连接的进程占用的时间，PCPU 是用户当前进程所占用的时间。
1.4 修改用户属性 使用usermod命令，可以修改用户相关属性和信息。
语法格式： usermod [参数] &lt;用户名&gt;
常用参数：
参数 作用 -u 修改用户UID -c 修改用户的说明/备注 -g 修改用户的所属用户组 -G 修改用户的附加组 -L 锁定用户密码 -U 解锁用户密码 -s 修改用户的登录shell 操作演示：
设置用户xiaobei的登录shell为nologin 使其无法登录
[root@localhost ~]# usermod -s /sbin/nologin xiaobei 1.5 用户密码有效性 使用chage命令修改用户和用户密码的有效期限，这个信息由系统用于确定用户何时必须更改其密码。
语法格式： chage [参数] [用户名]
常用参数：
参数 作用 -M 密码保持有效的最大天数 -W 用户密码到期前，提前收到警告信息的天数 -E 帐号到期的日期，会禁止此帐号 -d 上一次更改的日期 -l 显示用户的密码相关信息 操作演示：
使用户 xiaobei 的密码有效期最大为30天。
[root@localhost ~]# chage -M 30 xiaobei 1.6 删除用户 使用命令userdel删除用户。在删除之前确定用户没有登录。
语法格式： userdel [参数] [用户名]
常用参数：
参数 作用 -f 强制删除用户账号 -r 同时删除用户的家目录 操作演示： 删除用户 test01 同时删除该用户的家目录
[root@localhost ~]# userdel -r test01 1.7 切换登录用户 使用 su 命令切换当前登录用户。root 用户切换普通用户时不需要输入密码，反之需要。
语法格式： su [用户名]
常用参数：
参数 作用 -c 仅执行一次命令，不切换用户身份 操作演示：
切换到用户 xiaobei
[root@localhost ~]# su xiaobei 切换到用户 root 同时一起切换环境变量。
[xiaobei@localhost ~]$ su - root 用root用户执行一条命令 useradd
[xiaobei@localhost ~]$ su - root -c &#34;useradd test01&#34; 1.8 踢出当前登录中的用户 我们想对某用户进行删除操作的时候，发现该用户正在被登录，这个时候我们就可以用命令 pkill ，使该用户被迫下线。知晓linux系统的同仁应该会了解，该命令其实是一个杀死进程的命令。其实在这里可以踢出登录的用户，也是可以理解的，因为一个用户在系统上登录，是会产生对应的进程的。因为在本贴我们主讲用户管理，所以在这里只介绍这一种用法。
语法格式： pkill -9 -t &lt;终端号&gt;
操作演示：
踢出在远程终端 终端号为 pts/1 登录的用户。
[root@localhost ~]# pkill -9 -t pts/1 操作解释：
这里的 -9 参数，是linux系统中的kill信号，在这里我们只需要知道这条命令可以立即踢出一个用户即可。 参数 -t 代表指定终端号。前面我们讲到过，可以通过 w 命令和 who 命令查询当前都有哪些用户登录，这里就是要配合这两个命令使用的，我们需要知道要踢出的用户所登录的终端号，一般踢出的都是远程用户，所以基本都是pts开头，这两个查询命令都可以查到用户登录的终端号，这个时候再使用该命令按终端号踢出用户，该用户就会立即下线。
1.9 查询用户登录信息 在Linux系统中可以查询到所有用户的登录信息，以及系统上近期的登录信息，通过两个命令可以查询：lastlog 和 last。
语法格式： lastlog [参数]
常用参数：
参数 作用 -b 显示指定天数前的登录信息 -t 显示指定天数以来的登录信息 -u 显示指定用户的最后一次的登录信息 操作演示：
查询root用户最后一次的登录信息
[root@localhost ~]# lastlog -u root 查询UID为 1000 的用户最近7天有没有登录过(有就会输出信息)。
[root@localhost ~]# lastlog -t 7 -u 1000 使用last命令查看的是系统上的用户登录记录及信息，以时间排序。
语法格式： last [参数]
常用参数：
参数 作用 -R 简略输出(短格式) -n 指定最近几条记录 操作演示：
查询系统上最近的十条登录信息。
[root@localhost ~]# last -n 10 使用lastb命令查看的是系统上的用户登录失败的记录及信息
语法格式： lastb [参数]
常用参数：
参数 作用 -a 把从何处登入系统的主机名称或ip地址显示在最后一行 -n 设置列出名单的显示列数 -R 不显示登入系统的主机名称或IP地址 -x 显示系统关机，重新开机，以及执行等级的改变等信息 操作演示： 查询登录失败所有的信息
[root@localhost ~]#lastb 1.10 查询用户UID及GID信息 使用 id 命令可以查询用户的UID以及所属用户组的GID信息。
语法格式： id [参数] [用户名]
常用参数：
参数 作用 -r 显示实际ID -u 显示用户ID -g 显示用户所属群组的ID -G 显示用户所属附加群组的ID -n 显示用户，所属群组或附加群组的名称 操作演示：
查询用户 xiaobei 的所有ID的信息
[root@localhost ~]# id xiaobei 1.11 退出登录 使用命令 logout 退出登录。远程终端以及su命令登录的用户也可用 exit 退出。
二.用户组管理命令 在前面我们提到过，在创建新用户时，会同时创建一个与该用户同名的用户组。这是因为Linux中的用户，必须有一个所属组，如果在创建用户时指定一个所属组，就不会创建与其同名的组了。下面我们只简单介绍几个组管理的命令。
2.1 添加用户组 使用命令groupadd 添加用户组。
语法格式： groupadd [参数] &lt;组名&gt;
常用参数：
参数 作用 -g 创建的同时制定用户组ID 操作演示：
添加用户组 userg 并指定id为6666
[root@localhost ~]# groupadd -g 6666 userg 2.2 修改组属性 使用命令groupmod 修改用户组的信息。
语法格式： groupmod [参数] &lt;组名&gt;
常用参数：
参数 作用 -n 修改组名 -g 修改新的GUID 操作演示：
修改用户组 userg 组名为testgroup
[root@localhost ~]# groupmod testgroup userg 2.3 设置用户组 使用命令gpasswd 来设置组和组内成员
语法格式： gpasswd &lt;参数 &gt; &lt;组名&gt;
常用参数：
参数 作用 -a 添加用户到组 -d 从组删除用户 操作演示：
把用户 xiaobei 添加到 group01 用户组
[root@localhost ~]# gpasswd -a xiaobei group01 2.4 删除用户组 使用命令groupdel 来设置组和组内成员。如果组内有初始用户，则不能删除，如果组内有附加用户，也可以删除。
语法格式： groupdel [参数] &lt;组名&gt;
操作演示：
删除用户组 test01
[root@localhost ~]# groupdel test01 三.用户管理相关的配置文件 以上所有的用户管理、组管理命令，包括用户的添加、删除，密码的修改，有效期设置等命令的操作，均会保存在配置文件中，也就是命令的操作也就是修改配置文件。换一种说法，例如我们要修改某用户的密码有效期，除了可以使用命令，还可以直接修改Linux中记录用户信息的配置文件。都可以达到同样的效果。
3.1 用户信息配置文件 通过命令进行创建、修改用户以及相关操作，都是对配置文件/etc/passwd的修改。比如修改用户家目录，可以用命令 usermod 修改，也可以直接修改文件中的第六个字段。该文件除了记录普通用户的信息，也记录了系统用户的信息。切记，系统用户的信息不要轻易更改，否则进行某相关操作时，会导致系统错误。 通过命令 less /etc/passwd 或者 vim /etc/passwd 可以查看以及修改该配置文件。
文件概览： 字段对应信息：
1.用户名称：2.密码标志：3.UID：4.GID ：5.用户说明/备注：6.家目录：7.登录的shell
字段解释：
密码标志 x 代表该用户有密码。 UID中 0 代表超级用户，RedHat、CentOS系列的发行版中，1-499为系统用户(伪用户),通过配置文件可以看到它们的shell解释器都为nologin也就是不登录。500-65535为普通用户可用的UID。 用户的附加组可以有多个。
3.2 用户密码信息配置文件 在Linux系统中/etc/shadow文件存放用户密码信息，又称为“影子文件”。由于存放了密码信息，为了保证安全性，该文件只有root用户可以读取。
文件概览： 字段对应信息：
1.用户名称：2.加密密码：3.密码最后一次修改日期：4.两次密码的修改间隔：5.密码有效期：6.有效期到期前的警告天数：7.宽限天数：8.账号失效时间
字段解释：
加密密码采用了SHA512散列加密算法。如果该字段为 !! 或 * 就代表该用户不能登录。 该文件所有的日期格式均采用时间戳。 两次密码的修改间隔为天数，10 就代表修改过一次密码后十天内不能再次修改。
unix时间戳是从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数，不考虑闰秒。 Unix时间戳（英文为Unix epoch, Unix time, POSIX time 或 Unix timestamp） 是从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数，不考虑闰秒。 UNIX时间戳的0按照ISO 8601规范为 ：1970-01-01T00:00:00Z. 一个小时表示为UNIX时间戳格式为：3600秒；一天表示为UNIX时间戳为86400秒，闰秒不计算。 在大多数的UNIX系统中UNIX时间戳存储为32位，这样会引发2038年问题或Y2038。 &mdash;&mdash;&ndash; 百度百科
第七字段宽限天数，代表用户封禁前的缓冲天数，如果该值为3，就代表有效期过三天后再进行用户封禁。
3.3 创建用户默认配置信息文件 在创建用户时，我们可以手动指定家目录。如果不指定，就会默认把家目录放到/home目录下。如果我想让它默认创建到其他位置呢？我们就可以通过修改配置文件/etc/default/useradd文件来实现。
文件概览： 字段解释：
HOME字段控制创建用户时默认的家目录位置 INACTIVE为密码过期的宽限天数 SHELL创建用户默认的登录shell SKEL为家目录的模板目录 CREATE_MAIL_SPOOL是否建立邮箱 GROUP用户的默认组 EXPIRE密码失效时间
3.4 用户限制设定配置文件 在配置文件/etc/login.defs中，记录了用户限制设定。该文件的作用是为了对用户更为规范的管理，例如用户默认的密码有效期，就可以通过该文件进行修改，就是前面有讲到的chage命令相关的，不过该文件修改的是用户创建时的默认项，相当于一个模板文件。注意，该文件设置对用户root不生效。
文件概览： 部分字段解释： PASS_MAX_DAYS 默认密码有效期 UID_MIN UID的最小值 PASS_MIN_DAYS 两次密码修改的间隔。
四.组管理相关的配置文件 与用户管理相同，除了命令，也可以通过直接修改配置文件来达到对组的配置。
4.1 组信息配置文件 用户组的配置文件位置为/etc/group。
文件概览： 字段对应信息：
1.组名：2.组密码标志：3.GID：4.组中附加用户
4.2 组密码信息配置文件 组密码信息文件/etc/gshadow中存放着用户组的密码以及管理员用户名。
文件概览： 字段对应信息：
1.组名：2.组密码：3.组管理员用户名：4.组中附加用户
五. 快速创建示例 #查看用户信息 less /etc/passwd #查看组信息 less /etc/group #创建用户组 groupadd colzry #创建用户家目录 mkdir -p /home/colzry #创建用户 useradd -d /home/colzry -s /bin/bash colzry #设置用户密码 passwd colzry #用户家目录赋权755 chmod -R 755 /home/colzry #切换用户 su colzry #修改文件所属用户:组 chown -R colzry:colzry filename ]]></content></entry><entry><title>Maven快速入门</title><url>/posts/java/maven-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url><categories><category>Java</category></categories><tags><tag>Java</tag><tag>Maven</tag></tags><content type="html"><![CDATA[Maven的作用 项目的自动构建，帮助开发人员做项目代码的编译，测试， 打包，安装，部署等工作。 管理依赖（管理项目中使用的各种jar包）。 依赖：项目中需要使用的其他资源， 常见的是jar 。 比如项目要使用mysql驱动。我们就说项目依赖mysql驱动。 Maven 安装 确定JAVA_HOME 指定jdk的安装目录， 如果没有JAVA_HOME， 需要在windows的环境变量中创建JAVA_HOME, 它的值是jdk的安装目录 解压缩 apache-maven-3.3.9-bin.zip ，把解压后的文件放到一个目录中。 目录的路径不要有中文，不要有空格。 把maven安装目录中下的bin的路径添加到path中 测试maven的安装。 在命令行执行 mvn -v C:\Users\NING MEI&gt;mvn -v Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00) Maven home: D:\tools\apache-maven-3.3.9\bin\.. Java version: 1.8.0_101, vendor: Oracle Corporation Java home: C:\Program Files\Java\jdk1.8.0_101\jre Default locale: zh_CN, platform encoding: GBK OS name: &#34;windows 10&#34;, version: &#34;10.0&#34;, arch: &#34;amd64&#34;, family: &#34;dos&#34; maven解压后的目录结构 maven的其他安装方式：
确定JAVA_HOME是否有效 在环境变量中，创建一个叫做M2_HOME (或者MAVEN_HOME) ，它的值是maven的安装目录 M2_HOME=D:\tools\apache-maven-3.3.9 在path环境变量中，加入 %M2_HOME%\bin 测试maven的安装，在命令行执行 mvn -v C:\Users\NING MEI&gt;mvn -v Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00) Maven home: D:\tools\apache-maven-3.3.9\bin\.. Java version: 1.8.0_101, vendor: Oracle Corporation Java home: C:\Program Files\Java\jdk1.8.0_101\jre Default locale: zh_CN, platform encoding: GBK OS name: &#34;windows 10&#34;, version: &#34;10.0&#34;, arch: &#34;amd64&#34;, family: &#34;dos&#34; Maven的核心概念 目录结构 一个maven项目是一个文件夹。 比如项目叫做Hello
Hello 项目文件夹 \src \main	叫做主程序目录（完成项目功能的代码和配置文件） \java 源代码（包和相关的类定义） \resources	配置文件 \test 放置测试程序代码的（开发人员自己写的测试代码） \java 测试代码的（junit） \resources 测试程序需要的配置文件 \pom.xml maven的配置文件， 核心文件 POM POM： Project Object Model 项目对象模型， maven把项目当做模型处理。 操作这个模型就是操作项目。
maven通过pom.xml文件实现 项目的构建和依赖的管理。
&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt; &lt;!-- project是根标签， 后面的是约束文件 --&gt; &lt;project xmlns=&#34;http://maven.apache.org/POM/4.0.0&#34; xmlns:xsi=&#34;http://www.w3.org/2001/XMLSchema-instance&#34; xsi:schemaLocation=&#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&#34;&gt; &lt;!-- pom模型的版本， 就是4.0.0 --&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 坐标 --&gt; &lt;groupId&gt;com.bjpowernode&lt;/groupId&gt; &lt;artifactId&gt;ch01-maven&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;/project&gt; 坐标 坐标组成是 groupid, artifiactId, version。
坐标作用：确定资源的，是资源的唯一标识。 在maven中，每个资源都是坐标。 坐标值是唯一的。简称叫gav
&lt;groupId&gt;com.bjpowernode&lt;/groupId&gt; &lt;artifactId&gt;ch01-maven&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; groupId: 组织名称，代码。 公司，团体或者单位的标识。 这个值常使用的公司域名的倒写。 例如：学校的网站 www.bjpowernode.com, groupId: com.bjpowernode 如果项目规模比较大， 也可以是 域名倒写+大项目名称。 例如： www.baidu.com , 无人车： com.baidu.appollo artifactId:项目名称， 如果groupId中有项目， 此时当前的值就是子项目名。 项目名称是唯一的。 version：版本， 项目的版本号， 使用的数字。 三位组成。 例如 主版本号.次版本号.小版本号， 例如： 5.2.5。 注意：版本号中有-SNAPSHOT， 表示快照，不是稳定的版本。 packaging 项目打包的类型， 有jar ，war， ear， pom等等 默认是jar 依赖 dependency 依赖：项目中要使用的其他资源（jar）。
需要使用maven表示依赖，管理依赖。 通过使用dependency和gav一起完成依赖的使用
需要在pom.xml文件中，使用dependencies 和dependency， 还有gav 完成依赖的说明。
格式：
&lt;dependencies&gt; &lt;!-- 日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; maven使用gav作为标识，从互联网下载依赖的jar。 下载到你的本机上。 由maven管理项目使用的这些jar 搜索依赖的地址： https://mvnrepository.com/ 仓库 仓库是存东西的，maven的仓库存放的是：
maven工具自己的jar包。 第三方的其他jar， 比如项目中要使用mysql驱动。 自己写的程序，可以打包为jar 。 存放到仓库。 仓库的分类：
本地仓库：默认路径，是你登录操作系统的账号的目录中%HOMEPATH%/.m2/repository C:\Users\NING MEI\.m2\repository 修改本地仓库的位置：修改maven工具的配置文件（maven的安装路径\conf\setting.xml） 步骤： 1）创建一个目录，作为仓库使用。 目录不要有中文和空格。 目录不要太深。 例如： D:\openrepository 2）修改setting.xml文件，指定 D:\openrepository这个目录
远程仓库： 需要通过联网访问的 1）中央仓库： 一个ftp服务器， 存放了所有的资源。 2）中央仓库的镜像： 就是中央仓库的拷贝。 在各大主要城市都有镜像。 3）私服：在局域网中使用的。 私服就是自己的仓库服务器。 在公司内部使用的。 maven使用仓库： maven自动使用仓库， 当项目启动后， 执行了maven的命令， maven首先访问的是本地仓库， 从仓库中获取所需的jar， 如果本地仓库没有 ，需要访问私服或者中央仓库或者镜像。
maven的生命周期 maven的生命周期： 项目构建的各个阶段。 包括 清理， 编译， 测试，报告，打包，安装，部署
命令 mvn clean	清理命令 mvn compile	编译命令 mvn test	测试命令 mvn package	打包 mvn install 把生成的打包的文件 ，安装到maven仓库。 mvn deploy	部署 IDEA的使用 在IDEA中创建Maven项目
pom.xml的配置 &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt; &lt;project xmlns=&#34;http://maven.apache.org/POM/4.0.0&#34; xmlns:xsi=&#34;http://www.w3.org/2001/XMLSchema-instance&#34; xsi:schemaLocation=&#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&#34;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;MavenDemo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;14&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;14&lt;/maven.compiler.target&gt; &lt;!--项目构建使用的编码，避免中文乱码--&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;!--生成报告的编码--&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!--自定义Spring版本变量--&gt; &lt;spring.version&gt;5.2.12.RELEASE&lt;/spring.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13.1&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 更改IDEA中的Maven成本地安装的Maven Maven 配置阿里镜像 在Maven的安装目录的conf下修改settings.xml文件，添加下面的内容
&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;huaweicloud&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus huaweicloud&lt;/name&gt; &lt;url&gt;https://repo.huaweicloud.com/repository/maven/&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;nexus-tencentyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus tencentyun&lt;/name&gt; &lt;url&gt;http://mirrors.cloud.tencent.com/nexus/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; 修改UTF-8为默认编码 设置环境变量
变量名 MAVEN_OPTS
变量值 -Xms256m -Xmx512m -Dfile.encoding=UTF-8
Linux安装Maven wget https://repo.huaweicloud.com/apache/maven/maven-3/3.9.0/binaries/apache-maven-3.9.0-bin.tar.gz tar -zxvf apache-maven-3.9.0-bin.tar.gz -C /usr/local/ cat &gt; /etc/profile.d/my_env.sh &lt;&lt;-EOF export M2_HOME=/usr/local/apache-maven-3.9.0 export PATH=$M2_HOME/bin:$PATH EOF source /etc/profile ]]></content></entry><entry><title>MyBatis使用示例</title><url>/posts/java/mybatis%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/</url><categories><category>Java</category></categories><tags><tag>Java</tag><tag>MyBatis</tag></tags><content type="html"><![CDATA[什么是 MyBatis？ MyBatis 是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。MyBatis 可以通过简单的 XML 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。
创建MyBatis项目 使用 IDEA 建立一个 SpringBoot 项目，初始化组件部分选择 Web、JDBC API、MyBatis Framework、MySQL Driver
若创建失败或者创建太慢，可以更换阿里镜像： https://start.aliyun.com 创建数据库 CREATE DATABASE IF NOT EXISTS mybatis; USE mybatis; 其对应的数据库 Schema 脚本如下：
DROP TABLE IF EXISTS user; CREATE TABLE user ( id BIGINT(20) NOT NULL COMMENT &#39;主键ID&#39;, name VARCHAR(30) NULL DEFAULT NULL COMMENT &#39;姓名&#39;, age INT(11) NULL DEFAULT NULL COMMENT &#39;年龄&#39;, email VARCHAR(50) NULL DEFAULT NULL COMMENT &#39;邮箱&#39;, PRIMARY KEY (id) ); 其对应的数据库 Data 脚本如下：
INSERT INTO user (id, name, age, email) VALUES (1, &#39;Jone&#39;, 18, &#39;test1@baomidou.com&#39;), (2, &#39;Jack&#39;, 20, &#39;test2@baomidou.com&#39;), (3, &#39;Tom&#39;, 28, &#39;test3@baomidou.com&#39;), (4, &#39;Sandy&#39;, 21, &#39;test4@baomidou.com&#39;), (5, &#39;Billie&#39;, 24, &#39;test5@baomidou.com&#39;); 创建对应的程序目录和类 controller层负责具体的业务模块流程的控制 dao层主要是做数据持久层的工作，负责与数据库联络，封装了增删改查基本操作 entity层用于存放我们的实体类，与数据库中的属性值基本保持一致，实现set和get的方法 service层主要负责业务模块的逻辑应用设计，具体要调用到已定义的DAO层的接口 package com.colzry.mybatis.entity; import lombok.Data; @Data public class User { private Integer id; private String name; private Integer age; private String email; } package com.colzry.mybatis.dao; import com.colzry.mybatis.entity.User; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; import org.apache.ibatis.annotations.Select; import org.springframework.stereotype.Repository; import java.util.List; @Mapper @Repository public interface UserDao { @Select(&#34;select * from user where id=#{id}&#34;) public User getUserById(@Param(&#34;id&#34;) Integer id); @Select(&#34;select * from user where age &gt;= #{age}&#34;) public List&lt;User&gt; getUserByGtAge(@Param(&#34;age&#34;) int age); } package com.colzry.mybatis.service; import com.colzry.mybatis.dao.UserDao; import com.colzry.mybatis.entity.User; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import java.util.List; @Service public class UserService { @Autowired private UserDao userDao; public User queryUser(int id) { return userDao.getUserById(id); } public List&lt;User&gt; queryUser01(int age) { return userDao.getUserByGtAge(age); } } package com.colzry.mybatis.controller; import com.colzry.mybatis.entity.User; import com.colzry.mybatis.service.UserService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import java.util.List; @RestController public class UserController { @Autowired private UserService userService; @RequestMapping(&#34;/user&#34;) public User getUser(@RequestParam(&#34;id&#34;) int id) { return userService.queryUser(id); } @RequestMapping(&#34;/user01&#34;) public List&lt;User&gt; getUserByAge(@RequestParam(&#34;age&#34;) int age) { return userService.queryUser01(age); } } 编写配置文件 对应的application.yml文件
server: port: 9090 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC username: mybatis password: 123456 mybatis: mapper-locations: classpath:/mappers/*.xml type-aliases-package: com.colzry.mybatis.entity 运行项目 运行MyBatisApplication主程序
在浏览器中访问本地的9090端口，输入以下两个内容进行测试
http://localhost:9090/user?id=1 http://localhost:9090/user01?age=18 ]]></content></entry><entry><title>NFS服务搭建</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/nfs%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>NFS</tag></tags><content type="html"><![CDATA[1.安装服务端 # Debian sudo apt install nfs-kernel-server # RedHat sudo yum install rpcbind nfs-utils 2. 更改配置文件 sudo vim /etc/exports 填入一下内容
# * 表示允许任何网段 IP 的系统访问该 NFS 目录 /nfs *(rw,sync,no_root_squash) 配置说明
NFS配置参数权限： ro 只读访问 rw 读写访问 --------------- sync 同步方式存储数据直接将数据保存到磁盘（数据存储安全） async 异步方式存储数据直接将数据保存到内存（提高数据存储效率） all_squash 将所有用户身份都进行转换匿名用户anonymous，适合公用目录。 no_all_squash 不要将普通用户身份进行转换 root_squash 将root用户身份进行转换,root用户的所有请求映射成如anonymous用户一样的权限（默认） no_root_squas 不要将root用户身份进行转换 3.创建目录并赋予权限 sudo mkdir /nfs sudo chown nobody:nogroup /nfs sudo chmod -R 777 /nfs 4.启动NFS服务 sudo /etc/init.d/nfs-kernel-server restart 或者 systemctl restart nfs-kernel-server.service 5. 写入测试内容 echo &#34;test&#34; &gt;&gt; /nfs/test.txt 到此服务器端的安装配置完毕
6.客户端操作 安装客户端
sudo apt install nfs-common 挂载
sudo mount -t nfs 192.168.5.103:/nfs /mnt/nfs -o nolock 设置开机自动挂载
sudo vim /etc/fstab 192.168.5.103:/nfs /mnt/nfs nfs rw 0 0 ]]></content></entry><entry><title>Nmap主机扫描</title><url>/posts/linux%E6%93%8D%E4%BD%9C/nmap%E4%B8%BB%E6%9C%BA%E6%89%AB%E6%8F%8F/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html">ICMP协议探测 nmap -sn -PE -T4 192.168.5.0/24 ARP协议探测 nmap -sn -PR 192.168.5.0/24</content></entry><entry><title>Screen的使用</title><url>/posts/linux%E6%93%8D%E4%BD%9C/screen%E7%9A%84%E4%BD%BF%E7%94%A8/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html"><![CDATA[# 新建会话 screen -S &lt;session_name&gt; # 快捷键Ctrl + A + D 分离当前会话到后台，返回到用户终端 C-a + d # 查看建立的会话 screen -ls # 连接建立的会话 screen -r &lt;session_name&gt; # 杀死建立的会话 screen -XS &lt;session_name&gt; quit ]]></content></entry><entry><title>SpeedTest测速</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/speedtest%E6%B5%8B%E9%80%9F/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>SpeedTest</tag></tags><content type="html"><![CDATA[1. 安装脚本 curl -fsSL git.io/speedtest-cli.sh | sudo bash 下载不了可以新建
#!/usr/bin/env bash # # Copyright (c) 2020-2021 P3TERX &lt;https://p3terx.com&gt; # # This is free software, licensed under the MIT License. # See /LICENSE for more information. # # https://github.com/P3TERX/script # File name: speedtest-cli.sh # Description: Install Ookla Speedtest CLI # System Required: GNU/Linux # Version: 1.3 # set -o errexit set -o errtrace set -o pipefail Green_font_prefix=&#34;\033[32m&#34; Red_font_prefix=&#34;\033[31m&#34; Green_background_prefix=&#34;\033[42;37m&#34; Red_background_prefix=&#34;\033[41;37m&#34; Font_color_suffix=&#34;\033[0m&#34; INFO=&#34;[${Green_font_prefix}INFO${Font_color_suffix}]&#34; ERROR=&#34;[${Red_font_prefix}ERROR${Font_color_suffix}]&#34; PROJECT_NAME=&#39;Ookla Speedtest CLI&#39; BIN_DIR=&#39;/usr/local/bin&#39; BIN_NAME=&#39;speedtest&#39; BIN_FILE=&#34;${BIN_DIR}/${BIN_NAME}&#34; if [[ $(uname -s) != Linux ]]; then echo -e &#34;${ERROR} This operating system is not supported.&#34; exit 1 fi if [[ $(id -u) != 0 ]]; then echo -e &#34;${ERROR} This script must be run as root.&#34; exit 1 fi echo -e &#34;${INFO} Get CPU architecture ...&#34; if [[ $(command -v apk) ]]; then PKGT=&#39;(apk)&#39; OS_ARCH=$(apk --print-arch) elif [[ $(command -v dpkg) ]]; then PKGT=&#39;(dpkg)&#39; OS_ARCH=$(dpkg --print-architecture | awk -F- &#39;{ print $NF }&#39;) else OS_ARCH=$(uname -m) fi case ${OS_ARCH} in *86) FILE_KEYWORD=&#39;i386&#39; ;; x86_64 | amd64) FILE_KEYWORD=&#39;x86_64&#39; ;; aarch64 | arm64) FILE_KEYWORD=&#39;aarch64&#39; ;; arm*) FILE_KEYWORD=&#39;arm&#39; ;; *) echo -e &#34;${ERROR} Unsupported architecture: ${OS_ARCH} ${PKGT}&#34; exit 1 ;; esac echo -e &#34;${INFO} Architecture: ${OS_ARCH} ${PKGT}&#34; echo -e &#34;${INFO} Get ${PROJECT_NAME} download URL ...&#34; DOWNLOAD_URL=&#34;https://install.speedtest.net/app/cli/ookla-speedtest-1.0.0-${FILE_KEYWORD}-linux.tgz&#34; echo -e &#34;${INFO} Download URL: ${DOWNLOAD_URL}&#34; echo -e &#34;${INFO} Installing ${PROJECT_NAME} ...&#34; curl -LS &#34;${DOWNLOAD_URL}&#34; | tar xzC ${BIN_DIR} ${BIN_NAME} chmod +x ${BIN_FILE} if [[ ! $(echo ${PATH} | grep ${BIN_DIR}) ]]; then ln -sf ${BIN_FILE} /usr/bin/${BIN_NAME} fi if [[ -s ${BIN_FILE} &amp;&amp; $(${BIN_NAME} --version) ]]; then echo -e &#34;${INFO} Done.&#34; else echo -e &#34;${ERROR} ${PROJECT_NAME} installation failed !&#34; exit 1 fi 安装完成后执行
speedtest ]]></content></entry><entry><title>Tmux的使用</title><url>/posts/linux%E6%93%8D%E4%BD%9C/tmux%E7%9A%84%E4%BD%BF%E7%94%A8/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html"><![CDATA[Tmux的使用 说明：Ctrl+b 为快捷方式的前缀键，即先按下Ctrl+b，快捷键才会生效。
1. 会话管理 1.1 新建会话 tmux new -s &lt;session-name&gt; 1.2 分离会话 在 Tmux 窗口中，按下Ctrl+b d或者输入tmux detach命令，就会将当前会话与窗口分离。
tmux detach 上面命令执行后，就会退出当前 Tmux 窗口，但是会话和里面的进程仍然在后台运行。
tmux ls命令可以查看当前所有的 Tmux 会话。
tmux ls # or tmux list-session 1.3 接入会话 tmux attach命令用于重新接入某个已存在的会话
# 使用会话编号 tmux attach -t 0 # 使用会话名称 tmux attach -t &lt;session-name&gt; 1.4 杀死会话 tmux kill-session命令用于杀死某个会话
# 使用会话编号 tmux kill-session -t 0 # 使用会话名称 tmux kill-session -t &lt;session-name&gt; 1.5 切换会话 tmux switch命令用于切换会话
# 使用会话编号 tmux switch -t 0 # 使用会话名称 tmux switch -t &lt;session-name&gt; 1.6 重命名会话 tmux rename-session命令用于重命名会话。
tmux rename-session -t 0 &lt;new-name&gt; 1.7 会话快捷键 $ Ctrl+b d：分离当前会话。 $ Ctrl+b s：列出所有会话。 $ Ctrl+b $：重命名当前会话。 2. 窗口管理 2.1 新建窗口 tmux new-window # 新建一个指定名称的窗口 tmux new-window -n &lt;window-name&gt; 2.2 切换窗口 # 切换到指定编号的窗口 tmux select-window -t &lt;window-number&gt; # 切换到指定名称的窗口 tmux select-window -t &lt;window-name&gt; 2.3 重命名窗口 tmux rename-window &lt;new-name&gt; 2.4 窗口快捷键 Ctrl+b c：创建一个新窗口，状态栏会显示多个窗口的信息。 Ctrl+b p：切换到上一个窗口（按照状态栏上的顺序）。 Ctrl+b n：切换到下一个窗口。 Ctrl+b ：切换到指定编号的窗口，其中的是状态栏上的窗口编号。 Ctrl+b w：从列表中选择窗口。 Ctrl+b ,：窗口重命名。 Ctrl+b %：划分左右两个窗格。 Ctrl+b &#34;：划分上下两个窗格。 Ctrl+b ：光标切换到其他窗格。是指向要切换到的窗格的方向键，比如切换到下方窗格，就按方向键↓。 Ctrl+b ;：光标切换到上一个窗格。 Ctrl+b o：光标切换到下一个窗格。 Ctrl+b {：当前窗格左移。 Ctrl+b }：当前窗格右移。 Ctrl+b Ctrl+o：当前窗格上移。 Ctrl+b Alt+o：当前窗格下移。 Ctrl+b x：关闭当前窗格。 Ctrl+b !：将当前窗格拆分为一个独立窗口。 Ctrl+b z：当前窗格全屏显示，再使用一次会变回原来大小。 Ctrl+b Ctrl+：按箭头方向调整窗格大小。 Ctrl+b q：显示窗格编号。 更改prefix前缀快捷键 修改系统级的/etc/tmux.conf或用户级的~/.tmux.conf，没有的话新建
向文件写入一下内容
set -g prefix C-x unbind C-b bind C-x send-prefix ]]></content></entry><entry><title>X-UI，支持多协议多用户的Xray面板</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/x-ui%E6%94%AF%E6%8C%81%E5%A4%9A%E5%8D%8F%E8%AE%AE%E5%A4%9A%E7%94%A8%E6%88%B7%E7%9A%84-xray-%E9%9D%A2%E6%9D%BF/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>XUI</tag></tags><content type="html"><![CDATA[X-ui，支持多协议多用户的 Xray 面板！ 1.0 安装x-ui x-ui地址： https://github.com/vaxilu/x-ui acme脚本地址： https://github.com/acmesh-official/acme.sh 1.0.1更新及安装组件 apt update -y # Debian/Ubuntu 命令 apt install -y curl #Debian/Ubuntu 命令 apt install -y socat #Debian/Ubuntu 命令 yum update -y #CentOS 命令 yum install -y curl #CentOS 命令 yum install -y socat #CentOS 命令 # 关闭防火墙 systemctl disable firewalld.service systemctl stop firewalld.service 1.0.2 安装 Acme 脚本 curl https://get.acme.sh | sh 1.0.3 80 端口空闲的证书申请方式 自行更换代码中的域名、邮箱为你解析的域名及邮箱
~/.acme.sh/acme.sh --set-default-ca --server letsencrypt /zerossl ~/.acme.sh/acme.sh --register-account -m xxxx@xxxx.com ~/.acme.sh/acme.sh --issue -d mydomain.com --standalone 1.0.4 安装证书到指定文件夹（选做） 自行更换代码中的域名为你解析的域名
~/.acme.sh/acme.sh --installcert -d mydomain.com --key-file /root/private.key --fullchain-file /root/cert.crt 1.0.5 安装 &amp; 升级 X-ui 面板 安装及升级的一键代码
bash &lt;(curl -Ls https://raw.githubusercontent.com/vaxilu/x-ui/master/install.sh) 2.0 节点配置及功能讲解 2.0.1 更改面板端口，根路径，用户名和密码 2.0.2 更改xray版本到最新(选做) 2.0.3 创建节点 vmess协议
vless 协议
Trojan 协议
2.0.4 nginx配置 配置此项之前先搭建https静态网站(伪装)
filebrowser (目前推荐安装此服务) 反代别人的网站 安装nginx dnf install nginx -y 安装filebrowser curl -fsSL https://raw.githubusercontent.com/filebrowser/get/master/get.sh | bash #创建配置数据库 filebrowser -d /etc/filebrowser/filebrowser.db config init #设置监听端口 filebrowser -d /etc/filebrowser/filebrowser.db config set --port 5210 #设置语言环境 filebrowser -d /etc/filebrowser/filebrowser.db config set --locale zh-cn #添加一个用户 filebrowser -d /etc/filebrowser/filebrowser.db users add admin password --perm.admin #设置网盘根目录 mkdir -p /data/fs filebrowser -d /etc/filebrowser/filebrowser.db config set --root /data/fs vim /lib/systemd/system/filebrowser.service -----------------------------filebrowser.service------------ [Unit] Description=File Browser After=network.target [Service] Type=simple ExecStart=/usr/local/bin/filebrowser -d /etc/filebrowser/filebrowser.db Restart=on-abnormal RestartSec=5s KillMode=mixed [Install] WantedBy=multi-user.target ----------------------------------------------------------- systemctl daemon-reload systemctl start filebrowser systemctl status filebrowser systemctl enable filebrowser 用户名：admin 密码：password 修改nginx配置 # 先删除nginx默认的80端口配置 vim /etc/nginx/nginx.conf 确保http中有红框中的内容 # 再添加新的配置 vim /etc/nginx/conf.d/vps.conf server{ ssl on; listen 443; server_name fs.gossip.tk; ssl_certificate /root/.acme.sh/fs.gossip.tk/fs.gossip.tk.cer; ssl_certificate_key /root/.acme.sh/fs.gossip.tk/fs.gossip.tk.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; # 反向代理filebrowser网站 location / { proxy_pass http://127.0.0.1:5210; # 设置文件上传大小 client_max_body_size 100M; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # x-ui面板 location ^~ /cocoly { proxy_pass http://127.0.0.1:10105/cocoly; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # ws协议 location /gofic { proxy_redirect off; proxy_pass http://127.0.0.1:31694; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &#34;upgrade&#34;; proxy_set_header Host $http_host; proxy_read_timeout 300s; # Show realip in v2ray access.log proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # 可以把ws协议统一管理 # include /etc/x-ui/location/*.conf; } 可自行更改x-ui的根路径和端口（下面的内容应填在https配置的地方）
location ^~ 面板url根路径 { proxy_pass http://127.0.0.1:面板监听端口/面板url根路径; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location 节点路径 { proxy_redirect off; proxy_pass http://127.0.0.1:节点端口; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &#34;upgrade&#34;; proxy_set_header Host $http_host; proxy_read_timeout 300s; # Show realip in v2ray access.log proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } ok之后可以到cloudflare开启小云朵代理 将SSL的模式改为完全，不然访问网站时可能会报** **此页面不能正确地重定向 错误 我的配置 vim /etc/nginx/conf.d/vps.conf
动态伪装网站配置（搭建了filebrowser）
server{ ssl on; listen 443; server_name fs.gossip.tk; ssl_certificate /root/.acme.sh/fs.gossip.tk/fs.gossip.tk.cer; ssl_certificate_key /root/.acme.sh/fs.gossip.tk/fs.gossip.tk.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; # 反向代理filebrowser网站 location / { proxy_pass http://127.0.0.1:5210; # 设置文件上传大小 client_max_body_size 100M; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # x-ui面板 location ^~ /cocoly { proxy_pass http://127.0.0.1:10105/cocoly; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # ws协议 location /gofic { proxy_redirect off; proxy_pass http://127.0.0.1:31694; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &#34;upgrade&#34;; proxy_set_header Host $http_host; proxy_read_timeout 300s; # Show realip in v2ray access.log proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # 可以把ws协议统一管理 # include /etc/x-ui/location/*.conf; } # 停止80端口的使用，证书的申请需要占用80端口 #server { # listen 80; # server_name pan.gossip.tk; # rewrite ^(.*)$ https://$host$1 permanent; #} 配置完成后重启nginx # 检查nginx 配置的语法错误 nginx -t systemctl restart nginx nginx -t 测试配置文件 nginx -s reload 修改配置后重载生效 nginx -s reopen 重新打开日志文件 nginx -s stop 快速停止 nginx -s quit 如果语法检查通过，重启报错的话，应该是端口被占用了
复制节点信息到代理软件中 注意勾选底层传输为tls（虽然节点并没有开启tls，但nginx已经转发到了443端口），并填写伪装域名
开启cloudflare代理(选做) 优选IP 软件下载地址
Github： https://github.com/XIU2/CloudflareSpeedTest 蓝奏云： https://pan.lanzouo.com/b0742hkxe 将优选出来的IP填入到之前的域名地址中，注意填写伪装域名
成功之后可对节点进行测速，对比之前的0.4M/s快了很多
]]></content></entry><entry><title>搭建私有云盘</title><url>/posts/linux%E6%9C%8D%E5%8A%A1/%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E4%BA%91%E7%9B%98/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>服务搭建</tag><tag>cloudreve</tag></tags><content type="html">
下载并安装cloudreve GitHub仓库地址： https://github.com/cloudreve/Cloudreve/releases 下载arm版本 上传并解压 # 解压程序包 tar -zxvf cloudreve_VERSION_OS_ARCH.tar.gz # 赋予执行权限 chmod +x ./cloudreve # 启动 Cloudreve ./cloudreve 这个时候控制台会显示管理员的用户名和密码，访问树莓派的5212端口（先放行5212端口）就可以来到网站
添加守护进程，让其开机自启 # 编辑配置文件 sudo vim /usr/lib/systemd/system/cloudreve.service 将下文 PATH_TO_CLOUDREVE 更换为程序所在目录：
[Unit] Description=Cloudreve Documentation=https://docs.cloudreve.org After=network.target After=mysqld.service Wants=network.target [Service] WorkingDirectory=/PATH_TO_CLOUDREVE ExecStart=/PATH_TO_CLOUDREVE/cloudreve Restart=on-abnormal RestartSec=5s KillMode=mixed StandardOutput=null StandardError=syslog [Install] WantedBy=multi-user.target ======================法二======================== [Unit] Description=Cloudreve Documentation=https://docs.cloudreve.org After=network.target Wants=network.target [Service] WorkingDirectory=/opt ExecStart=/opt/cloudreve Restart=on-abnormal RestartSec=5s KillMode=mixed StandardOutput=null StandardError=syslog [Install] WantedBy=multi-user.target # 更新配置 sudo systemctl daemon-reload # 启动服务 sudo systemctl start cloudreve # 设置开机启动 sudo systemctl enable cloudreve 管理命令：
# 启动服务 sudo systemctl start cloudreve # 停止服务 sudo systemctl stop cloudreve # 重启服务 sudo systemctl restart cloudreve # 查看状态 sudo systemctl status cloudreve 安装Aria2让cloudreve支持离线下载 BT下载服务搭建 cloudreve配置aria2 来到cloudreve首页，点击管理面板 RPC Secret处填写自己设定的密码
RPC 服务器地址填写本地aria2监听的端口
填写一下临时下载目录保存就行了
批量删除前缀 j=&amp;#34;&amp;#34;;for i in `ls` ;do echo $i;j=${i#*_};mv $i $j;echo $j ;done</content></entry><entry><title>使用Kali爆破WIFI密码</title><url>/posts/linux%E6%93%8D%E4%BD%9C/%E4%BD%BF%E7%94%A8kali%E7%88%86%E7%A0%B4wifi%E5%AF%86%E7%A0%81/</url><categories><category>Linux</category></categories><tags><tag>Linux</tag><tag>工具使用</tag></tags><content type="html">使用kali爆破WiFi密码 首先准备一个免驱的kali无线网卡 过程 插上无线网卡，让虚拟机的kali连接上无线网卡 打开终端，使用ifconfig查看网卡信息 可以看到wlan0就是无线网卡
注意： 以下命令都在root模式下执行
为无线网卡开启监听模式 airmon-ng start wlan0 若遇到提示，则运行提示里的命令即可
再次使用ifconfig命令查看是否被监听
若后面出现mon则说明已经被监听
扫描附近的WiFi airodump-ng wlan0mon BSSID 表示MAC地址 PWR 表示信号 -------排名越靠前的信号越好 CH 表示信号道 ESSID 表示WiFi名称 大概稳定之后可以使用Ctrl + C结束扫描
抓包 airodump-ng --bssid 02:4B:F3:00:7E:D7 -c 6 --write /home/kali/demo wlan0mon --bssid 表示目标WiFi的MAC地址 -c 表示目标WiFi所处的信号道 --wirte 表示抓到的包所在的文件地址（/home/kali/ 为文件目录） 若红框中并没有内容则说明还没抓到数据包，这时需要有人连接上WiFi或者让连接的设备下线，让设备再次自动连接WiFi，这时就可以抓取到握手包
我们选择后者的操作，重新打开新的终端，使用命令
sudo aireplay-ng -0 3 -a 02:4B:F3:00:7E:D7 wlan0mon -0 表示发送攻击的数据包个数 -a 表示目标WiFi的MAC地址 这个时候可以发现上一个终端所标的红框处已经有了内容，说明抓包成功
来到保存握手包的目录，可以发现握手包已经放在了此目录下
使用密码字典进行爆破 密码字典可以使用网上找的，也可以使用kali自带的
来到密码字典所在的目录，执行下面命令
aircrack-ng -w FastPwds.txt /home/kali/demo-01.cap -w 表示密码字典 /home/kali/demo-01.cap 则是握手包 啪的一下，很快啊，就爆破完了(前提密码很简单)，红框中的内容就是密码
注意：本方法只是用来学习和交流的</content></entry><entry><title>Containerd安装</title><url>/posts/docker/containerd%E5%AE%89%E8%A3%85/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[官方下载地址：https://github.com/containerd/containerd/releases
wget https://github.com/containerd/containerd/releases/download/v1.6.8/cri-containerd-cni-1.6.8-linux-amd64.tar.gz mkdir cri-containerd-cni &amp;&amp; tar -zxvf cri-containerd-cni-1.6.8-linux-amd64.tar.gz -C cri-containerd-cni 复制配置文件
cp cri-containerd-cni/etc/crictl.yaml /etc/ cp cri-containerd-cni/etc/systemd/system/containerd.service /etc/systemd/system/ # 复制 containerd 和相关依赖 cp cri-containerd-cni/usr/local/bin/. /usr/local/bin/ -a # 复制runc文件 cp cri-containerd-cni/usr/local/sbin/. /usr/local/sbin/ -a 生成和配置启动文件 # 1. 创建文件夹 mkdir -p /etc/containerd # 2. 生成配置文件 containerd config default &gt; /etc/containerd/config.toml vim /etc/containerd/config.toml disabled_plugins = [] imports = [] oom_score = 0 plugin_dir = &#34;&#34; required_plugins = [] root = &#34;/var/lib/containerd&#34; state = &#34;/run/containerd&#34; version = 2 [cgroup] path = &#34;&#34; [debug] address = &#34;&#34; format = &#34;&#34; gid = 0 level = &#34;&#34; uid = 0 [grpc] address = &#34;/run/containerd/containerd.sock&#34; gid = 0 max_recv_message_size = 16777216 max_send_message_size = 16777216 tcp_address = &#34;&#34; tcp_tls_cert = &#34;&#34; tcp_tls_key = &#34;&#34; uid = 0 [metrics] address = &#34;&#34; grpc_histogram = false [plugins] [plugins.&#34;io.containerd.gc.v1.scheduler&#34;] deletion_threshold = 0 mutation_threshold = 100 pause_threshold = 0.02 schedule_delay = &#34;0s&#34; startup_delay = &#34;100ms&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;] disable_apparmor = false disable_cgroup = false disable_hugetlb_controller = true disable_proc_mount = false disable_tcp_service = true enable_selinux = false enable_tls_streaming = false ignore_image_defined_volumes = false max_concurrent_downloads = 3 max_container_log_line_size = 16384 netns_mounts_under_state_dir = false restrict_oom_score_adj = false # sandbox_image = &#34;k8s.gcr.io/pause:3.5&#34; # 1. 修改基础镜像地址 sandbox_image = &#34;registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5&#34; selinux_category_range = 1024 stats_collect_period = 10 stream_idle_timeout = &#34;4h0m0s&#34; stream_server_address = &#34;127.0.0.1&#34; stream_server_port = &#34;0&#34; systemd_cgroup = false tolerate_missing_hugetlb_controller = true unset_seccomp_profile = &#34;&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.cni] bin_dir = &#34;/opt/cni/bin&#34; conf_dir = &#34;/etc/cni/net.d&#34; conf_template = &#34;&#34; max_conf_num = 1 [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd] default_runtime_name = &#34;runc&#34; disable_snapshot_annotations = true discard_unpacked_layers = false no_pivot = false snapshotter = &#34;overlayfs&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.default_runtime] base_runtime_spec = &#34;&#34; container_annotations = [] pod_annotations = [] privileged_without_host_devices = false runtime_engine = &#34;&#34; runtime_root = &#34;&#34; runtime_type = &#34;&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.default_runtime.options] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc] base_runtime_spec = &#34;&#34; container_annotations = [] pod_annotations = [] privileged_without_host_devices = false runtime_engine = &#34;&#34; runtime_root = &#34;&#34; runtime_type = &#34;io.containerd.runc.v2&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc.options] BinaryName = &#34;&#34; CriuImagePath = &#34;&#34; CriuPath = &#34;&#34; CriuWorkPath = &#34;&#34; IoGid = 0 IoUid = 0 NoNewKeyring = false NoPivotRoot = false Root = &#34;&#34; ShimCgroup = &#34;&#34; SystemdCgroup = false [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.untrusted_workload_runtime] base_runtime_spec = &#34;&#34; container_annotations = [] pod_annotations = [] privileged_without_host_devices = false runtime_engine = &#34;&#34; runtime_root = &#34;&#34; runtime_type = &#34;&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.untrusted_workload_runtime.options] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.image_decryption] key_model = &#34;node&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry] config_path = &#34;&#34; [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.auths] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.configs] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.headers] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.mirrors] # 2. 设置仓库地址 [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.mirrors.&#34;docker.io&#34;] endpoint = [&#34;https://usydjf4t.mirror.aliyuncs.com&#34;] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry.mirrors.&#34;k8s.gcr.io&#34;] endpoint = [&#34;https://registry.cn-hangzhou.aliyuncs.com/google_containers&#34;] [plugins.&#34;io.containerd.grpc.v1.cri&#34;.x509_key_pair_streaming] tls_cert_file = &#34;&#34; tls_key_file = &#34;&#34; [plugins.&#34;io.containerd.internal.v1.opt&#34;] path = &#34;/opt/containerd&#34; [plugins.&#34;io.containerd.internal.v1.restart&#34;] interval = &#34;10s&#34; [plugins.&#34;io.containerd.metadata.v1.bolt&#34;] content_sharing_policy = &#34;shared&#34; [plugins.&#34;io.containerd.monitor.v1.cgroups&#34;] no_prometheus = false [plugins.&#34;io.containerd.runtime.v1.linux&#34;] no_shim = false runtime = &#34;runc&#34; runtime_root = &#34;&#34; shim = &#34;containerd-shim&#34; shim_debug = false [plugins.&#34;io.containerd.runtime.v2.task&#34;] platforms = [&#34;linux/amd64&#34;] [plugins.&#34;io.containerd.service.v1.diff-service&#34;] default = [&#34;walking&#34;] [plugins.&#34;io.containerd.snapshotter.v1.aufs&#34;] root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.btrfs&#34;] root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.devmapper&#34;] async_remove = false base_image_size = &#34;&#34; pool_name = &#34;&#34; root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.native&#34;] root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.overlayfs&#34;] root_path = &#34;&#34; [plugins.&#34;io.containerd.snapshotter.v1.zfs&#34;] root_path = &#34;&#34; [proxy_plugins] [stream_processors] [stream_processors.&#34;io.containerd.ocicrypt.decoder.v1.tar&#34;] accepts = [&#34;application/vnd.oci.image.layer.v1.tar+encrypted&#34;] args = [&#34;--decryption-keys-path&#34;, &#34;/etc/containerd/ocicrypt/keys&#34;] env = [&#34;OCICRYPT_KEYPROVIDER_CONFIG=/etc/containerd/ocicrypt/ocicrypt_keyprovider.conf&#34;] path = &#34;ctd-decoder&#34; returns = &#34;application/vnd.oci.image.layer.v1.tar&#34; [stream_processors.&#34;io.containerd.ocicrypt.decoder.v1.tar.gzip&#34;] accepts = [&#34;application/vnd.oci.image.layer.v1.tar+gzip+encrypted&#34;] args = [&#34;--decryption-keys-path&#34;, &#34;/etc/containerd/ocicrypt/keys&#34;] env = [&#34;OCICRYPT_KEYPROVIDER_CONFIG=/etc/containerd/ocicrypt/ocicrypt_keyprovider.conf&#34;] path = &#34;ctd-decoder&#34; returns = &#34;application/vnd.oci.image.layer.v1.tar+gzip&#34; [timeouts] &#34;io.containerd.timeout.shim.cleanup&#34; = &#34;5s&#34; &#34;io.containerd.timeout.shim.load&#34; = &#34;5s&#34; &#34;io.containerd.timeout.shim.shutdown&#34; = &#34;3s&#34; &#34;io.containerd.timeout.task.state&#34; = &#34;2s&#34; [ttrpc] address = &#34;&#34; gid = 0 uid = 0 启动 systemctl daemon-reload systemctl enable containerd --now systemctl status containerd ]]></content></entry><entry><title>Docker换源</title><url>/posts/docker/%E6%8D%A2%E6%BA%90/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[Podman换源 网易 hub-mirror.c.163.com USTC docker.mirrors.ustc.edu.cn vim /etc/containers/registries.conf ################################################ unqualified-search-registries = [&#34;docker.io&#34;] [[registry]] prefix = &#34;docker.io&#34; location = &#34;l6p4ic76.mirror.aliyuncs.com&#34; ################################################# Docker换源 vim /etc/docker/daemon.json { &#34;registry-mirrors&#34;: [&#34;https://l6p4ic76.mirror.aliyuncs.com&#34;], &#34;log-driver&#34;:&#34;json-file&#34;, &#34;log-opts&#34;: {&#34;max-size&#34;:&#34;500m&#34;, &#34;max-file&#34;:&#34;3&#34;} } systemctl restart docker &gt; 南京大学 https://docker.nju.edu.cn/ &gt; 网易 http://hub-mirror.c.163.com &gt; 腾讯云 docker hub mirror https://mirror.ccs.tencentyun.com &gt; docker中国 https://registry.docker-cn.com &gt; 我的 daocloud http://f1361db2.m.daocloud.io &gt; 我的华为云 https://326fcbdbb5c7487aa2d8180833e71119.mirror.swr.myhuaweicloud.com ) 我的阿里云 https://l6p4ic76.mirror.aliyuncs.com 查看镜像源 docker info podman info ]]></content></entry><entry><title>K8S集群部署</title><url>/posts/docker/k8s%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[官网地址：https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/
1. 搭建单Master集群 创建一个 Master 节点 kubeadm init 将 Node节点加入到当前集群中 kubeadm join &lt;Master节点的IP和端口&gt; 环境准备 工作节点 主机名 IP地址 系统版本 master k8s-master 192.168.211.201 almalinux8.6 node1 k8s-node1 192.168.211.202 almalinux8.6 node2 k8s-node2 192.168.211.203 almalinux8.6 注意： 从 2 - 5 的内容在在master和node节点主机在都要执行
2. 安装前准备 2.1 修改和添加主机名 # 修改主机名 # 在master节点执行 hostnamectl set-hostname k8s-master # 在node节点执行 hostnamectl set-hostname k8s-node1 hostnamectl set-hostname k8s-node2 # 添加主机名 cat &gt;&gt; /etc/hosts &lt;&lt; EOF 192.168.211.201 k8s-master 192.168.211.202 k8s-node1 192.168.211.203 k8s-node2 EOF 2.2 关闭防火墙 systemctl stop firewalld systemctl disable firewalld 2.3 关闭 selinux sed -i &#39;s/SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux setenforce 0 2.4 关闭swap分区 先临时关闭，再永久关闭，这样就不用重启 # 临时关闭 swapoff -a # 永久关闭 sed -ri &#39;s/.*swap.*/#&amp;/&#39; /etc/fstab # 重启生效 # 查看效果 free -m # 重新启动swap分区 swapon -a 2.5 网桥过滤 cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-arptables = 1 net.ipv4.ip_forward=1 net.ipv4.ip_forward_use_pmtu = 0 EOF # 生效命令 sysctl --system 2.6 时间同步 # 安装软件 yum -y install ntpdate # 向阿里云服务器同步时间 ntpdate time1.aliyun.com # 删除本地时间并设置时区为上海 rm -rf /etc/localtime ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # 查看时间 date -R || date 3. 所有节点安装Docker 1.卸载旧版本 yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-engine 2.安装需要的依赖包	yum install -y yum-utils 3.设置阿里云docker镜像 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo &amp;&amp; yum makecache 4.安装docker yum -y install docker-ce docker-ce-cli containerd.io 5.启动Docker systemctl start docker &amp;&amp; systemctl enable docker &amp;&amp; systemctl status docker 6.查看docker版本信息 docker info 4. 所有节点配置阿里云Docker、kubernetes镜像 1. 配置阿里云docker镜像加速 mkdir -p /etc/docker cat &gt; /etc/docker/daemon.json &lt;&lt; EOF { &#34;registry-mirrors&#34;: [&#34;https://l6p4ic76.mirror.aliyuncs.com&#34;], &#34;log-driver&#34;:&#34;json-file&#34;, &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;], &#34;log-opts&#34;: {&#34;max-size&#34;:&#34;500m&#34;, &#34;max-file&#34;:&#34;3&#34;} } EOF systemctl restart docker 2. 配置阿里云Kubernetes 镜像 cat &gt;&gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 5. 所有节点安装kubelet kubeadm kubectl yum install -y --nogpgcheck kubelet-1.22.15 kubeadm-1.22.15 kubectl-1.22.15 # 指定K8S版本安装，不指定版本默认安装最新版。 # yum install -y --nogpgcheck kubelet kubeadm kubectl systemctl enable kubelet &amp;&amp; systemctl start kubelet 6. 部署Kubernetes Master节点 这里指定阿里云镜像仓库地址，默认的镜像地址无法加载访问。
kubeadm init \ --apiserver-advertise-address=192.168.211.201 \ --image-repository registry.aliyuncs.com/google_containers \ --kubernetes-version v1.22.15 \ --service-cidr=10.96.0.0/12 \ --pod-network-cidr=10.244.0.0/16 若出现错误
[root@almalinux ~]# kubeadm init \ &gt; --apiserver-advertise-address=192.168.211.201 \ &gt; --image-repository registry.aliyuncs.com/google_containers \ &gt; --kubernetes-version v1.25.3 \ &gt; --service-cidr=10.96.0.0/12 \ &gt; --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.25.3 [preflight] Running pre-flight checks [WARNING FileExisting-tc]: tc not found in system path error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR CRI]: container runtime is not running: output: E1029 14:48:00.390255 29768 remote_runtime.go:948] &#34;Status from runtime service failed&#34; err=&#34;rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.RuntimeService&#34; time=&#34;2022-10-29T14:48:00+08:00&#34; level=fatal msg=&#34;getting status of runtime: rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.RuntimeService&#34; , error: exit status 1 [preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...` To see the stack trace of this error execute with --v=5 or higher 解决办法
rm -rf /etc/containerd/config.toml systemctl restart containerd # 最后使用 kubeadm reset 若出现错误
[root@k8s-master ~]# kubeadm init \ &gt; --apiserver-advertise-address=192.168.211.201 \ &gt; --image-repository registry.aliyuncs.com/google_containers \ &gt; --kubernetes-version v1.25.3 \ &gt; --service-cidr=10.96.0.0/12 \ &gt; --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.25.3 [preflight] Running pre-flight checks [WARNING FileExisting-tc]: tc not found in system path [WARNING Hostname]: hostname &#34;k8s-master&#34; could not be reached [WARNING Hostname]: hostname &#34;k8s-master&#34;: lookup k8s-master on 223.5.5.5:53: no such host error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist [preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...` To see the stack trace of this error execute with --v=5 or higher 解决方法
modprobe br_netfilter echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables 注意： 如果要使用 kubectl get nodes 命令需要做以下配置
- master节点，root用户，执行以下命令 echo &#34;export KUBECONFIG=/etc/kubernetes/admin.conf&#34; &gt;&gt; ~/.bash_profile source ~/.bash_profile - master节点，非root用户，执行以下命令 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config - node节点需要从 master 节点拷贝 admin.con 文件到 node 节点上 scp root@master:/etc/kubernetes/admin.conf /etc/kubernetes/ - root 和 非root 用户的命令同master 7. 部署网络插件 # 以下网络插件任选一个 # CNI网络插件 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml # Flannel网络插件 kubectl apply -f https://kuboard.cn/install-script/flannel/flannel-v0.14.0.yaml # 查看 kubectl get pods -n kube-system 若发现有Pending的删除即可，会自动重新部署
[root@k8s-master ~]# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-7f6cbbb7b8-6gxf6 0/1 Pending 0 23m coredns-7f6cbbb7b8-nnjsk 0/1 Pending 0 23m etcd-k8s-master 1/1 Running 1 23m kube-apiserver-k8s-master 1/1 Running 1 23m kube-controller-manager-k8s-master 1/1 Running 1 23m kube-proxy-6d4d6 1/1 Running 0 18m kube-proxy-m4vx9 1/1 Running 0 23m kube-scheduler-k8s-master 1/1 Running 1 23m [root@k8s-master ~]# kubectl delete pods coredns-7f6cbbb7b8-6gxf6 coredns-7f6cbbb7b8-nnjsk -n kube-system pod &#34;coredns-7f6cbbb7b8-6gxf6&#34; deleted pod &#34;coredns-7f6cbbb7b8-nnjsk&#34; deleted [root@k8s-master ~]# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-7f6cbbb7b8-4df47 1/1 Running 0 11s coredns-7f6cbbb7b8-wxzcl 1/1 Running 0 11s etcd-k8s-master 1/1 Running 1 24m kube-apiserver-k8s-master 1/1 Running 1 24m kube-controller-manager-k8s-master 1/1 Running 1 24m kube-proxy-6d4d6 1/1 Running 0 19m kube-proxy-m4vx9 1/1 Running 0 24m kube-scheduler-k8s-master 8. 部署node节点 # 只在 master 节点执行 kubeadm token create --print-join-command # 在node节点中执行打印出的结果 kubeadm join 192.168.211.201:6443 --token hfyeoe.ie453hoen4eku70w --discovery-token-ca-cert-hash sha256:3716cd7f3c8a52b78b1ab495e7fbd3c6f7dabd899a0237c203c05bce11ac9be6 # 在 master 节点中查看 [root@k8s-master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master Ready control-plane,master 59m v1.22.3 k8s-node1 Ready &lt;none&gt; 54m v1.22.3 k8s-node2 Ready &lt;none&gt; 3m53s v1.22.3 注意： 若新加入的node节点出现NotReady等待一会即可
9. 添加图形化管理（选做） # 在 master 节点执行 kubectl apply -f https://addons.kuboard.cn/kuboard/kuboard-v3-swr.yaml 执行指令 watch kubectl get pods -n kuboard，等待 kuboard 名称空间中所有的 Pod 就绪
root@k8s-master ~]# kubectl get pods -n kuboard NAME READY STATUS RESTARTS AGE kuboard-agent-2-85d76b44dd-jvpm2 1/1 Running 0 9s kuboard-agent-67864c5f66-4w9z2 1/1 Running 0 9s kuboard-etcd-htppb 1/1 Running 0 36s kuboard-v3-765f7bcbfd-lpwct 0/1 Running 0 36s 访问 Kuboard 在浏览器中打开链接 http://your-node-ip-address:30080
输入初始用户名和密码，并登录
用户名： admin 密码： Kuboard123 卸载 kubectl delete -f https://addons.kuboard.cn/kuboard/kuboard-v3-swr.yaml rm -rf /usr/share/kuboard ]]></content></entry><entry><title>安装Docker</title><url>/posts/docker/%E5%AE%89%E8%A3%85docker/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html">1. 命令行安装 1.1 卸载旧版本 yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine 1.2 安装 执行以下命令安装依赖包：
yum install -y yum-utils 鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。 执行下面的命令添加 yum 软件源：
yum-config-manager \ --add-repo \ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 官方源 # yum-config-manager \ # --add-repo \ # https://download.docker.com/linux/centos/docker-ce.repo 更新 yum 软件源缓存，并安装 docker-ce
yum makecache yum install docker-ce docker-ce-cli containerd.io docker-scan-plugin docker-compose-plugin docker-ce-rootless-extras 1.3 防火墙额外设置 由于 CentOS8 防火墙使用了 nftables，但 Docker 尚未支持 nftables， 我们可以使用如下设置使用 iptables：
更改 vim /etc/firewalld/firewalld.conf
# FirewallBackend=nftables FirewallBackend=iptables 或者执行如下命令：
firewall-cmd --permanent --zone=trusted --add-interface=docker0 firewall-cmd --reload 2. 使用脚本自动安装 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 3. 启动Docker systemctl enable docker systemctl start docker</content></entry><entry><title>使用Docker安装常用环境</title><url>/posts/docker/%E4%BD%BF%E7%94%A8docker%E5%AE%89%E8%A3%85%E5%B8%B8%E7%94%A8%E7%8E%AF%E5%A2%83/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag></tags><content type="html"><![CDATA[安装Docker $ curl -fsSL get.docker.com -o get-docker.sh $ sudo sh get-docker.sh --mirror Aliyun 卸载
dnf remove -y -q docker-ce docker-ce-cli containerd.io docker-scan-plugin docker-compose-plugin docker-ce-rootless-extras rm -rf 启动 Docker $ sudo systemctl enable docker $ sudo systemctl start docker 建立 docker 用户组 默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。
建立 docker 组：
$ sudo groupadd docker 将当前用户加入 docker 组：
$ sudo usermod -aG docker $USER 注销用户或者重启系统 更换镜像源 vim /etc/docker/daemon.json {&#34;registry-mirrors&#34;: [&#34;http://hub-mirror.c.163.com&#34;]} systemctl restart docker 2) 腾讯云 docker hub mirror https://mirror.ccs.tencentyun.com 3) 华为云 https://05f073ad3c0010ea0f4bc00b7105ec20.mirror.swr.myhuaweicloud.com 4) docker中国 https://registry.docker-cn.com 5) 网易 http://hub-mirror.c.163.com 6) daocloud http://f1361db2.m.daocloud.io 安装Docker图形化界面 #下载 Docker 图形化界面 portainer sudo docker pull portainer/portainer #创建 portainer 容器 sudo docker volume create portainer_data #运行 portainer sudo docker run -d \ -p 9000:9000 \ --name portainer \ --restart always \ -v /var/run/docker.sock:/var/run/docker.sock \ -v portainer_data:/data \ portainer/portainer 安装MySql //拉取MySQL镜像 docker pull mysql //启动MySQL，注意更改密码，用户名为root，密码czyadmin docker run -d \ --name mysql \ --restart=always \ -p 3306:3306 \ -e MYSQL_ROOT_PASSWORD=czyadmin \ mysql 安装Redis //拉取Redis镜像 docker pull redis //启动Redis，注意更改密码，用户名为root，密码czyadmin docker run -d \ --name redis \ --restart=always \ -p 6379:6379 \ redis \ --requirepass &#34;czyadmin&#34; 安装Nginx 拉取镜像
docker pull nginx 创建本地配置文件
mkdir -p /etc/nginx/conf.d &amp;&amp; vim /etc/nginx/nginx.conf user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#39;$remote_addr - $remote_user [$time_local] &#34;$request&#34; &#39; &#39;$status $body_bytes_sent &#34;$http_referer&#34; &#39; &#39;&#34;$http_user_agent&#34; &#34;$http_x_forwarded_for&#34;&#39;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; } 启动服务
//启动nginx，映射本地配置文件 docker run -d \ --name nginx \ --restart=always \ -p 80:80 \ -v /etc/nginx/nginx.conf:/etc/nginx/nginx.conf \ -v /etc/nginx/conf.d:/etc/nginx/conf.d \ nginx vim /etc/nginx/conf.d/demo.conf server { listen 80; listen [::]:80; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; } } docker exec nginx bash -c &#39;nginx -s reload&#39; 安装RabbitMQ docker pull rabbitmq:management 默认用户名和密码：guest/guest
docker run -dit \ --name rabbitmq \ --restart=always \ -p 5672:5672 \ -p 15672:15672 \ rabbitmq:management 端口 作用 15672 管理界面UI的使用端口 15671 管理监听端口 5672,5671 AMQP 0-9-1 without and with TLSclient端通信口 4369 (epmd)epmd代表Erlang端口映射守护进程，erlang发现口 25672 ( Erlang distribution) server间内部通信口 安装Postgresql docker pull postgres docker run -d \ --name postgres \ --restart=always \ -p 5432:5432 \ -e POSTGRES_PASSWORD=czyadmin \ postgres 用户名：postgres	密码：czyadmin
]]></content></entry><entry><title>树莓派使用Docker安装openwrt作为旁路由(网关服务器)</title><url>/posts/docker/%E6%A0%91%E8%8E%93%E6%B4%BE%E4%BD%BF%E7%94%A8docker%E5%AE%89%E8%A3%85openwrt%E4%BD%9C%E4%B8%BA%E6%97%81%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3%E6%9C%8D%E5%8A%A1%E5%99%A8/</url><categories><category>Docker</category></categories><tags><tag>Docker</tag><tag>树莓派</tag></tags><content type="html"><![CDATA[
推荐使用 树莓派爱好基地的arm64无桌面增强版镜像
仓库地址： https://github.com/openfans-community-offical/Debian-Pi-Aarch64/blob/master/README_zh.md 仓库中有详细的说明文档和下载地址
开始安装openwrt容器 树莓派爱好基地的arm64无桌面增强版自带docker，可以直接使用
1. 打开网卡混杂模式 sudo ip link set eth0 promisc on 2. 创建macvlan虚拟网络，同一网段下的主机才能访问容器 下面的网段(subnet)和网关(gateway)选项请结合实际自行更改
docker network create -d macvlan --subnet=192.168.0.0/24 --gateway=192.168.0.1 -o parent=eth0 macnet 此时，我们使用 docker network ls命令可以看到网络macnet已建立成功：
pi@raspbian:~$ docker network ls NETWORK ID NAME DRIVER SCOPE 7b8e38d3dd3c bridge bridge local f96e6360c248 host host local 7c7a5a51b268 macnet macvlan local c8c6782b8e1e none null local 3. 拉取openwrt镜像 docker pull registry.cn-shanghai.aliyuncs.com/suling/openwrt:rpi4 镜像拉取完成后，我们可以执行docker images命令查看现存镜像：
docker images REPOSITORY TAG IMAGE ID CREATED SIZE registry.cn-shanghai.aliyuncs.com/suling/openwrt rpi4 c3ba4d17a20e 32 hours ago 455MB 4. 创建并启动容器 docker run --restart always --name openwrt -d --network macnet --privileged --ip 192.168.0.200 registry.cn-shanghai.aliyuncs.com/suling/openwrt:rpi4 /sbin/init 其中：
--restart always参数表示容器退出时始终重启，使服务尽量保持始终可用；
--name openwrt参数定义了容器的名称；
-d参数定义使容器运行在 Daemon 模式(后台运行)；
--network macnet参数定义将容器加入 maxnet网络；
--privileged参数定义容器运行在特权模式下；
--ip 192.168.0.200指定容器的ip
registry.cn-shanghai.aliyuncs.com/suling/openwrt:latest为 Docker 镜像名，因容器托管在阿里云 Docker 镜像仓库内，所以在镜像名中含有阿里云仓库信息；
/sbin/init定义容器启动后执行的命令。
启动容器后，我们可以使用 docker ps -a命令查看当前运行的容器：
docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 5cd19f4cd735 registry.cn-shanghai.aliyuncs.com/suling/openwrt:rpi4 &#34;/sbin/init&#34; 20 hours ago Up 7 hours openwrt 5. 进入容器修改ip,网关和dns docker exec -it openwrt ash 执行此命令后我们便进入 OpenWrt 的命令行界面，首先，我们需要编辑 OpenWrt 的网络配置文件：
vim /etc/config/network 我们需要更改 Lan 口设置：
config interface &#39;lan&#39; option ifname &#39;eth0&#39; option proto &#39;static&#39; option netmask &#39;255.255.255.0&#39; option ip6assign &#39;60&#39; option ipaddr &#39;192.168.0.200&#39; option gateway &#39;192.168.0.1&#39; option dns &#39;192.168.0.1&#39; 6. 保存后重启网络 /etc/init.d/network restart 按下Ctrl + D可以退出openwrt的终端
7. 进入luci 控制面板 在浏览器中输入第 5 步option ipaddr项目中的 IP 进入 Luci 控制面板，若option ipaddr的参数为 192.168.0.200，则可以在浏览器输入 http://192.168.0.200进入控制面板。
用户名：root
密码：password
8. 配置防火墙 在网络-防火墙-自定义规则添加以下命令后重启防火墙
iptables -t nat -I POSTROUTING -o eth0 -j MASQUERADE 9. 关闭dhcp服务 在网络-接口处删除多于的网络，只保留LAN口，点击LAN口的修改
来到最下面的基本设置，勾上忽略此接口，然后保存应用即可
10. 将网关指向openwrt 来到路由器的后台管理，将路由器的网关指向openwrt的ip地址即可
参考： https://mlapp.cn/376.html ]]></content></entry><entry><title>初次安装Git的配置</title><url>/posts/git/%E5%88%9D%E6%AC%A1%E5%AE%89%E8%A3%85git%E7%9A%84%E9%85%8D%E7%BD%AE/</url><categories><category>Git</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[初次运行 Git 前的配置 Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：
/etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果在执行 git config 时带上 --system 选项，那么它就会读写该文件中的配置变量。 （由于它是系统配置文件，因此你需要管理员或超级用户权限来修改它。） ~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 你可以传递 --global 选项让 Git 读写此文件，这会对你系统上 所有 的仓库生效。 当前使用仓库的 Git 目录中的 config 文件（即 .git/config）：针对该仓库。 你可以传递 --local 选项让 Git 强制读写此文件，虽然默认情况下用的就是它。。 （当然，你需要进入某个 Git 仓库中才能让该选项生效。） 每一个级别会覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。
在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\Users\$USER ）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。 如果你在 Windows 上使用 Git 2.x 以后的版本，那么还有一个系统级的配置文件，Windows XP 上在 C:\Documents and Settings\All Users\Application Data\Git\config ，Windows Vista 及更新的版本在 C:\ProgramData\Git\config 。此文件只能以管理员权限通过 git config -f &lt;file&gt; 来修改。
你可以通过以下命令查看所有的配置以及它们所在的文件：
$ git config --list --show-origin 用户信息 安装完 Git 之后，要做的第一件事就是设置你的用户名和邮件地址。 这一点很重要，因为每一个 Git 提交都会使用这些信息，它们会写入到你的每一次提交中，不可更改：
$ git config --global user.name &#34;John Doe&#34; $ git config --global user.email johndoe@example.com 再次强调，如果使用了 --global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。 当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 --global 选项的命令来配置。
检查配置信息 如果想要检查你的配置，可以使用 git config --list 命令来列出所有 Git 当时能找到的配置。
$ git config --list user.name=John Doe user.email=johndoe@example.com color.status=auto color.branch=auto color.interactive=auto color.diff=auto ... 你可能会看到重复的变量名，因为 Git 会从不同的文件中读取同一个配置（例如：/etc/gitconfig 与 ~/.gitconfig）。 这种情况下，Git 会使用它找到的每一个变量的最后一个配置。
你可以通过输入 git config &lt;key&gt;： 来检查 Git 的某一项配置
$ git config user.name John Doe 生成 SSH 公钥 许多 Git 服务器都使用 SSH 公钥进行认证。 为了向 Git 服务器提供 SSH 公钥，如果某系统用户尚未拥有密钥，必须事先为其生成一份。 这个过程在所有操作系统上都是相似的。 首先，你需要确认自己是否已经拥有密钥。 默认情况下，用户的 SSH 密钥存储在其 ~/.ssh 目录下。 进入该目录并列出其中内容，你便可以快速确认自己是否已拥有密钥：
$ cd ~/.ssh $ ls authorized_keys2 id_dsa known_hosts config id_dsa.pub 我们需要寻找一对以 id_dsa 或 id_rsa 命名的文件，其中一个带有 .pub 扩展名。 .pub 文件是你的公钥，另一个则是与之对应的私钥。 如果找不到这样的文件（或者根本没有 .ssh 目录），你可以通过运行 ssh-keygen 程序来创建它们。 在 Linux/macOS 系统中，ssh-keygen 随 SSH 软件包提供；在 Windows 上，该程序包含于 MSysGit 软件包中。
$ ssh-keygen -o Generating public/private rsa key pair. Enter file in which to save the key (/home/schacon/.ssh/id_rsa): Created directory &#39;/home/schacon/.ssh&#39;. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/schacon/.ssh/id_rsa. Your public key has been saved in /home/schacon/.ssh/id_rsa.pub. The key fingerprint is: d0:82:24:8e:d7:f1:bb:9b:33:53:96:93:49:da:9b:e3 schacon@mylaptop.local 首先 ssh-keygen 会确认密钥的存储位置（默认是 .ssh/id_rsa），然后它会要求你输入两次密钥口令。 如果你不想在使用密钥时输入口令，将其留空即可。 然而，如果你使用了密码，那么请确保添加了 -o 选项，它会以比默认格式更能抗暴力破解的格式保存私钥。 你也可以用 ssh-agent 工具来避免每次都要输入密码。
现在，进行了上述操作的用户需要将各自的公钥发送给任意一个 Git 服务器管理员 （假设服务器正在使用基于公钥的 SSH 验证设置）。 他们所要做的就是复制各自的 .pub 文件内容，并将其通过邮件发送。 公钥看起来是这样的：
$ cat ~/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSU GPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3 Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XA t3FaoJoAsncM1Q9x5+3V0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/En mZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbx NrRFi9wrf+M7Q== schacon@mylaptop.local 将公钥上传到指定服务器 # 上传公钥到服务器 $ ssh-copy-id user@host # 文件会自动上传为服务器特定文件 ～/.ssh/authorized_keys 要了解更多关于Git的知识请访问官方文档
官方文档入口 ]]></content></entry></search>